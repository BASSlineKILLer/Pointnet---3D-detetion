2025-07-12 11:38:54,372   INFO  **********************Start logging**********************
2025-07-12 11:38:54,372   INFO  CUDA_VISIBLE_DEVICES=ALL
2025-07-12 11:38:54,372   INFO  Training with a single process
2025-07-12 11:38:54,372   INFO  cfg_file         ./cfgs/nuscenes_models/cbgs_voxel0075_voxelnext.yaml
2025-07-12 11:38:54,372   INFO  batch_size       4
2025-07-12 11:38:54,372   INFO  epochs           100
2025-07-12 11:38:54,372   INFO  workers          4
2025-07-12 11:38:54,372   INFO  extra_tag        default
2025-07-12 11:38:54,372   INFO  ckpt             None
2025-07-12 11:38:54,373   INFO  pretrained_model None
2025-07-12 11:38:54,373   INFO  launcher         none
2025-07-12 11:38:54,373   INFO  tcp_port         18888
2025-07-12 11:38:54,373   INFO  sync_bn          False
2025-07-12 11:38:54,373   INFO  fix_random_seed  False
2025-07-12 11:38:54,373   INFO  ckpt_save_interval 1
2025-07-12 11:38:54,373   INFO  local_rank       None
2025-07-12 11:38:54,373   INFO  max_ckpt_save_num 30
2025-07-12 11:38:54,373   INFO  merge_all_iters_to_one_epoch False
2025-07-12 11:38:54,373   INFO  set_cfgs         None
2025-07-12 11:38:54,373   INFO  max_waiting_mins 0
2025-07-12 11:38:54,373   INFO  start_epoch      0
2025-07-12 11:38:54,373   INFO  num_epochs_to_eval 5
2025-07-12 11:38:54,373   INFO  save_to_file     False
2025-07-12 11:38:54,373   INFO  use_tqdm_to_record False
2025-07-12 11:38:54,373   INFO  logger_iter_interval 50
2025-07-12 11:38:54,373   INFO  ckpt_save_time_interval 300
2025-07-12 11:38:54,373   INFO  wo_gpu_stat      True
2025-07-12 11:38:54,373   INFO  use_amp          False
2025-07-12 11:38:54,373   INFO  cfg.ROOT_DIR: /root/autodl-tmp/OpenPCDet
2025-07-12 11:38:54,373   INFO  cfg.LOCAL_RANK: 0
2025-07-12 11:38:54,373   INFO  cfg.CLASS_NAMES: ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']
2025-07-12 11:38:54,373   INFO  ----------- DATA_CONFIG -----------
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.DATASET: NuScenesDataset
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/nuscenes
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.VERSION: v1.0-mini
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.MAX_SWEEPS: 10
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.PRED_VELOCITY: True
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.SET_NAN_VELOCITY_TO_ZEROS: True
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT: 1
2025-07-12 11:38:54,373   INFO  ----------- DATA_SPLIT -----------
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2025-07-12 11:38:54,373   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2025-07-12 11:38:54,373   INFO  ----------- INFO_PATH -----------
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['nuscenes_infos_10sweeps_train.pkl']
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['nuscenes_infos_10sweeps_val.pkl']
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.BALANCED_RESAMPLING: True
2025-07-12 11:38:54,374   INFO  ----------- DATA_AUGMENTOR -----------
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'DB_INFO_PATH': ['nuscenes_dbinfos_10sweeps_withvelo.pkl'], 'USE_SHARED_MEMORY': False, 'DB_DATA_PATH': ['nuscenes_dbinfos_10sweeps_withvelo_global.pkl.npy'], 'PREPARE': {'filter_by_min_points': ['car:5', 'truck:5', 'construction_vehicle:5', 'bus:5', 'trailer:5', 'barrier:5', 'motorcycle:5', 'bicycle:5', 'pedestrian:5', 'traffic_cone:5']}, 'SAMPLE_GROUPS': ['car:2', 'truck:2', 'construction_vehicle:2', 'bus:2', 'trailer:2', 'barrier:2', 'motorcycle:2', 'bicycle:2', 'pedestrian:2', 'traffic_cone:2'], 'NUM_POINT_FEATURES': 5, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.9, 1.1]}, {'NAME': 'random_world_translation', 'NOISE_TRANSLATE_STD': [0.5, 0.5, 0.5]}]
2025-07-12 11:38:54,374   INFO  ----------- POINT_FEATURE_ENCODING -----------
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': True}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.075, 0.075, 0.2], 'MAX_POINTS_PER_VOXEL': 10, 'MAX_NUMBER_OF_VOXELS': {'train': 120000, 'test': 160000}}]
2025-07-12 11:38:54,374   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/nuscenes_dataset.yaml
2025-07-12 11:38:54,374   INFO  ----------- MODEL -----------
2025-07-12 11:38:54,374   INFO  cfg.MODEL.NAME: VoxelNeXt
2025-07-12 11:38:54,374   INFO  ----------- VFE -----------
2025-07-12 11:38:54,374   INFO  cfg.MODEL.VFE.NAME: MeanVFE
2025-07-12 11:38:54,374   INFO  ----------- BACKBONE_3D -----------
2025-07-12 11:38:54,374   INFO  cfg.MODEL.BACKBONE_3D.NAME: VoxelResBackBone8xVoxelNeXt
2025-07-12 11:38:54,374   INFO  ----------- DENSE_HEAD -----------
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.NAME: VoxelNeXtHead
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.INPUT_FEATURES: 128
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.CLASS_NAMES_EACH_HEAD: [['car'], ['truck', 'construction_vehicle'], ['bus', 'trailer'], ['barrier'], ['motorcycle', 'bicycle'], ['pedestrian', 'traffic_cone']]
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.SHARED_CONV_CHANNEL: 128
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.KERNEL_SIZE_HEAD: 1
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.USE_BIAS_BEFORE_NORM: True
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.NUM_HM_CONV: 2
2025-07-12 11:38:54,374   INFO  ----------- SEPARATE_HEAD_CFG -----------
2025-07-12 11:38:54,374   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_ORDER: ['center', 'center_z', 'dim', 'rot', 'vel']
2025-07-12 11:38:54,374   INFO  ----------- HEAD_DICT -----------
2025-07-12 11:38:54,375   INFO  ----------- center -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.out_channels: 2
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.num_conv: 2
2025-07-12 11:38:54,375   INFO  ----------- center_z -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center_z.out_channels: 1
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center_z.num_conv: 2
2025-07-12 11:38:54,375   INFO  ----------- dim -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.out_channels: 3
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.num_conv: 2
2025-07-12 11:38:54,375   INFO  ----------- rot -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.out_channels: 2
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.num_conv: 2
2025-07-12 11:38:54,375   INFO  ----------- vel -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.out_channels: 2
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.num_conv: 2
2025-07-12 11:38:54,375   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.FEATURE_MAP_STRIDE: 8
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NUM_MAX_OBJS: 500
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.GAUSSIAN_OVERLAP: 0.1
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MIN_RADIUS: 2
2025-07-12 11:38:54,375   INFO  ----------- LOSS_CONFIG -----------
2025-07-12 11:38:54,375   INFO  ----------- LOSS_WEIGHTS -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 0.25
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0, 1.0]
2025-07-12 11:38:54,375   INFO  ----------- POST_PROCESSING -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.SCORE_THRESH: 0.1
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.POST_CENTER_LIMIT_RANGE: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.MAX_OBJ_PER_SAMPLE: 500
2025-07-12 11:38:54,375   INFO  ----------- NMS_CONFIG -----------
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.2
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 1000
2025-07-12 11:38:54,375   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 83
2025-07-12 11:38:54,376   INFO  ----------- POST_PROCESSING -----------
2025-07-12 11:38:54,376   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2025-07-12 11:38:54,376   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2025-07-12 11:38:54,376   INFO  ----------- OPTIMIZATION -----------
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 20
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.LR: 0.003
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2025-07-12 11:38:54,376   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2025-07-12 11:38:54,376   INFO  cfg.TAG: cbgs_voxel0075_voxelnext
2025-07-12 11:38:54,376   INFO  cfg.EXP_GROUP_PATH: cfgs/nuscenes_models
2025-07-12 11:38:54,383   INFO  ----------- Create dataloader & network & optimizer -----------
2025-07-12 11:38:54,433   INFO  Database filter by min points car: 4082 => 3303
2025-07-12 11:38:54,433   INFO  Database filter by min points truck: 451 => 412
2025-07-12 11:38:54,433   INFO  Database filter by min points construction_vehicle: 174 => 161
2025-07-12 11:38:54,433   INFO  Database filter by min points bus: 337 => 309
2025-07-12 11:38:54,433   INFO  Database filter by min points trailer: 59 => 57
2025-07-12 11:38:54,434   INFO  Database filter by min points barrier: 1851 => 1741
2025-07-12 11:38:54,434   INFO  Database filter by min points motorcycle: 179 => 149
2025-07-12 11:38:54,434   INFO  Database filter by min points bicycle: 147 => 136
2025-07-12 11:38:54,434   INFO  Database filter by min points pedestrian: 3068 => 2799
2025-07-12 11:38:54,434   INFO  Database filter by min points traffic_cone: 773 => 635
2025-07-12 11:38:54,435   INFO  Loading NuScenes dataset
2025-07-12 11:38:54,456   INFO  Total samples for NuScenes dataset: 323
2025-07-12 11:38:54,460   INFO  Total samples after balanced resampling: 1630
2025-07-12 11:38:56,196   INFO  ==> Loading parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_24.pth to GPU
2025-07-12 11:38:56,317   INFO  ==> Loading optimizer parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_24.pth to GPU
2025-07-12 11:38:56,346   INFO  ==> Done
2025-07-12 11:38:56,350   INFO  ----------- Model VoxelNeXt created, param count: 7981398 -----------
2025-07-12 11:38:56,350   INFO  VoxelNeXt(
  (vfe): MeanVFE()
  (backbone_3d): VoxelResBackBone8xVoxelNeXt(
    (conv_input): SparseSequential(
      (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv1): SparseSequential(
      (0): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv2): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv3): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv4): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv5): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv6): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (shared_conv): SparseSequential(
      (0): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (map_to_bev_module): None
  (pfe): None
  (backbone_2d): None
  (dense_head): VoxelNeXtHead(
    (heads_list): ModuleList(
      (0): SeparateHead(
        (center): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (center_z): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (dim): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 3, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (rot): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (vel): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (hm): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
      )
      (1): SeparateHead(
        (center): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (center_z): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (dim): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 3, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (rot): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (vel): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (hm): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
      )
      (2): SeparateHead(
        (center): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (center_z): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (dim): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 3, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (rot): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (vel): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (hm): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
      )
      (3): SeparateHead(
        (center): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (center_z): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (dim): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 3, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (rot): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (vel): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (hm): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
      )
      (4): SeparateHead(
        (center): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (center_z): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (dim): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 3, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (rot): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (vel): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (hm): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
      )
      (5): SeparateHead(
        (center): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (center_z): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 1, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (dim): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 3, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (rot): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (vel): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
        (hm): Sequential(
          (0): SparseSequential(
            (0): SubMConv2d(128, 128, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): SubMConv2d(128, 2, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        )
      )
    )
    (hm_loss_func): FocalLossSparse()
    (reg_loss_func): RegLossSparse()
  )
  (point_head): None
  (roi_head): None
)
2025-07-12 11:38:56,355   INFO  **********************Start training cfgs/nuscenes_models/cbgs_voxel0075_voxelnext(default)**********************
2025-07-12 11:39:12,533   INFO  Train:   25/100 ( 25%) [   0/408 (  0%)]  Loss: 4.940 (4.94)  LR: 2.067e-03  Time cost: 00:15/1:43:25 [00:16/131:00:27]  Acc_iter 9793        Data time: 4.33(4.33)  Forward time: 10.88(10.88)  Batch time: 15.21(15.21)
2025-07-12 11:39:16,092   INFO  Train:   25/100 ( 25%) [   7/408 (  2%)]  Loss: 5.829 (5.77)  LR: 2.069e-03  Time cost: 00:18/15:40 [00:19/20:12:12]  Acc_iter 9800        Data time: 0.00(0.54)  Forward time: 0.35(1.80)  Batch time: 0.36(2.35)
2025-07-12 11:39:42,273   INFO  Train:   25/100 ( 25%) [  57/408 ( 14%)]  Loss: 7.564 (5.81)  LR: 2.081e-03  Time cost: 00:44/04:32 [00:45/6:39:46]  Acc_iter 9850        Data time: 0.00(0.08)  Forward time: 0.61(0.70)  Batch time: 0.61(0.77)
2025-07-12 11:40:07,800   INFO  Train:   25/100 ( 25%) [ 107/408 ( 26%)]  Loss: 5.733 (5.83)  LR: 2.094e-03  Time cost: 01:10/03:16 [01:11/5:36:04]  Acc_iter 9900        Data time: 0.00(0.04)  Forward time: 0.68(0.61)  Batch time: 0.68(0.65)
2025-07-12 11:40:33,053   INFO  Train:   25/100 ( 25%) [ 157/408 ( 38%)]  Loss: 5.221 (5.76)  LR: 2.106e-03  Time cost: 01:35/02:32 [01:36/5:11:32]  Acc_iter 9950        Data time: 0.01(0.03)  Forward time: 0.73(0.57)  Batch time: 0.74(0.61)
2025-07-12 11:40:58,507   INFO  Train:   25/100 ( 25%) [ 207/408 ( 51%)]  Loss: 6.625 (5.75)  LR: 2.118e-03  Time cost: 02:01/01:57 [02:02/4:59:05]  Acc_iter 10000       Data time: 0.00(0.02)  Forward time: 0.64(0.56)  Batch time: 0.64(0.58)
2025-07-12 11:41:24,385   INFO  Train:   25/100 ( 25%) [ 257/408 ( 63%)]  Loss: 5.133 (5.76)  LR: 2.130e-03  Time cost: 02:27/01:26 [02:28/4:52:08]  Acc_iter 10050       Data time: 0.00(0.02)  Forward time: 0.82(0.55)  Batch time: 0.82(0.57)
2025-07-12 11:41:49,730   INFO  Train:   25/100 ( 25%) [ 307/408 ( 75%)]  Loss: 5.157 (5.76)  LR: 2.142e-03  Time cost: 02:52/00:56 [02:53/4:46:25]  Acc_iter 10100       Data time: 0.00(0.02)  Forward time: 0.36(0.54)  Batch time: 0.36(0.56)
2025-07-12 11:42:15,245   INFO  Train:   25/100 ( 25%) [ 357/408 ( 88%)]  Loss: 4.839 (5.76)  LR: 2.154e-03  Time cost: 03:17/00:28 [03:18/4:42:25]  Acc_iter 10150       Data time: 0.00(0.02)  Forward time: 0.63(0.54)  Batch time: 0.63(0.55)
2025-07-12 11:42:39,008   INFO  Train:   25/100 ( 25%) [ 407/408 (100%)]  Loss: 7.516 (5.74)  LR: 2.166e-03  Time cost: 03:41/00:00 [03:42/4:37:06]  Acc_iter 10200       Data time: 0.00(0.01)  Forward time: 0.15(0.53)  Batch time: 0.15(0.54)
2025-07-12 11:42:43,691   INFO  Train:   26/100 ( 26%) [   0/408 (  0%)]  Loss: 6.538 (6.54)  LR: 2.167e-03  Time cost: 00:04/27:49 [03:47/34:47:16]  Acc_iter 10201       Data time: 3.40(3.40)  Forward time: 0.69(0.69)  Batch time: 4.09(4.09)
2025-07-12 11:43:09,170   INFO  Train:   26/100 ( 26%) [  49/408 ( 12%)]  Loss: 5.168 (5.91)  LR: 2.178e-03  Time cost: 00:29/03:32 [04:12/5:01:08]  Acc_iter 10250       Data time: 0.00(0.07)  Forward time: 0.65(0.52)  Batch time: 0.65(0.59)
2025-07-12 11:43:34,589   INFO  Train:   26/100 ( 26%) [  99/408 ( 24%)]  Loss: 6.858 (5.77)  LR: 2.190e-03  Time cost: 00:54/02:49 [04:38/4:39:32]  Acc_iter 10300       Data time: 0.00(0.04)  Forward time: 0.44(0.51)  Batch time: 0.45(0.55)
2025-07-12 11:44:00,693   INFO  Train:   26/100 ( 26%) [ 149/408 ( 37%)]  Loss: 4.180 (5.65)  LR: 2.202e-03  Time cost: 01:21/02:20 [05:04/4:34:22]  Acc_iter 10350       Data time: 0.00(0.03)  Forward time: 0.61(0.51)  Batch time: 0.61(0.54)
2025-07-12 11:44:26,236   INFO  Train:   26/100 ( 26%) [ 199/408 ( 49%)]  Loss: 5.274 (5.66)  LR: 2.214e-03  Time cost: 01:46/01:51 [05:29/4:30:09]  Acc_iter 10400       Data time: 0.00(0.02)  Forward time: 0.72(0.51)  Batch time: 0.72(0.53)
2025-07-12 11:44:51,922   INFO  Train:   26/100 ( 26%) [ 249/408 ( 61%)]  Loss: 7.288 (5.63)  LR: 2.226e-03  Time cost: 02:12/01:24 [05:55/4:27:44]  Acc_iter 10450       Data time: 0.00(0.02)  Forward time: 0.35(0.51)  Batch time: 0.35(0.53)
2025-07-12 11:45:17,686   INFO  Train:   26/100 ( 26%) [ 299/408 ( 73%)]  Loss: 5.590 (5.64)  LR: 2.238e-03  Time cost: 02:38/00:57 [06:21/4:26:07]  Acc_iter 10500       Data time: 0.00(0.02)  Forward time: 0.73(0.51)  Batch time: 0.73(0.53)
2025-07-12 11:45:43,010   INFO  Train:   26/100 ( 26%) [ 349/408 ( 86%)]  Loss: 3.629 (5.65)  LR: 2.249e-03  Time cost: 03:03/00:30 [06:46/4:24:12]  Acc_iter 10550       Data time: 0.00(0.01)  Forward time: 0.56(0.51)  Batch time: 0.56(0.52)
2025-07-12 11:46:08,359   INFO  Train:   26/100 ( 26%) [ 399/408 ( 98%)]  Loss: 6.091 (5.67)  LR: 2.261e-03  Time cost: 03:28/00:04 [07:12/4:22:42]  Acc_iter 10600       Data time: 0.00(0.01)  Forward time: 0.27(0.51)  Batch time: 0.28(0.52)
2025-07-12 11:46:10,316   INFO  Train:   26/100 ( 26%) [ 407/408 (100%)]  Loss: 3.578 (5.67)  LR: 2.263e-03  Time cost: 03:30/00:00 [07:13/4:19:53]  Acc_iter 10608       Data time: 0.00(0.01)  Forward time: 0.12(0.50)  Batch time: 0.13(0.52)
2025-07-12 11:46:14,952   INFO  Train:   27/100 ( 27%) [   0/408 (  0%)]  Loss: 5.628 (5.63)  LR: 2.263e-03  Time cost: 00:03/26:26 [07:18/32:36:54]  Acc_iter 10609       Data time: 3.10(3.10)  Forward time: 0.79(0.79)  Batch time: 3.89(3.89)
2025-07-12 11:46:36,368   INFO  Train:   27/100 ( 27%) [  41/408 ( 10%)]  Loss: 4.404 (5.50)  LR: 2.272e-03  Time cost: 00:25/03:41 [07:40/5:02:45]  Acc_iter 10650       Data time: 0.00(0.08)  Forward time: 0.57(0.53)  Batch time: 0.57(0.60)
2025-07-12 11:47:01,977   INFO  Train:   27/100 ( 27%) [  91/408 ( 22%)]  Loss: 5.721 (5.51)  LR: 2.284e-03  Time cost: 00:50/02:55 [08:05/4:37:38]  Acc_iter 10700       Data time: 0.00(0.04)  Forward time: 0.60(0.52)  Batch time: 0.61(0.55)
2025-07-12 11:47:27,763   INFO  Train:   27/100 ( 27%) [ 141/408 ( 35%)]  Loss: 5.219 (5.52)  LR: 2.295e-03  Time cost: 01:16/02:24 [08:31/4:30:31]  Acc_iter 10750       Data time: 0.00(0.03)  Forward time: 0.37(0.51)  Batch time: 0.37(0.54)
2025-07-12 11:47:53,353   INFO  Train:   27/100 ( 27%) [ 191/408 ( 47%)]  Loss: 6.064 (5.54)  LR: 2.307e-03  Time cost: 01:42/01:55 [08:56/4:26:23]  Acc_iter 10800       Data time: 0.00(0.02)  Forward time: 0.43(0.51)  Batch time: 0.44(0.53)
2025-07-12 11:48:19,165   INFO  Train:   27/100 ( 27%) [ 241/408 ( 59%)]  Loss: 6.725 (5.52)  LR: 2.318e-03  Time cost: 02:08/01:28 [09:22/4:24:14]  Acc_iter 10850       Data time: 0.00(0.02)  Forward time: 0.43(0.51)  Batch time: 0.44(0.53)
2025-07-12 11:48:44,146   INFO  Train:   27/100 ( 27%) [ 291/408 ( 71%)]  Loss: 5.289 (5.49)  LR: 2.329e-03  Time cost: 02:33/01:01 [09:47/4:21:15]  Acc_iter 10900       Data time: 0.00(0.01)  Forward time: 0.48(0.51)  Batch time: 0.49(0.52)
2025-07-12 11:49:09,297   INFO  Train:   27/100 ( 27%) [ 341/408 ( 84%)]  Loss: 4.973 (5.50)  LR: 2.340e-03  Time cost: 02:58/00:34 [10:12/4:19:16]  Acc_iter 10950       Data time: 0.00(0.01)  Forward time: 0.44(0.51)  Batch time: 0.44(0.52)
2025-07-12 11:49:34,214   INFO  Train:   27/100 ( 27%) [ 391/408 ( 96%)]  Loss: 6.683 (5.51)  LR: 2.352e-03  Time cost: 03:23/00:08 [10:37/4:17:24]  Acc_iter 11000       Data time: 0.00(0.01)  Forward time: 0.62(0.51)  Batch time: 0.62(0.52)
2025-07-12 11:49:40,085   INFO  Train:   27/100 ( 27%) [ 407/408 (100%)]  Loss: 4.642 (5.52)  LR: 2.355e-03  Time cost: 03:29/00:00 [10:43/4:14:19]  Acc_iter 11016       Data time: 0.00(0.01)  Forward time: 0.18(0.50)  Batch time: 0.19(0.51)
2025-07-12 11:49:45,039   INFO  Train:   28/100 ( 28%) [   0/408 (  0%)]  Loss: 5.077 (5.08)  LR: 2.355e-03  Time cost: 00:04/28:14 [10:48/34:21:24]  Acc_iter 11017       Data time: 3.20(3.20)  Forward time: 0.95(0.95)  Batch time: 4.15(4.15)
2025-07-12 11:50:01,684   INFO  Train:   28/100 ( 28%) [  33/408 (  8%)]  Loss: 5.663 (5.42)  LR: 2.363e-03  Time cost: 00:20/03:49 [11:05/5:03:18]  Acc_iter 11050       Data time: 0.00(0.10)  Forward time: 0.84(0.51)  Batch time: 0.84(0.61)
2025-07-12 11:50:26,899   INFO  Train:   28/100 ( 28%) [  83/408 ( 20%)]  Loss: 4.949 (5.45)  LR: 2.374e-03  Time cost: 00:46/02:58 [11:30/4:31:09]  Acc_iter 11100       Data time: 0.00(0.04)  Forward time: 0.62(0.51)  Batch time: 0.62(0.55)
2025-07-12 11:50:51,666   INFO  Train:   28/100 ( 28%) [ 133/408 ( 33%)]  Loss: 7.392 (5.55)  LR: 2.385e-03  Time cost: 01:10/02:25 [11:55/4:21:01]  Acc_iter 11150       Data time: 0.00(0.03)  Forward time: 0.36(0.50)  Batch time: 0.37(0.53)
2025-07-12 11:51:17,265   INFO  Train:   28/100 ( 28%) [ 183/408 ( 45%)]  Loss: 8.062 (5.54)  LR: 2.395e-03  Time cost: 01:36/01:57 [12:20/4:18:25]  Acc_iter 11200       Data time: 0.00(0.02)  Forward time: 0.56(0.50)  Batch time: 0.56(0.52)
2025-07-12 11:51:42,645   INFO  Train:   28/100 ( 28%) [ 233/408 ( 57%)]  Loss: 5.225 (5.48)  LR: 2.406e-03  Time cost: 02:01/01:31 [12:46/4:16:16]  Acc_iter 11250       Data time: 0.00(0.02)  Forward time: 0.33(0.50)  Batch time: 0.33(0.52)
2025-07-12 11:52:07,051   INFO  Train:   28/100 ( 28%) [ 283/408 ( 69%)]  Loss: 5.015 (5.48)  LR: 2.417e-03  Time cost: 02:26/01:04 [13:10/4:13:03]  Acc_iter 11300       Data time: 0.00(0.02)  Forward time: 0.30(0.50)  Batch time: 0.30(0.51)
2025-07-12 11:52:32,122   INFO  Train:   28/100 ( 28%) [ 333/408 ( 82%)]  Loss: 6.103 (5.48)  LR: 2.428e-03  Time cost: 02:51/00:38 [13:35/4:11:39]  Acc_iter 11350       Data time: 0.00(0.01)  Forward time: 0.50(0.50)  Batch time: 0.51(0.51)
2025-07-12 11:52:56,787   INFO  Train:   28/100 ( 28%) [ 383/408 ( 94%)]  Loss: 4.583 (5.46)  LR: 2.438e-03  Time cost: 03:15/00:12 [14:00/4:09:59]  Acc_iter 11400       Data time: 0.00(0.01)  Forward time: 0.38(0.50)  Batch time: 0.38(0.51)
2025-07-12 11:53:06,820   INFO  Train:   28/100 ( 28%) [ 407/408 (100%)]  Loss: 4.048 (5.44)  LR: 2.443e-03  Time cost: 03:25/00:00 [14:10/4:07:07]  Acc_iter 11424       Data time: 0.00(0.01)  Forward time: 0.17(0.49)  Batch time: 0.17(0.50)
2025-07-12 11:53:11,411   INFO  Train:   29/100 ( 29%) [   0/408 (  0%)]  Loss: 8.195 (8.20)  LR: 2.444e-03  Time cost: 00:03/25:40 [14:15/30:49:10]  Acc_iter 11425       Data time: 2.97(2.97)  Forward time: 0.81(0.81)  Batch time: 3.78(3.78)
2025-07-12 11:53:23,679   INFO  Train:   29/100 ( 29%) [  25/408 (  6%)]  Loss: 5.852 (5.32)  LR: 2.449e-03  Time cost: 00:16/03:56 [14:27/5:01:52]  Acc_iter 11450       Data time: 0.00(0.12)  Forward time: 0.30(0.50)  Batch time: 0.31(0.62)
2025-07-12 11:53:48,673   INFO  Train:   29/100 ( 29%) [  75/408 ( 18%)]  Loss: 4.772 (5.23)  LR: 2.459e-03  Time cost: 00:41/02:59 [14:52/4:23:41]  Acc_iter 11500       Data time: 0.00(0.04)  Forward time: 0.60(0.50)  Batch time: 0.61(0.54)
2025-07-12 11:54:15,310   INFO  Train:   29/100 ( 29%) [ 125/408 ( 31%)]  Loss: 5.917 (5.26)  LR: 2.470e-03  Time cost: 01:07/02:32 [15:18/4:21:50]  Acc_iter 11550       Data time: 0.00(0.03)  Forward time: 0.47(0.51)  Batch time: 0.47(0.54)
2025-07-12 11:54:41,010   INFO  Train:   29/100 ( 29%) [ 175/408 ( 43%)]  Loss: 5.280 (5.25)  LR: 2.480e-03  Time cost: 01:33/02:03 [15:44/4:18:12]  Acc_iter 11600       Data time: 0.00(0.02)  Forward time: 0.61(0.51)  Batch time: 0.61(0.53)
2025-07-12 11:55:05,936   INFO  Train:   29/100 ( 29%) [ 225/408 ( 55%)]  Loss: 7.034 (5.23)  LR: 2.490e-03  Time cost: 01:58/01:35 [16:09/4:14:19]  Acc_iter 11650       Data time: 0.00(0.02)  Forward time: 0.50(0.51)  Batch time: 0.51(0.52)
2025-07-12 11:55:31,654   INFO  Train:   29/100 ( 29%) [ 275/408 ( 67%)]  Loss: 5.156 (5.26)  LR: 2.500e-03  Time cost: 02:24/01:09 [16:35/4:13:05]  Acc_iter 11700       Data time: 0.00(0.01)  Forward time: 0.35(0.51)  Batch time: 0.35(0.52)
2025-07-12 11:55:57,000   INFO  Train:   29/100 ( 29%) [ 325/408 ( 80%)]  Loss: 5.557 (5.25)  LR: 2.510e-03  Time cost: 02:49/00:43 [17:00/4:11:32]  Acc_iter 11750       Data time: 0.00(0.01)  Forward time: 0.63(0.51)  Batch time: 0.63(0.52)
2025-07-12 11:56:22,255   INFO  Train:   29/100 ( 29%) [ 375/408 ( 92%)]  Loss: 4.041 (5.27)  LR: 2.520e-03  Time cost: 03:14/00:17 [17:25/4:10:11]  Acc_iter 11800       Data time: 0.00(0.01)  Forward time: 0.56(0.51)  Batch time: 0.57(0.52)
2025-07-12 11:56:36,536   INFO  Train:   29/100 ( 29%) [ 407/408 (100%)]  Loss: 4.202 (5.25)  LR: 2.527e-03  Time cost: 03:28/00:00 [17:40/4:07:12]  Acc_iter 11832       Data time: 0.00(0.01)  Forward time: 0.12(0.50)  Batch time: 0.12(0.51)
2025-07-12 11:56:40,602   INFO  Train:   30/100 ( 30%) [   0/408 (  0%)]  Loss: 6.878 (6.88)  LR: 2.527e-03  Time cost: 00:03/22:47 [17:44/26:57:44]  Acc_iter 11833       Data time: 2.70(2.70)  Forward time: 0.65(0.65)  Batch time: 3.35(3.35)
2025-07-12 11:56:49,827   INFO  Train:   30/100 ( 30%) [  17/408 (  4%)]  Loss: 6.631 (5.94)  LR: 2.530e-03  Time cost: 00:12/04:33 [17:53/5:37:06]  Acc_iter 11850       Data time: 0.00(0.15)  Forward time: 0.86(0.54)  Batch time: 0.86(0.70)
2025-07-12 11:57:14,940   INFO  Train:   30/100 ( 30%) [  67/408 ( 16%)]  Loss: 4.795 (5.54)  LR: 2.540e-03  Time cost: 00:37/03:08 [18:18/4:26:58]  Acc_iter 11900       Data time: 0.00(0.04)  Forward time: 0.72(0.51)  Batch time: 0.72(0.55)
2025-07-12 11:57:40,058   INFO  Train:   30/100 ( 30%) [ 117/408 ( 29%)]  Loss: 4.437 (5.41)  LR: 2.550e-03  Time cost: 01:02/02:34 [18:43/4:15:56]  Acc_iter 11950       Data time: 0.00(0.03)  Forward time: 0.29(0.51)  Batch time: 0.29(0.53)
2025-07-12 11:58:05,289   INFO  Train:   30/100 ( 30%) [ 167/408 ( 41%)]  Loss: 5.335 (5.37)  LR: 2.559e-03  Time cost: 01:28/02:06 [19:08/4:11:32]  Acc_iter 12000       Data time: 0.00(0.02)  Forward time: 0.32(0.50)  Batch time: 0.32(0.52)
2025-07-12 11:58:30,751   INFO  Train:   30/100 ( 30%) [ 217/408 ( 53%)]  Loss: 4.144 (5.29)  LR: 2.569e-03  Time cost: 01:53/01:39 [19:34/4:09:28]  Acc_iter 12050       Data time: 0.00(0.02)  Forward time: 0.46(0.50)  Batch time: 0.46(0.52)
2025-07-12 11:58:56,844   INFO  Train:   30/100 ( 30%) [ 267/408 ( 65%)]  Loss: 6.483 (5.27)  LR: 2.578e-03  Time cost: 02:19/01:13 [20:00/4:09:09]  Acc_iter 12100       Data time: 0.00(0.01)  Forward time: 0.38(0.51)  Batch time: 0.38(0.52)
2025-07-12 11:59:22,287   INFO  Train:   30/100 ( 30%) [ 317/408 ( 78%)]  Loss: 4.730 (5.23)  LR: 2.588e-03  Time cost: 02:45/00:47 [20:25/4:07:49]  Acc_iter 12150       Data time: 0.00(0.01)  Forward time: 0.53(0.51)  Batch time: 0.53(0.52)
2025-07-12 11:59:47,583   INFO  Train:   30/100 ( 30%) [ 367/408 ( 90%)]  Loss: 5.985 (5.20)  LR: 2.597e-03  Time cost: 03:10/00:21 [20:51/4:06:32]  Acc_iter 12200       Data time: 0.00(0.01)  Forward time: 0.59(0.51)  Batch time: 0.59(0.52)
2025-07-12 12:00:05,346   INFO  Train:   30/100 ( 30%) [ 407/408 (100%)]  Loss: 4.179 (5.19)  LR: 2.604e-03  Time cost: 03:28/00:00 [21:08/4:02:47]  Acc_iter 12240       Data time: 0.00(0.01)  Forward time: 0.17(0.50)  Batch time: 0.17(0.51)
2025-07-12 12:00:10,467   INFO  Train:   31/100 ( 31%) [   0/408 (  0%)]  Loss: 5.046 (5.05)  LR: 2.605e-03  Time cost: 00:04/29:01 [21:14/33:52:04]  Acc_iter 12241       Data time: 3.10(3.10)  Forward time: 1.17(1.17)  Batch time: 4.27(4.27)
2025-07-12 12:00:14,870   INFO  Train:   31/100 ( 31%) [   9/408 (  2%)]  Loss: 5.305 (4.90)  LR: 2.606e-03  Time cost: 00:08/05:46 [21:18/6:52:39]  Acc_iter 12250       Data time: 0.00(0.31)  Forward time: 0.73(0.55)  Batch time: 0.73(0.87)
2025-07-12 12:00:40,263   INFO  Train:   31/100 ( 31%) [  59/408 ( 14%)]  Loss: 5.219 (5.05)  LR: 2.615e-03  Time cost: 00:34/03:18 [21:43/4:29:41]  Acc_iter 12300       Data time: 0.00(0.06)  Forward time: 0.64(0.51)  Batch time: 0.64(0.57)
2025-07-12 12:01:05,896   INFO  Train:   31/100 ( 31%) [ 109/408 ( 27%)]  Loss: 4.787 (5.25)  LR: 2.624e-03  Time cost: 00:59/02:42 [22:09/4:17:20]  Acc_iter 12350       Data time: 0.00(0.03)  Forward time: 0.67(0.51)  Batch time: 0.67(0.54)
2025-07-12 12:01:30,764   INFO  Train:   31/100 ( 31%) [ 159/408 ( 39%)]  Loss: 3.573 (5.15)  LR: 2.633e-03  Time cost: 01:24/02:11 [22:34/4:10:11]  Acc_iter 12400       Data time: 0.00(0.02)  Forward time: 0.46(0.51)  Batch time: 0.46(0.53)
2025-07-12 12:01:56,242   INFO  Train:   31/100 ( 31%) [ 209/408 ( 51%)]  Loss: 5.069 (5.14)  LR: 2.642e-03  Time cost: 01:50/01:44 [22:59/4:07:36]  Acc_iter 12450       Data time: 0.00(0.02)  Forward time: 0.46(0.51)  Batch time: 0.46(0.52)
2025-07-12 12:02:21,322   INFO  Train:   31/100 ( 31%) [ 259/408 ( 63%)]  Loss: 4.156 (5.11)  LR: 2.651e-03  Time cost: 02:15/01:17 [23:24/4:05:08]  Acc_iter 12500       Data time: 0.00(0.02)  Forward time: 0.40(0.50)  Batch time: 0.41(0.52)
2025-07-12 12:02:45,575   INFO  Train:   31/100 ( 31%) [ 309/408 ( 76%)]  Loss: 4.171 (5.13)  LR: 2.660e-03  Time cost: 02:39/00:50 [23:49/4:02:04]  Acc_iter 12550       Data time: 0.00(0.01)  Forward time: 0.50(0.50)  Batch time: 0.51(0.51)
2025-07-12 12:03:10,917   INFO  Train:   31/100 ( 31%) [ 359/408 ( 88%)]  Loss: 5.794 (5.12)  LR: 2.668e-03  Time cost: 03:04/00:25 [24:14/4:01:10]  Acc_iter 12600       Data time: 0.00(0.01)  Forward time: 0.52(0.50)  Batch time: 0.52(0.51)
2025-07-12 12:03:32,668   INFO  Train:   31/100 ( 31%) [ 407/408 (100%)]  Loss: 4.640 (5.10)  LR: 2.676e-03  Time cost: 03:26/00:00 [24:36/3:57:26]  Acc_iter 12648       Data time: 0.00(0.01)  Forward time: 0.14(0.49)  Batch time: 0.14(0.51)
2025-07-12 12:03:36,907   INFO  Train:   32/100 ( 32%) [   0/408 (  0%)]  Loss: 5.225 (5.22)  LR: 2.677e-03  Time cost: 00:03/24:25 [24:40/28:05:12]  Acc_iter 12649       Data time: 2.45(2.45)  Forward time: 1.14(1.14)  Batch time: 3.59(3.59)
2025-07-12 12:03:37,695   INFO  Train:   32/100 ( 32%) [   1/408 (  0%)]  Loss: 4.782 (5.00)  LR: 2.677e-03  Time cost: 00:04/14:51 [24:41/17:07:29]  Acc_iter 12650       Data time: 0.00(1.23)  Forward time: 0.78(0.96)  Batch time: 0.79(2.19)
2025-07-12 12:04:02,792   INFO  Train:   32/100 ( 32%) [  51/408 ( 12%)]  Loss: 6.054 (4.94)  LR: 2.685e-03  Time cost: 00:29/03:22 [25:06/4:25:29]  Acc_iter 12700       Data time: 0.00(0.05)  Forward time: 0.42(0.51)  Batch time: 0.43(0.57)
2025-07-12 12:04:27,954   INFO  Train:   32/100 ( 32%) [ 101/408 ( 25%)]  Loss: 5.039 (4.99)  LR: 2.693e-03  Time cost: 00:54/02:44 [25:31/4:10:26]  Acc_iter 12750       Data time: 0.00(0.03)  Forward time: 0.40(0.51)  Batch time: 0.40(0.54)
2025-07-12 12:04:53,506   INFO  Train:   32/100 ( 32%) [ 151/408 ( 37%)]  Loss: 4.684 (4.96)  LR: 2.702e-03  Time cost: 01:20/02:15 [25:57/4:06:12]  Acc_iter 12800       Data time: 0.00(0.02)  Forward time: 0.54(0.51)  Batch time: 0.54(0.53)
2025-07-12 12:05:19,017   INFO  Train:   32/100 ( 32%) [ 201/408 ( 49%)]  Loss: 3.823 (5.02)  LR: 2.710e-03  Time cost: 01:45/01:48 [26:22/4:03:46]  Acc_iter 12850       Data time: 0.00(0.02)  Forward time: 0.43(0.51)  Batch time: 0.43(0.52)
2025-07-12 12:05:44,447   INFO  Train:   32/100 ( 32%) [ 251/408 ( 62%)]  Loss: 5.107 (5.06)  LR: 2.718e-03  Time cost: 02:11/01:21 [26:48/4:01:58]  Acc_iter 12900       Data time: 0.00(0.01)  Forward time: 0.52(0.51)  Batch time: 0.52(0.52)
2025-07-12 12:06:09,642   INFO  Train:   32/100 ( 32%) [ 301/408 ( 74%)]  Loss: 4.930 (5.00)  LR: 2.726e-03  Time cost: 02:36/00:55 [27:13/4:00:16]  Acc_iter 12950       Data time: 0.00(0.01)  Forward time: 0.42(0.51)  Batch time: 0.43(0.52)
2025-07-12 12:06:34,497   INFO  Train:   32/100 ( 32%) [ 351/408 ( 86%)]  Loss: 5.476 (5.03)  LR: 2.733e-03  Time cost: 03:01/00:29 [27:38/3:58:29]  Acc_iter 13000       Data time: 0.00(0.01)  Forward time: 0.44(0.50)  Batch time: 0.45(0.51)
2025-07-12 12:06:58,942   INFO  Train:   32/100 ( 32%) [ 401/408 ( 98%)]  Loss: 4.005 (5.00)  LR: 2.741e-03  Time cost: 03:25/00:03 [28:02/3:56:34]  Acc_iter 13050       Data time: 0.00(0.01)  Forward time: 0.30(0.50)  Batch time: 0.30(0.51)
2025-07-12 12:07:00,387   INFO  Train:   32/100 ( 32%) [ 407/408 (100%)]  Loss: 4.126 (4.99)  LR: 2.742e-03  Time cost: 03:27/00:00 [28:04/3:54:41]  Acc_iter 13056       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.15(0.51)
2025-07-12 12:07:04,873   INFO  Train:   33/100 ( 33%) [   0/408 (  0%)]  Loss: 6.477 (6.48)  LR: 2.742e-03  Time cost: 00:03/25:52 [28:08/29:19:44]  Acc_iter 13057       Data time: 3.15(3.15)  Forward time: 0.65(0.65)  Batch time: 3.81(3.81)
2025-07-12 12:07:26,361   INFO  Train:   33/100 ( 33%) [  43/408 ( 11%)]  Loss: 4.392 (5.05)  LR: 2.749e-03  Time cost: 00:25/03:29 [28:30/4:25:24]  Acc_iter 13100       Data time: 0.00(0.08)  Forward time: 0.48(0.50)  Batch time: 0.48(0.57)
2025-07-12 12:07:51,548   INFO  Train:   33/100 ( 33%) [  93/408 ( 23%)]  Loss: 4.888 (5.03)  LR: 2.756e-03  Time cost: 00:50/02:49 [28:55/4:07:29]  Acc_iter 13150       Data time: 0.00(0.04)  Forward time: 0.69(0.50)  Batch time: 0.69(0.54)
2025-07-12 12:08:16,168   INFO  Train:   33/100 ( 33%) [ 143/408 ( 35%)]  Loss: 5.579 (5.06)  LR: 2.764e-03  Time cost: 01:15/02:18 [29:19/3:59:54]  Acc_iter 13200       Data time: 0.02(0.03)  Forward time: 0.43(0.50)  Batch time: 0.45(0.52)
2025-07-12 12:08:40,816   INFO  Train:   33/100 ( 33%) [ 193/408 ( 47%)]  Loss: 5.107 (5.02)  LR: 2.771e-03  Time cost: 01:39/01:50 [29:44/3:56:05]  Acc_iter 13250       Data time: 0.00(0.02)  Forward time: 0.44(0.49)  Batch time: 0.45(0.51)
2025-07-12 12:09:05,655   INFO  Train:   33/100 ( 33%) [ 243/408 ( 60%)]  Loss: 5.592 (5.00)  LR: 2.778e-03  Time cost: 02:04/01:24 [30:09/3:54:02]  Acc_iter 13300       Data time: 0.00(0.02)  Forward time: 0.38(0.49)  Batch time: 0.38(0.51)
2025-07-12 12:09:30,400   INFO  Train:   33/100 ( 33%) [ 293/408 ( 72%)]  Loss: 7.669 (5.04)  LR: 2.785e-03  Time cost: 02:29/00:58 [30:34/3:52:23]  Acc_iter 13350       Data time: 0.00(0.01)  Forward time: 0.60(0.49)  Batch time: 0.60(0.51)
2025-07-12 12:09:54,960   INFO  Train:   33/100 ( 33%) [ 343/408 ( 84%)]  Loss: 4.737 (5.01)  LR: 2.792e-03  Time cost: 02:53/00:32 [30:58/3:50:51]  Acc_iter 13400       Data time: 0.00(0.01)  Forward time: 0.44(0.49)  Batch time: 0.44(0.51)
2025-07-12 12:10:19,799   INFO  Train:   33/100 ( 33%) [ 393/408 ( 96%)]  Loss: 7.688 (5.00)  LR: 2.799e-03  Time cost: 03:18/00:07 [31:23/3:49:55]  Acc_iter 13450       Data time: 0.00(0.01)  Forward time: 0.38(0.49)  Batch time: 0.38(0.50)
2025-07-12 12:10:24,505   INFO  Train:   33/100 ( 33%) [ 407/408 (100%)]  Loss: 5.166 (5.00)  LR: 2.801e-03  Time cost: 03:23/00:00 [31:28/3:47:10]  Acc_iter 13464       Data time: 0.00(0.01)  Forward time: 0.17(0.49)  Batch time: 0.18(0.50)
2025-07-12 12:10:28,830   INFO  Train:   34/100 ( 34%) [   0/408 (  0%)]  Loss: 4.424 (4.42)  LR: 2.801e-03  Time cost: 00:03/24:43 [31:32/27:36:51]  Acc_iter 13465       Data time: 2.46(2.46)  Forward time: 1.18(1.18)  Batch time: 3.64(3.64)
2025-07-12 12:10:46,566   INFO  Train:   34/100 ( 34%) [  35/408 (  9%)]  Loss: 4.483 (4.78)  LR: 2.806e-03  Time cost: 00:21/03:41 [31:50/4:30:07]  Acc_iter 13500       Data time: 0.00(0.07)  Forward time: 0.92(0.52)  Batch time: 0.92(0.59)
2025-07-12 12:11:12,009   INFO  Train:   34/100 ( 34%) [  85/408 ( 21%)]  Loss: 3.314 (4.89)  LR: 2.812e-03  Time cost: 00:46/02:55 [32:15/4:07:14]  Acc_iter 13550       Data time: 0.00(0.03)  Forward time: 0.51(0.51)  Batch time: 0.51(0.54)
2025-07-12 12:11:37,324   INFO  Train:   34/100 ( 34%) [ 135/408 ( 33%)]  Loss: 5.066 (4.88)  LR: 2.819e-03  Time cost: 01:12/02:24 [32:40/4:00:26]  Acc_iter 13600       Data time: 0.00(0.02)  Forward time: 0.67(0.51)  Batch time: 0.68(0.53)
2025-07-12 12:12:02,201   INFO  Train:   34/100 ( 34%) [ 185/408 ( 45%)]  Loss: 6.206 (4.81)  LR: 2.825e-03  Time cost: 01:37/01:56 [33:05/3:56:00]  Acc_iter 13650       Data time: 0.00(0.02)  Forward time: 0.61(0.50)  Batch time: 0.62(0.52)
2025-07-12 12:12:27,285   INFO  Train:   34/100 ( 34%) [ 235/408 ( 58%)]  Loss: 4.484 (4.83)  LR: 2.832e-03  Time cost: 02:02/01:29 [33:30/3:53:40]  Acc_iter 13700       Data time: 0.00(0.01)  Forward time: 0.52(0.50)  Batch time: 0.53(0.52)
2025-07-12 12:12:53,056   INFO  Train:   34/100 ( 34%) [ 285/408 ( 70%)]  Loss: 4.421 (4.83)  LR: 2.838e-03  Time cost: 02:27/01:03 [33:56/3:53:05]  Acc_iter 13750       Data time: 0.00(0.01)  Forward time: 0.40(0.50)  Batch time: 0.40(0.52)
2025-07-12 12:13:18,944   INFO  Train:   34/100 ( 34%) [ 335/408 ( 82%)]  Loss: 4.117 (4.83)  LR: 2.844e-03  Time cost: 02:53/00:37 [34:22/3:52:42]  Acc_iter 13800       Data time: 0.00(0.01)  Forward time: 0.36(0.51)  Batch time: 0.37(0.52)
2025-07-12 12:13:44,827   INFO  Train:   34/100 ( 34%) [ 385/408 ( 94%)]  Loss: 4.151 (4.84)  LR: 2.850e-03  Time cost: 03:19/00:11 [34:48/3:52:18]  Acc_iter 13850       Data time: 0.00(0.01)  Forward time: 0.53(0.51)  Batch time: 0.53(0.52)
2025-07-12 12:13:53,918   INFO  Train:   34/100 ( 34%) [ 407/408 (100%)]  Loss: 4.671 (4.84)  LR: 2.853e-03  Time cost: 03:28/00:00 [34:57/3:49:36]  Acc_iter 13872       Data time: 0.00(0.01)  Forward time: 0.13(0.50)  Batch time: 0.14(0.51)
2025-07-12 12:13:57,997   INFO  Train:   35/100 ( 35%) [   0/408 (  0%)]  Loss: 4.209 (4.21)  LR: 2.853e-03  Time cost: 00:03/22:25 [35:01/24:40:26]  Acc_iter 13873       Data time: 2.18(2.18)  Forward time: 1.12(1.12)  Batch time: 3.30(3.30)
2025-07-12 12:14:12,212   INFO  Train:   35/100 ( 35%) [  27/408 (  7%)]  Loss: 3.875 (4.91)  LR: 2.856e-03  Time cost: 00:17/03:58 [35:15/4:40:26]  Acc_iter 13900       Data time: 0.00(0.08)  Forward time: 0.73(0.54)  Batch time: 0.74(0.63)
2025-07-12 12:14:37,906   INFO  Train:   35/100 ( 35%) [  77/408 ( 19%)]  Loss: 3.647 (4.80)  LR: 2.862e-03  Time cost: 00:43/03:03 [35:41/4:07:53]  Acc_iter 13950       Data time: 0.00(0.03)  Forward time: 0.85(0.52)  Batch time: 0.85(0.55)
2025-07-12 12:15:03,805   INFO  Train:   35/100 ( 35%) [ 127/408 ( 31%)]  Loss: 5.865 (4.79)  LR: 2.867e-03  Time cost: 01:09/02:31 [36:07/4:01:09]  Acc_iter 14000       Data time: 0.00(0.02)  Forward time: 0.60(0.52)  Batch time: 0.60(0.54)
2025-07-12 12:15:28,424   INFO  Train:   35/100 ( 35%) [ 177/408 ( 43%)]  Loss: 4.599 (4.81)  LR: 2.873e-03  Time cost: 01:33/02:01 [36:32/3:54:45]  Acc_iter 14050       Data time: 0.00(0.02)  Forward time: 0.31(0.51)  Batch time: 0.31(0.53)
2025-07-12 12:15:53,782   INFO  Train:   35/100 ( 35%) [ 227/408 ( 56%)]  Loss: 3.974 (4.78)  LR: 2.878e-03  Time cost: 01:59/01:34 [36:57/3:52:25]  Acc_iter 14100       Data time: 0.00(0.01)  Forward time: 0.49(0.51)  Batch time: 0.50(0.52)
2025-07-12 12:16:19,899   INFO  Train:   35/100 ( 35%) [ 277/408 ( 68%)]  Loss: 4.075 (4.76)  LR: 2.884e-03  Time cost: 02:25/01:08 [37:23/3:51:59]  Acc_iter 14150       Data time: 0.00(0.01)  Forward time: 0.83(0.51)  Batch time: 0.83(0.52)
2025-07-12 12:16:44,279   INFO  Train:   35/100 ( 35%) [ 327/408 ( 80%)]  Loss: 4.654 (4.74)  LR: 2.889e-03  Time cost: 02:49/00:41 [37:47/3:49:13]  Acc_iter 14200       Data time: 0.00(0.01)  Forward time: 0.33(0.51)  Batch time: 0.34(0.52)
2025-07-12 12:17:09,078   INFO  Train:   35/100 ( 35%) [ 377/408 ( 92%)]  Loss: 4.644 (4.72)  LR: 2.894e-03  Time cost: 03:14/00:15 [38:12/3:47:33]  Acc_iter 14250       Data time: 0.00(0.01)  Forward time: 0.39(0.50)  Batch time: 0.40(0.51)
2025-07-12 12:17:22,083   INFO  Train:   35/100 ( 35%) [ 407/408 (100%)]  Loss: 5.491 (4.72)  LR: 2.897e-03  Time cost: 03:27/00:00 [38:25/3:44:40]  Acc_iter 14280       Data time: 0.00(0.01)  Forward time: 0.16(0.50)  Batch time: 0.16(0.51)
2025-07-12 12:17:27,243   INFO  Train:   36/100 ( 36%) [   0/408 (  0%)]  Loss: 4.321 (4.32)  LR: 2.897e-03  Time cost: 00:04/29:10 [38:30/31:36:28]  Acc_iter 14281       Data time: 3.48(3.48)  Forward time: 0.81(0.81)  Batch time: 4.29(4.29)
2025-07-12 12:17:36,764   INFO  Train:   36/100 ( 36%) [  19/408 (  5%)]  Loss: 5.097 (5.07)  LR: 2.899e-03  Time cost: 00:13/04:28 [38:40/5:05:01]  Acc_iter 14300       Data time: 0.00(0.18)  Forward time: 0.69(0.51)  Batch time: 0.69(0.69)
2025-07-12 12:18:02,506   INFO  Train:   36/100 ( 36%) [  69/408 ( 17%)]  Loss: 4.245 (4.79)  LR: 2.904e-03  Time cost: 00:39/03:11 [39:06/4:09:06]  Acc_iter 14350       Data time: 0.01(0.05)  Forward time: 0.35(0.51)  Batch time: 0.36(0.57)
2025-07-12 12:18:28,895   INFO  Train:   36/100 ( 36%) [ 119/408 ( 29%)]  Loss: 6.476 (4.77)  LR: 2.909e-03  Time cost: 01:05/02:38 [39:32/4:01:47]  Acc_iter 14400       Data time: 0.00(0.03)  Forward time: 0.44(0.52)  Batch time: 0.44(0.55)
2025-07-12 12:18:54,581   INFO  Train:   36/100 ( 36%) [ 169/408 ( 41%)]  Loss: 5.204 (4.76)  LR: 2.913e-03  Time cost: 01:31/02:08 [39:58/3:56:42]  Acc_iter 14450       Data time: 0.00(0.02)  Forward time: 0.26(0.51)  Batch time: 0.27(0.54)
2025-07-12 12:19:20,638   INFO  Train:   36/100 ( 36%) [ 219/408 ( 54%)]  Loss: 4.085 (4.73)  LR: 2.918e-03  Time cost: 01:57/01:41 [40:24/3:54:28]  Acc_iter 14500       Data time: 0.00(0.02)  Forward time: 0.52(0.51)  Batch time: 0.52(0.53)
2025-07-12 12:19:46,684   INFO  Train:   36/100 ( 36%) [ 269/408 ( 66%)]  Loss: 4.839 (4.69)  LR: 2.922e-03  Time cost: 02:23/01:13 [40:50/3:52:54]  Acc_iter 14550       Data time: 0.00(0.02)  Forward time: 0.82(0.52)  Batch time: 0.83(0.53)
2025-07-12 12:20:11,804   INFO  Train:   36/100 ( 36%) [ 319/408 ( 78%)]  Loss: 4.393 (4.69)  LR: 2.927e-03  Time cost: 02:48/00:46 [41:15/3:50:25]  Acc_iter 14600       Data time: 0.00(0.02)  Forward time: 0.62(0.51)  Batch time: 0.62(0.53)
2025-07-12 12:20:38,163   INFO  Train:   36/100 ( 36%) [ 369/408 ( 90%)]  Loss: 6.476 (4.71)  LR: 2.931e-03  Time cost: 03:15/00:20 [41:41/3:49:57]  Acc_iter 14650       Data time: 0.00(0.01)  Forward time: 0.66(0.51)  Batch time: 0.66(0.53)
2025-07-12 12:20:55,587   INFO  Train:   36/100 ( 36%) [ 407/408 (100%)]  Loss: 7.803 (4.73)  LR: 2.934e-03  Time cost: 03:32/00:00 [41:59/3:46:49]  Acc_iter 14688       Data time: 0.00(0.01)  Forward time: 0.17(0.51)  Batch time: 0.17(0.52)
2025-07-12 12:20:59,774   INFO  Train:   37/100 ( 37%) [   0/408 (  0%)]  Loss: 4.731 (4.73)  LR: 2.934e-03  Time cost: 00:03/23:16 [42:03/24:50:02]  Acc_iter 14689       Data time: 2.43(2.43)  Forward time: 1.00(1.00)  Batch time: 3.42(3.42)
2025-07-12 12:21:05,058   INFO  Train:   37/100 ( 37%) [  11/408 (  3%)]  Loss: 5.264 (4.61)  LR: 2.935e-03  Time cost: 00:08/04:48 [42:08/5:15:39]  Acc_iter 14700       Data time: 0.00(0.21)  Forward time: 0.34(0.52)  Batch time: 0.34(0.73)
2025-07-12 12:21:30,236   INFO  Train:   37/100 ( 37%) [  61/408 ( 15%)]  Loss: 4.745 (4.48)  LR: 2.939e-03  Time cost: 00:33/03:09 [42:33/3:57:17]  Acc_iter 14750       Data time: 0.00(0.04)  Forward time: 0.72(0.50)  Batch time: 0.73(0.55)
2025-07-12 12:21:55,874   INFO  Train:   37/100 ( 37%) [ 111/408 ( 27%)]  Loss: 4.302 (4.57)  LR: 2.943e-03  Time cost: 00:59/02:37 [42:59/3:50:18]  Acc_iter 14800       Data time: 0.00(0.03)  Forward time: 0.42(0.51)  Batch time: 0.43(0.53)
2025-07-12 12:22:21,053   INFO  Train:   37/100 ( 37%) [ 161/408 ( 39%)]  Loss: 3.522 (4.55)  LR: 2.946e-03  Time cost: 01:24/02:09 [43:24/3:46:08]  Acc_iter 14850       Data time: 0.00(0.02)  Forward time: 0.61(0.50)  Batch time: 0.61(0.52)
2025-07-12 12:22:46,572   INFO  Train:   37/100 ( 37%) [ 211/408 ( 52%)]  Loss: 3.964 (4.56)  LR: 2.950e-03  Time cost: 01:50/01:42 [43:50/3:44:26]  Acc_iter 14900       Data time: 0.00(0.02)  Forward time: 0.39(0.50)  Batch time: 0.40(0.52)
2025-07-12 12:23:11,282   INFO  Train:   37/100 ( 37%) [ 261/408 ( 64%)]  Loss: 5.770 (4.61)  LR: 2.953e-03  Time cost: 02:14/01:15 [44:14/3:41:53]  Acc_iter 14950       Data time: 0.00(0.01)  Forward time: 0.29(0.50)  Batch time: 0.29(0.52)
2025-07-12 12:23:36,267   INFO  Train:   37/100 ( 37%) [ 311/408 ( 76%)]  Loss: 3.800 (4.61)  LR: 2.957e-03  Time cost: 02:39/00:49 [44:39/3:40:24]  Acc_iter 15000       Data time: 0.00(0.01)  Forward time: 0.35(0.50)  Batch time: 0.36(0.51)
2025-07-12 12:24:01,382   INFO  Train:   37/100 ( 37%) [ 361/408 ( 88%)]  Loss: 4.327 (4.61)  LR: 2.960e-03  Time cost: 03:05/00:24 [45:05/3:39:22]  Acc_iter 15050       Data time: 0.00(0.01)  Forward time: 0.32(0.50)  Batch time: 0.32(0.51)
2025-07-12 12:24:22,255   INFO  Train:   37/100 ( 37%) [ 407/408 (100%)]  Loss: 6.134 (4.64)  LR: 2.963e-03  Time cost: 03:25/00:00 [45:25/3:36:12]  Acc_iter 15096       Data time: 0.00(0.01)  Forward time: 0.13(0.49)  Batch time: 0.13(0.50)
2025-07-12 12:24:26,843   INFO  Train:   38/100 ( 38%) [   0/408 (  0%)]  Loss: 5.765 (5.76)  LR: 2.963e-03  Time cost: 00:03/26:16 [45:30/27:35:50]  Acc_iter 15097       Data time: 3.05(3.05)  Forward time: 0.81(0.81)  Batch time: 3.86(3.86)
2025-07-12 12:24:28,267   INFO  Train:   38/100 ( 38%) [   3/408 (  1%)]  Loss: 6.239 (5.01)  LR: 2.963e-03  Time cost: 00:05/08:55 [45:31/9:26:25]  Acc_iter 15100       Data time: 0.00(0.77)  Forward time: 0.31(0.56)  Batch time: 0.31(1.32)
2025-07-12 12:24:54,604   INFO  Train:   38/100 ( 38%) [  53/408 ( 13%)]  Loss: 4.820 (4.71)  LR: 2.966e-03  Time cost: 00:31/03:27 [45:58/4:10:22]  Acc_iter 15150       Data time: 0.00(0.06)  Forward time: 0.56(0.53)  Batch time: 0.56(0.59)
2025-07-12 12:25:20,762   INFO  Train:   38/100 ( 38%) [ 103/408 ( 25%)]  Loss: 5.272 (4.58)  LR: 2.969e-03  Time cost: 00:57/02:49 [46:24/3:57:04]  Acc_iter 15200       Data time: 0.00(0.03)  Forward time: 0.39(0.52)  Batch time: 0.39(0.56)
2025-07-12 12:25:45,672   INFO  Train:   38/100 ( 38%) [ 153/408 ( 38%)]  Loss: 5.440 (4.56)  LR: 2.971e-03  Time cost: 01:22/02:16 [46:49/3:48:40]  Acc_iter 15250       Data time: 0.01(0.02)  Forward time: 0.46(0.51)  Batch time: 0.47(0.54)
2025-07-12 12:26:11,007   INFO  Train:   38/100 ( 38%) [ 203/408 ( 50%)]  Loss: 3.911 (4.59)  LR: 2.974e-03  Time cost: 01:48/01:48 [47:14/3:45:04]  Acc_iter 15300       Data time: 0.00(0.02)  Forward time: 0.42(0.51)  Batch time: 0.42(0.53)
2025-07-12 12:26:36,069   INFO  Train:   38/100 ( 38%) [ 253/408 ( 62%)]  Loss: 3.985 (4.59)  LR: 2.976e-03  Time cost: 02:13/01:21 [47:39/3:42:15]  Acc_iter 15350       Data time: 0.00(0.02)  Forward time: 0.48(0.51)  Batch time: 0.48(0.52)
2025-07-12 12:27:01,725   INFO  Train:   38/100 ( 38%) [ 303/408 ( 74%)]  Loss: 3.323 (4.59)  LR: 2.979e-03  Time cost: 02:38/00:54 [48:05/3:41:04]  Acc_iter 15400       Data time: 0.00(0.01)  Forward time: 0.67(0.51)  Batch time: 0.67(0.52)
2025-07-12 12:27:27,148   INFO  Train:   38/100 ( 38%) [ 353/408 ( 87%)]  Loss: 4.008 (4.59)  LR: 2.981e-03  Time cost: 03:04/00:28 [48:30/3:39:48]  Acc_iter 15450       Data time: 0.00(0.01)  Forward time: 0.67(0.51)  Batch time: 0.68(0.52)
2025-07-12 12:27:51,102   INFO  Train:   38/100 ( 38%) [ 403/408 ( 99%)]  Loss: 5.069 (4.58)  LR: 2.983e-03  Time cost: 03:28/00:02 [48:54/3:37:14]  Acc_iter 15500       Data time: 0.00(0.01)  Forward time: 0.20(0.50)  Batch time: 0.20(0.52)
2025-07-12 12:27:51,919   INFO  Train:   38/100 ( 38%) [ 407/408 (100%)]  Loss: 11.59 (4.59)  LR: 2.983e-03  Time cost: 03:28/00:00 [48:55/3:35:54]  Acc_iter 15504       Data time: 0.00(0.01)  Forward time: 0.15(0.50)  Batch time: 0.15(0.51)
2025-07-12 12:27:56,354   INFO  Train:   39/100 ( 39%) [   0/408 (  0%)]  Loss: 4.356 (4.36)  LR: 2.983e-03  Time cost: 00:03/25:30 [48:59/26:21:57]  Acc_iter 15505       Data time: 2.48(2.48)  Forward time: 1.28(1.28)  Batch time: 3.75(3.75)
2025-07-12 12:28:18,349   INFO  Train:   39/100 ( 39%) [  45/408 ( 11%)]  Loss: 3.418 (4.65)  LR: 2.985e-03  Time cost: 00:25/03:23 [49:21/3:55:33]  Acc_iter 15550       Data time: 0.01(0.06)  Forward time: 0.68(0.50)  Batch time: 0.69(0.56)
2025-07-12 12:28:43,300   INFO  Train:   39/100 ( 39%) [  95/408 ( 23%)]  Loss: 5.751 (4.70)  LR: 2.987e-03  Time cost: 00:50/02:45 [49:46/3:41:48]  Acc_iter 15600       Data time: 0.00(0.03)  Forward time: 0.55(0.50)  Batch time: 0.55(0.53)
2025-07-12 12:29:08,814   INFO  Train:   39/100 ( 39%) [ 145/408 ( 36%)]  Loss: 5.374 (4.70)  LR: 2.989e-03  Time cost: 01:16/02:17 [50:12/3:38:48]  Acc_iter 15650       Data time: 0.00(0.02)  Forward time: 0.64(0.50)  Batch time: 0.65(0.52)
2025-07-12 12:29:33,474   INFO  Train:   39/100 ( 39%) [ 195/408 ( 48%)]  Loss: 4.042 (4.68)  LR: 2.990e-03  Time cost: 01:40/01:49 [50:37/3:35:18]  Acc_iter 15700       Data time: 0.01(0.02)  Forward time: 0.49(0.50)  Batch time: 0.49(0.51)
2025-07-12 12:29:58,509   INFO  Train:   39/100 ( 39%) [ 245/408 ( 60%)]  Loss: 4.810 (4.61)  LR: 2.992e-03  Time cost: 02:05/01:23 [51:02/3:33:41]  Acc_iter 15750       Data time: 0.00(0.01)  Forward time: 0.35(0.50)  Batch time: 0.36(0.51)
2025-07-12 12:30:24,067   INFO  Train:   39/100 ( 39%) [ 295/408 ( 72%)]  Loss: 3.944 (4.56)  LR: 2.993e-03  Time cost: 02:31/00:57 [51:27/3:33:13]  Acc_iter 15800       Data time: 0.00(0.01)  Forward time: 0.71(0.50)  Batch time: 0.71(0.51)
2025-07-12 12:30:49,000   INFO  Train:   39/100 ( 39%) [ 345/408 ( 85%)]  Loss: 4.446 (4.53)  LR: 2.994e-03  Time cost: 02:56/00:32 [51:52/3:32:00]  Acc_iter 15850       Data time: 0.00(0.01)  Forward time: 0.44(0.50)  Batch time: 0.44(0.51)
2025-07-12 12:31:14,445   INFO  Train:   39/100 ( 39%) [ 395/408 ( 97%)]  Loss: 5.460 (4.49)  LR: 2.996e-03  Time cost: 03:21/00:06 [52:18/3:31:32]  Acc_iter 15900       Data time: 0.00(0.01)  Forward time: 0.69(0.50)  Batch time: 0.70(0.51)
2025-07-12 12:31:18,802   INFO  Train:   39/100 ( 39%) [ 407/408 (100%)]  Loss: 6.193 (4.48)  LR: 2.996e-03  Time cost: 03:26/00:00 [52:22/3:29:38]  Acc_iter 15912       Data time: 0.00(0.01)  Forward time: 0.17(0.50)  Batch time: 0.18(0.51)
2025-07-12 12:31:23,928   INFO  Train:   40/100 ( 40%) [   0/408 (  0%)]  Loss: 4.322 (4.32)  LR: 2.996e-03  Time cost: 00:04/28:57 [52:27/29:26:35]  Acc_iter 15913       Data time: 3.38(3.38)  Forward time: 0.88(0.88)  Batch time: 4.26(4.26)
2025-07-12 12:31:42,788   INFO  Train:   40/100 ( 40%) [  37/408 (  9%)]  Loss: 4.040 (4.48)  LR: 2.997e-03  Time cost: 00:23/03:45 [52:46/4:11:59]  Acc_iter 15950       Data time: 0.00(0.09)  Forward time: 0.63(0.52)  Batch time: 0.63(0.61)
2025-07-12 12:32:08,422   INFO  Train:   40/100 ( 40%) [  87/408 ( 21%)]  Loss: 3.905 (4.51)  LR: 2.997e-03  Time cost: 00:48/02:57 [53:12/3:48:59]  Acc_iter 16000       Data time: 0.00(0.04)  Forward time: 0.43(0.51)  Batch time: 0.44(0.55)
2025-07-12 12:32:34,930   INFO  Train:   40/100 ( 40%) [ 137/408 ( 34%)]  Loss: 3.960 (4.49)  LR: 2.998e-03  Time cost: 01:15/02:27 [53:38/3:44:58]  Acc_iter 16050       Data time: 0.00(0.03)  Forward time: 0.58(0.52)  Batch time: 0.59(0.55)
2025-07-12 12:32:59,856   INFO  Train:   40/100 ( 40%) [ 187/408 ( 46%)]  Loss: 5.016 (4.46)  LR: 2.999e-03  Time cost: 01:40/01:57 [54:03/3:39:23]  Acc_iter 16100       Data time: 0.00(0.02)  Forward time: 0.22(0.51)  Batch time: 0.22(0.53)
2025-07-12 12:33:24,819   INFO  Train:   40/100 ( 40%) [ 237/408 ( 58%)]  Loss: 3.915 (4.42)  LR: 2.999e-03  Time cost: 02:05/01:29 [54:28/3:36:02]  Acc_iter 16150       Data time: 0.01(0.02)  Forward time: 0.48(0.51)  Batch time: 0.49(0.53)
2025-07-12 12:33:49,782   INFO  Train:   40/100 ( 40%) [ 287/408 ( 70%)]  Loss: 5.523 (4.43)  LR: 3.000e-03  Time cost: 02:30/01:03 [54:53/3:33:42]  Acc_iter 16200       Data time: 0.00(0.02)  Forward time: 0.51(0.51)  Batch time: 0.51(0.52)
2025-07-12 12:34:14,786   INFO  Train:   40/100 ( 40%) [ 337/408 ( 83%)]  Loss: 2.464 (4.42)  LR: 3.000e-03  Time cost: 02:55/00:36 [55:18/3:31:59]  Acc_iter 16250       Data time: 0.00(0.01)  Forward time: 0.47(0.50)  Batch time: 0.47(0.52)
2025-07-12 12:34:39,845   INFO  Train:   40/100 ( 40%) [ 387/408 ( 95%)]  Loss: 3.487 (4.40)  LR: 3.000e-03  Time cost: 03:20/00:10 [55:43/3:30:40]  Acc_iter 16300       Data time: 0.00(0.01)  Forward time: 0.46(0.50)  Batch time: 0.47(0.52)
2025-07-12 12:34:48,230   INFO  Train:   40/100 ( 40%) [ 407/408 (100%)]  Loss: 3.381 (4.40)  LR: 3.000e-03  Time cost: 03:28/00:00 [55:51/3:28:34]  Acc_iter 16320       Data time: 0.00(0.01)  Forward time: 0.17(0.50)  Batch time: 0.17(0.51)
2025-07-12 12:34:52,348   INFO  Train:   41/100 ( 41%) [   0/408 (  0%)]  Loss: 4.430 (4.43)  LR: 3.000e-03  Time cost: 00:03/22:46 [55:55/22:46:36]  Acc_iter 16321       Data time: 2.24(2.24)  Forward time: 1.11(1.11)  Batch time: 3.35(3.35)
2025-07-12 12:35:06,868   INFO  Train:   41/100 ( 41%) [  29/408 (  7%)]  Loss: 4.696 (4.34)  LR: 3.000e-03  Time cost: 00:17/03:45 [56:10/4:02:44]  Acc_iter 16350       Data time: 0.00(0.08)  Forward time: 0.36(0.52)  Batch time: 0.36(0.60)
2025-07-12 12:35:31,502   INFO  Train:   41/100 ( 41%) [  79/408 ( 19%)]  Loss: 2.837 (4.35)  LR: 3.000e-03  Time cost: 00:42/02:54 [56:35/3:36:04]  Acc_iter 16400       Data time: 0.00(0.03)  Forward time: 0.39(0.50)  Batch time: 0.39(0.53)
2025-07-12 12:35:55,858   INFO  Train:   41/100 ( 41%) [ 129/408 ( 32%)]  Loss: 3.308 (4.45)  LR: 3.000e-03  Time cost: 01:06/02:23 [56:59/3:28:43]  Acc_iter 16450       Data time: 0.00(0.02)  Forward time: 0.31(0.49)  Batch time: 0.31(0.51)
2025-07-12 12:36:21,571   INFO  Train:   41/100 ( 41%) [ 179/408 ( 44%)]  Loss: 4.543 (4.47)  LR: 3.000e-03  Time cost: 01:32/01:57 [57:25/3:28:17]  Acc_iter 16500       Data time: 0.00(0.02)  Forward time: 0.33(0.50)  Batch time: 0.33(0.51)
2025-07-12 12:36:47,898   INFO  Train:   41/100 ( 41%) [ 229/408 ( 56%)]  Loss: 6.441 (4.44)  LR: 2.999e-03  Time cost: 01:58/01:32 [57:51/3:28:56]  Acc_iter 16550       Data time: 0.00(0.01)  Forward time: 0.32(0.50)  Batch time: 0.32(0.52)
2025-07-12 12:37:13,152   INFO  Train:   41/100 ( 41%) [ 279/408 ( 68%)]  Loss: 4.951 (4.39)  LR: 2.999e-03  Time cost: 02:24/01:06 [58:16/3:27:39]  Acc_iter 16600       Data time: 0.00(0.01)  Forward time: 0.51(0.50)  Batch time: 0.51(0.51)
2025-07-12 12:37:39,342   INFO  Train:   41/100 ( 41%) [ 329/408 ( 81%)]  Loss: 4.696 (4.40)  LR: 2.999e-03  Time cost: 02:50/00:40 [58:42/3:27:46]  Acc_iter 16650       Data time: 0.00(0.01)  Forward time: 0.54(0.51)  Batch time: 0.55(0.52)
2025-07-12 12:38:04,302   INFO  Train:   41/100 ( 41%) [ 379/408 ( 93%)]  Loss: 3.493 (4.39)  LR: 2.998e-03  Time cost: 03:15/00:14 [59:07/3:26:26]  Acc_iter 16700       Data time: 0.00(0.01)  Forward time: 0.48(0.50)  Batch time: 0.48(0.51)
2025-07-12 12:38:16,555   INFO  Train:   41/100 ( 41%) [ 407/408 (100%)]  Loss: 3.687 (4.38)  LR: 2.998e-03  Time cost: 03:27/00:00 [59:20/3:24:06]  Acc_iter 16728       Data time: 0.00(0.01)  Forward time: 0.16(0.50)  Batch time: 0.17(0.51)
2025-07-12 12:38:21,094   INFO  Train:   42/100 ( 42%) [   0/408 (  0%)]  Loss: 3.955 (3.95)  LR: 2.998e-03  Time cost: 00:03/25:52 [59:24/25:26:14]  Acc_iter 16729       Data time: 2.73(2.73)  Forward time: 1.07(1.07)  Batch time: 3.80(3.80)
2025-07-12 12:38:31,266   INFO  Train:   42/100 ( 42%) [  21/408 (  5%)]  Loss: 3.411 (4.15)  LR: 2.998e-03  Time cost: 00:13/04:05 [59:34/4:14:39]  Acc_iter 16750       Data time: 0.00(0.13)  Forward time: 0.45(0.51)  Batch time: 0.46(0.64)
2025-07-12 12:38:55,958   INFO  Train:   42/100 ( 42%) [  71/408 ( 17%)]  Loss: 3.698 (4.16)  LR: 2.997e-03  Time cost: 00:38/03:00 [59:59/3:34:49]  Acc_iter 16800       Data time: 0.00(0.04)  Forward time: 0.43(0.50)  Batch time: 0.44(0.54)
2025-07-12 12:39:20,939   INFO  Train:   42/100 ( 42%) [ 121/408 ( 30%)]  Loss: 5.018 (4.15)  LR: 2.997e-03  Time cost: 01:03/02:29 [1:00:24/3:28:15]  Acc_iter 16850       Data time: 0.00(0.03)  Forward time: 0.84(0.50)  Batch time: 0.84(0.52)
2025-07-12 12:39:46,090   INFO  Train:   42/100 ( 42%) [ 171/408 ( 42%)]  Loss: 3.875 (4.24)  LR: 2.996e-03  Time cost: 01:28/02:02 [1:00:49/3:25:39]  Acc_iter 16900       Data time: 0.00(0.02)  Forward time: 0.46(0.50)  Batch time: 0.46(0.52)
2025-07-12 12:40:11,647   INFO  Train:   42/100 ( 42%) [ 221/408 ( 54%)]  Loss: 4.568 (4.23)  LR: 2.995e-03  Time cost: 01:54/01:36 [1:01:15/3:24:46]  Acc_iter 16950       Data time: 0.00(0.02)  Forward time: 0.50(0.50)  Batch time: 0.50(0.52)
2025-07-12 12:40:36,998   INFO  Train:   42/100 ( 42%) [ 271/408 ( 66%)]  Loss: 6.281 (4.22)  LR: 2.994e-03  Time cost: 02:19/01:10 [1:01:40/3:23:44]  Acc_iter 17000       Data time: 0.00(0.01)  Forward time: 0.39(0.50)  Batch time: 0.39(0.51)
2025-07-12 12:41:02,491   INFO  Train:   42/100 ( 42%) [ 321/408 ( 79%)]  Loss: 3.891 (4.24)  LR: 2.993e-03  Time cost: 02:45/00:44 [1:02:06/3:23:05]  Acc_iter 17050       Data time: 0.00(0.01)  Forward time: 0.44(0.50)  Batch time: 0.45(0.51)
2025-07-12 12:41:27,795   INFO  Train:   42/100 ( 42%) [ 371/408 ( 91%)]  Loss: 4.040 (4.26)  LR: 2.993e-03  Time cost: 03:10/00:18 [1:02:31/3:22:17]  Acc_iter 17100       Data time: 0.00(0.01)  Forward time: 0.44(0.50)  Batch time: 0.44(0.51)
2025-07-12 12:41:43,927   INFO  Train:   42/100 ( 42%) [ 407/408 (100%)]  Loss: 3.515 (4.25)  LR: 2.992e-03  Time cost: 03:26/00:00 [1:02:47/3:19:45]  Acc_iter 17136       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.14(0.51)
2025-07-12 12:41:48,536   INFO  Train:   43/100 ( 43%) [   0/408 (  0%)]  Loss: 4.468 (4.47)  LR: 2.992e-03  Time cost: 00:03/26:36 [1:02:52/25:43:33]  Acc_iter 17137       Data time: 3.16(3.16)  Forward time: 0.76(0.76)  Batch time: 3.91(3.91)
2025-07-12 12:41:54,897   INFO  Train:   43/100 ( 43%) [  13/408 (  3%)]  Loss: 3.695 (4.02)  LR: 2.992e-03  Time cost: 00:10/04:49 [1:02:58/4:49:16]  Acc_iter 17150       Data time: 0.00(0.23)  Forward time: 0.71(0.50)  Batch time: 0.72(0.73)
2025-07-12 12:42:19,260   INFO  Train:   43/100 ( 43%) [  63/408 ( 15%)]  Loss: 4.221 (4.29)  LR: 2.990e-03  Time cost: 00:34/03:06 [1:03:22/3:32:53]  Acc_iter 17200       Data time: 0.00(0.05)  Forward time: 0.44(0.49)  Batch time: 0.44(0.54)
2025-07-12 12:42:44,018   INFO  Train:   43/100 ( 43%) [ 113/408 ( 28%)]  Loss: 3.496 (4.19)  LR: 2.989e-03  Time cost: 00:59/02:33 [1:03:47/3:24:30]  Acc_iter 17250       Data time: 0.00(0.03)  Forward time: 0.65(0.49)  Batch time: 0.66(0.52)
2025-07-12 12:43:09,340   INFO  Train:   43/100 ( 43%) [ 163/408 ( 40%)]  Loss: 4.575 (4.19)  LR: 2.988e-03  Time cost: 01:24/02:06 [1:04:12/3:22:19]  Acc_iter 17300       Data time: 0.00(0.02)  Forward time: 0.27(0.49)  Batch time: 0.28(0.52)
2025-07-12 12:43:34,519   INFO  Train:   43/100 ( 43%) [ 213/408 ( 52%)]  Loss: 4.691 (4.16)  LR: 2.987e-03  Time cost: 01:49/01:40 [1:04:38/3:20:42]  Acc_iter 17350       Data time: 0.00(0.02)  Forward time: 0.27(0.49)  Batch time: 0.27(0.51)
2025-07-12 12:43:59,205   INFO  Train:   43/100 ( 43%) [ 263/408 ( 64%)]  Loss: 4.675 (4.15)  LR: 2.986e-03  Time cost: 02:14/01:13 [1:05:02/3:18:49]  Acc_iter 17400       Data time: 0.00(0.02)  Forward time: 0.41(0.49)  Batch time: 0.41(0.51)
2025-07-12 12:44:23,843   INFO  Train:   43/100 ( 43%) [ 313/408 ( 77%)]  Loss: 2.959 (4.16)  LR: 2.984e-03  Time cost: 02:39/00:48 [1:05:27/3:17:20]  Acc_iter 17450       Data time: 0.00(0.01)  Forward time: 0.56(0.49)  Batch time: 0.56(0.51)
2025-07-12 12:44:48,704   INFO  Train:   43/100 ( 43%) [ 363/408 ( 89%)]  Loss: 5.989 (4.16)  LR: 2.983e-03  Time cost: 03:04/00:22 [1:05:52/3:16:23]  Acc_iter 17500       Data time: 0.00(0.01)  Forward time: 0.52(0.49)  Batch time: 0.52(0.51)
2025-07-12 12:45:08,282   INFO  Train:   43/100 ( 43%) [ 407/408 (100%)]  Loss: 3.406 (4.17)  LR: 2.982e-03  Time cost: 03:23/00:00 [1:06:11/3:13:29]  Acc_iter 17544       Data time: 0.00(0.01)  Forward time: 0.13(0.49)  Batch time: 0.13(0.50)
2025-07-12 12:45:12,439   INFO  Train:   44/100 ( 44%) [   0/408 (  0%)]  Loss: 3.868 (3.87)  LR: 2.982e-03  Time cost: 00:03/23:42 [1:06:16/22:30:56]  Acc_iter 17545       Data time: 2.41(2.41)  Forward time: 1.07(1.07)  Batch time: 3.49(3.49)
2025-07-12 12:45:15,443   INFO  Train:   44/100 ( 44%) [   5/408 (  1%)]  Loss: 3.718 (4.25)  LR: 2.981e-03  Time cost: 00:06/07:15 [1:06:19/6:59:09]  Acc_iter 17550       Data time: 0.00(0.40)  Forward time: 0.65(0.68)  Batch time: 0.65(1.08)
2025-07-12 12:45:41,638   INFO  Train:   44/100 ( 44%) [  55/408 ( 13%)]  Loss: 4.279 (4.20)  LR: 2.980e-03  Time cost: 00:32/03:26 [1:06:45/3:45:41]  Acc_iter 17600       Data time: 0.01(0.05)  Forward time: 0.36(0.54)  Batch time: 0.36(0.58)
2025-07-12 12:46:08,075   INFO  Train:   44/100 ( 44%) [ 105/408 ( 26%)]  Loss: 5.183 (4.14)  LR: 2.978e-03  Time cost: 00:59/02:48 [1:07:11/3:35:12]  Acc_iter 17650       Data time: 0.00(0.03)  Forward time: 0.33(0.53)  Batch time: 0.34(0.56)
2025-07-12 12:46:34,085   INFO  Train:   44/100 ( 44%) [ 155/408 ( 38%)]  Loss: 3.361 (4.14)  LR: 2.977e-03  Time cost: 01:25/02:18 [1:07:37/3:30:06]  Acc_iter 17700       Data time: 0.00(0.02)  Forward time: 0.79(0.53)  Batch time: 0.80(0.55)
2025-07-12 12:47:00,693   INFO  Train:   44/100 ( 44%) [ 205/408 ( 50%)]  Loss: 4.568 (4.17)  LR: 2.975e-03  Time cost: 01:51/01:50 [1:08:04/3:28:23]  Acc_iter 17750       Data time: 0.00(0.02)  Forward time: 0.37(0.53)  Batch time: 0.37(0.54)
2025-07-12 12:47:26,280   INFO  Train:   44/100 ( 44%) [ 255/408 ( 62%)]  Loss: 4.618 (4.17)  LR: 2.973e-03  Time cost: 02:17/01:22 [1:08:29/3:25:38]  Acc_iter 17800       Data time: 0.00(0.01)  Forward time: 0.53(0.52)  Batch time: 0.54(0.54)
2025-07-12 12:47:51,719   INFO  Train:   44/100 ( 44%) [ 305/408 ( 75%)]  Loss: 5.262 (4.18)  LR: 2.971e-03  Time cost: 02:42/00:54 [1:08:55/3:23:27]  Acc_iter 17850       Data time: 0.00(0.01)  Forward time: 0.38(0.52)  Batch time: 0.38(0.53)
2025-07-12 12:48:16,458   INFO  Train:   44/100 ( 44%) [ 355/408 ( 87%)]  Loss: 4.270 (4.17)  LR: 2.969e-03  Time cost: 03:07/00:27 [1:09:20/3:21:01]  Acc_iter 17900       Data time: 0.00(0.01)  Forward time: 0.49(0.52)  Batch time: 0.49(0.53)
2025-07-12 12:48:39,888   INFO  Train:   44/100 ( 44%) [ 405/408 ( 99%)]  Loss: 3.428 (4.15)  LR: 2.967e-03  Time cost: 03:30/00:01 [1:09:43/3:17:52]  Acc_iter 17950       Data time: 0.00(0.01)  Forward time: 0.24(0.51)  Batch time: 0.24(0.52)
2025-07-12 12:48:40,256   INFO  Train:   44/100 ( 44%) [ 407/408 (100%)]  Loss: 4.782 (4.15)  LR: 2.967e-03  Time cost: 03:31/00:00 [1:09:43/3:17:13]  Acc_iter 17952       Data time: 0.00(0.01)  Forward time: 0.12(0.51)  Batch time: 0.13(0.52)
2025-07-12 12:48:44,455   INFO  Train:   45/100 ( 45%) [   0/408 (  0%)]  Loss: 3.426 (3.43)  LR: 2.967e-03  Time cost: 00:03/22:30 [1:09:48/21:00:51]  Acc_iter 17953       Data time: 2.20(2.20)  Forward time: 1.11(1.11)  Batch time: 3.31(3.31)
2025-07-12 12:49:08,885   INFO  Train:   45/100 ( 45%) [  47/408 ( 12%)]  Loss: 4.862 (3.99)  LR: 2.965e-03  Time cost: 00:27/03:28 [1:10:12/3:39:37]  Acc_iter 18000       Data time: 0.00(0.05)  Forward time: 0.40(0.53)  Batch time: 0.40(0.58)
2025-07-12 12:49:34,676   INFO  Train:   45/100 ( 45%) [  97/408 ( 24%)]  Loss: 4.689 (4.10)  LR: 2.963e-03  Time cost: 00:53/02:49 [1:10:38/3:27:07]  Acc_iter 18050       Data time: 0.00(0.03)  Forward time: 0.28(0.52)  Batch time: 0.28(0.55)
2025-07-12 12:50:01,028   INFO  Train:   45/100 ( 45%) [ 147/408 ( 36%)]  Loss: 4.588 (4.11)  LR: 2.961e-03  Time cost: 01:19/02:20 [1:11:04/3:24:12]  Acc_iter 18100       Data time: 0.00(0.02)  Forward time: 0.50(0.52)  Batch time: 0.51(0.54)
2025-07-12 12:50:26,008   INFO  Train:   45/100 ( 45%) [ 197/408 ( 48%)]  Loss: 3.927 (4.07)  LR: 2.959e-03  Time cost: 01:44/01:51 [1:11:29/3:19:56]  Acc_iter 18150       Data time: 0.00(0.02)  Forward time: 0.22(0.51)  Batch time: 0.22(0.53)
2025-07-12 12:50:51,985   INFO  Train:   45/100 ( 45%) [ 247/408 ( 61%)]  Loss: 3.727 (4.06)  LR: 2.957e-03  Time cost: 02:10/01:24 [1:11:55/3:18:43]  Acc_iter 18200       Data time: 0.00(0.01)  Forward time: 0.68(0.51)  Batch time: 0.68(0.53)
2025-07-12 12:51:17,012   INFO  Train:   45/100 ( 45%) [ 297/408 ( 73%)]  Loss: 3.769 (4.08)  LR: 2.954e-03  Time cost: 02:35/00:58 [1:12:20/3:16:35]  Acc_iter 18250       Data time: 0.00(0.01)  Forward time: 0.50(0.51)  Batch time: 0.51(0.52)
2025-07-12 12:51:41,495   INFO  Train:   45/100 ( 45%) [ 347/408 ( 85%)]  Loss: 2.859 (4.08)  LR: 2.952e-03  Time cost: 03:00/00:31 [1:12:45/3:14:21]  Acc_iter 18300       Data time: 0.00(0.01)  Forward time: 0.50(0.51)  Batch time: 0.50(0.52)
2025-07-12 12:52:06,772   INFO  Train:   45/100 ( 45%) [ 397/408 ( 97%)]  Loss: 3.455 (4.09)  LR: 2.949e-03  Time cost: 03:25/00:05 [1:13:10/3:13:19]  Acc_iter 18350       Data time: 0.02(0.01)  Forward time: 0.73(0.51)  Batch time: 0.75(0.52)
2025-07-12 12:52:09,758   INFO  Train:   45/100 ( 45%) [ 407/408 (100%)]  Loss: 5.640 (4.09)  LR: 2.949e-03  Time cost: 03:28/00:00 [1:13:13/3:11:14]  Acc_iter 18360       Data time: 0.00(0.01)  Forward time: 0.15(0.50)  Batch time: 0.16(0.51)
2025-07-12 12:52:14,106   INFO  Train:   46/100 ( 46%) [   0/408 (  0%)]  Loss: 4.854 (4.85)  LR: 2.949e-03  Time cost: 00:03/24:14 [1:13:17/22:13:24]  Acc_iter 18361       Data time: 2.43(2.43)  Forward time: 1.14(1.14)  Batch time: 3.56(3.56)
2025-07-12 12:52:33,898   INFO  Train:   46/100 ( 46%) [  39/408 ( 10%)]  Loss: 2.766 (4.18)  LR: 2.947e-03  Time cost: 00:23/03:35 [1:13:37/3:38:00]  Acc_iter 18400       Data time: 0.00(0.06)  Forward time: 0.45(0.52)  Batch time: 0.46(0.58)
2025-07-12 12:52:59,416   INFO  Train:   46/100 ( 46%) [  89/408 ( 22%)]  Loss: 2.870 (3.95)  LR: 2.944e-03  Time cost: 00:48/02:53 [1:14:03/3:22:17]  Acc_iter 18450       Data time: 0.00(0.03)  Forward time: 0.40(0.51)  Batch time: 0.41(0.54)
2025-07-12 12:53:25,377   INFO  Train:   46/100 ( 46%) [ 139/408 ( 34%)]  Loss: 2.568 (3.97)  LR: 2.942e-03  Time cost: 01:14/02:23 [1:14:29/3:18:41]  Acc_iter 18500       Data time: 0.06(0.02)  Forward time: 0.74(0.51)  Batch time: 0.79(0.53)
2025-07-12 12:53:51,279   INFO  Train:   46/100 ( 46%) [ 189/408 ( 46%)]  Loss: 3.841 (4.02)  LR: 2.939e-03  Time cost: 01:40/01:56 [1:14:54/3:16:37]  Acc_iter 18550       Data time: 0.00(0.02)  Forward time: 0.47(0.51)  Batch time: 0.47(0.53)
2025-07-12 12:54:16,975   INFO  Train:   46/100 ( 46%) [ 239/408 ( 59%)]  Loss: 3.950 (4.09)  LR: 2.936e-03  Time cost: 02:06/01:29 [1:15:20/3:14:55]  Acc_iter 18600       Data time: 0.00(0.01)  Forward time: 0.26(0.51)  Batch time: 0.26(0.53)
2025-07-12 12:54:42,666   INFO  Train:   46/100 ( 46%) [ 289/408 ( 71%)]  Loss: 4.195 (4.07)  LR: 2.933e-03  Time cost: 02:32/01:02 [1:15:46/3:13:39]  Acc_iter 18650       Data time: 0.01(0.01)  Forward time: 0.67(0.51)  Batch time: 0.67(0.52)
2025-07-12 12:55:08,042   INFO  Train:   46/100 ( 46%) [ 339/408 ( 83%)]  Loss: 3.748 (4.04)  LR: 2.931e-03  Time cost: 02:57/00:36 [1:16:11/3:12:18]  Acc_iter 18700       Data time: 0.00(0.01)  Forward time: 0.56(0.51)  Batch time: 0.56(0.52)
2025-07-12 12:55:33,473   INFO  Train:   46/100 ( 46%) [ 389/408 ( 95%)]  Loss: 2.954 (4.04)  LR: 2.928e-03  Time cost: 03:22/00:09 [1:16:37/3:11:14]  Acc_iter 18750       Data time: 0.00(0.01)  Forward time: 0.53(0.51)  Batch time: 0.53(0.52)
2025-07-12 12:55:40,492   INFO  Train:   46/100 ( 46%) [ 407/408 (100%)]  Loss: 5.697 (4.04)  LR: 2.927e-03  Time cost: 03:29/00:00 [1:16:44/3:08:57]  Acc_iter 18768       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.15(0.51)
2025-07-12 12:55:44,803   INFO  Train:   47/100 ( 47%) [   0/408 (  0%)]  Loss: 3.530 (3.53)  LR: 2.927e-03  Time cost: 00:03/24:17 [1:16:48/21:52:08]  Acc_iter 18769       Data time: 2.53(2.53)  Forward time: 1.04(1.04)  Batch time: 3.57(3.57)
2025-07-12 12:56:00,188   INFO  Train:   47/100 ( 47%) [  31/408 (  8%)]  Loss: 4.441 (3.91)  LR: 2.925e-03  Time cost: 00:18/03:43 [1:17:03/3:37:14]  Acc_iter 18800       Data time: 0.00(0.08)  Forward time: 0.61(0.51)  Batch time: 0.61(0.59)
2025-07-12 12:56:25,085   INFO  Train:   47/100 ( 47%) [  81/408 ( 20%)]  Loss: 4.497 (3.86)  LR: 2.922e-03  Time cost: 00:43/02:54 [1:17:28/3:15:39]  Acc_iter 18850       Data time: 0.00(0.03)  Forward time: 0.27(0.50)  Batch time: 0.27(0.53)
2025-07-12 12:56:50,516   INFO  Train:   47/100 ( 47%) [ 131/408 ( 32%)]  Loss: 3.966 (3.93)  LR: 2.919e-03  Time cost: 01:09/02:25 [1:17:54/3:11:35]  Acc_iter 18900       Data time: 0.00(0.02)  Forward time: 0.55(0.50)  Batch time: 0.56(0.52)
2025-07-12 12:57:16,028   INFO  Train:   47/100 ( 47%) [ 181/408 ( 44%)]  Loss: 5.077 (3.91)  LR: 2.915e-03  Time cost: 01:34/01:58 [1:18:19/3:09:41]  Acc_iter 18950       Data time: 0.00(0.02)  Forward time: 0.39(0.50)  Batch time: 0.40(0.52)
2025-07-12 12:57:41,079   INFO  Train:   47/100 ( 47%) [ 231/408 ( 57%)]  Loss: 4.246 (3.95)  LR: 2.912e-03  Time cost: 01:59/01:31 [1:18:44/3:07:42]  Acc_iter 19000       Data time: 0.00(0.01)  Forward time: 0.58(0.50)  Batch time: 0.59(0.52)
2025-07-12 12:58:05,801   INFO  Train:   47/100 ( 47%) [ 281/408 ( 69%)]  Loss: 3.465 (3.96)  LR: 2.909e-03  Time cost: 02:24/01:05 [1:19:09/3:05:50]  Acc_iter 19050       Data time: 0.00(0.01)  Forward time: 0.34(0.50)  Batch time: 0.35(0.51)
2025-07-12 12:58:30,299   INFO  Train:   47/100 ( 47%) [ 331/408 ( 81%)]  Loss: 4.281 (3.97)  LR: 2.906e-03  Time cost: 02:49/00:39 [1:19:33/3:04:11]  Acc_iter 19100       Data time: 0.00(0.01)  Forward time: 0.44(0.50)  Batch time: 0.44(0.51)
2025-07-12 12:58:55,212   INFO  Train:   47/100 ( 47%) [ 381/408 ( 93%)]  Loss: 4.212 (3.95)  LR: 2.902e-03  Time cost: 03:13/00:13 [1:19:58/3:03:14]  Acc_iter 19150       Data time: 0.00(0.01)  Forward time: 0.33(0.50)  Batch time: 0.33(0.51)
2025-07-12 12:59:06,468   INFO  Train:   47/100 ( 47%) [ 407/408 (100%)]  Loss: 3.716 (3.95)  LR: 2.900e-03  Time cost: 03:25/00:00 [1:20:10/3:01:18]  Acc_iter 19176       Data time: 0.00(0.01)  Forward time: 0.16(0.49)  Batch time: 0.16(0.50)
2025-07-12 12:59:10,938   INFO  Train:   48/100 ( 48%) [   0/408 (  0%)]  Loss: 3.037 (3.04)  LR: 2.900e-03  Time cost: 00:03/24:28 [1:20:14/21:37:33]  Acc_iter 19177       Data time: 2.24(2.24)  Forward time: 1.36(1.36)  Batch time: 3.60(3.60)
2025-07-12 12:59:22,344   INFO  Train:   48/100 ( 48%) [  23/408 (  6%)]  Loss: 2.866 (3.71)  LR: 2.899e-03  Time cost: 00:15/04:00 [1:20:25/3:45:06]  Acc_iter 19200       Data time: 0.00(0.10)  Forward time: 0.65(0.53)  Batch time: 0.65(0.63)
2025-07-12 12:59:47,860   INFO  Train:   48/100 ( 48%) [  73/408 ( 18%)]  Loss: 3.486 (3.87)  LR: 2.895e-03  Time cost: 00:40/03:03 [1:20:51/3:16:41]  Acc_iter 19250       Data time: 0.00(0.03)  Forward time: 0.49(0.51)  Batch time: 0.49(0.55)
2025-07-12 13:00:12,766   INFO  Train:   48/100 ( 48%) [ 123/408 ( 30%)]  Loss: 3.896 (3.96)  LR: 2.892e-03  Time cost: 01:05/02:30 [1:21:16/3:09:04]  Acc_iter 19300       Data time: 0.00(0.02)  Forward time: 0.42(0.51)  Batch time: 0.42(0.53)
2025-07-12 13:00:37,654   INFO  Train:   48/100 ( 48%) [ 173/408 ( 42%)]  Loss: 3.694 (3.97)  LR: 2.888e-03  Time cost: 01:30/02:01 [1:21:41/3:05:34]  Acc_iter 19350       Data time: 0.00(0.02)  Forward time: 0.36(0.50)  Batch time: 0.36(0.52)
2025-07-12 13:01:02,876   INFO  Train:   48/100 ( 48%) [ 223/408 ( 55%)]  Loss: 3.143 (3.96)  LR: 2.884e-03  Time cost: 01:55/01:35 [1:22:06/3:03:58]  Acc_iter 19400       Data time: 0.02(0.01)  Forward time: 0.63(0.50)  Batch time: 0.65(0.52)
2025-07-12 13:01:28,524   INFO  Train:   48/100 ( 48%) [ 273/408 ( 67%)]  Loss: 4.423 (3.93)  LR: 2.881e-03  Time cost: 02:21/01:09 [1:22:32/3:03:21]  Acc_iter 19450       Data time: 0.00(0.01)  Forward time: 0.55(0.50)  Batch time: 0.55(0.52)
2025-07-12 13:01:54,152   INFO  Train:   48/100 ( 48%) [ 323/408 ( 79%)]  Loss: 3.811 (3.91)  LR: 2.877e-03  Time cost: 02:46/00:43 [1:22:57/3:02:47]  Acc_iter 19500       Data time: 0.00(0.01)  Forward time: 0.51(0.50)  Batch time: 0.52(0.51)
2025-07-12 13:02:20,480   INFO  Train:   48/100 ( 48%) [ 373/408 ( 91%)]  Loss: 4.470 (3.90)  LR: 2.873e-03  Time cost: 03:13/00:18 [1:23:24/3:02:54]  Acc_iter 19550       Data time: 0.00(0.01)  Forward time: 0.68(0.51)  Batch time: 0.68(0.52)
2025-07-12 13:02:35,915   INFO  Train:   48/100 ( 48%) [ 407/408 (100%)]  Loss: 2.864 (3.90)  LR: 2.870e-03  Time cost: 03:28/00:00 [1:23:39/3:00:46]  Acc_iter 19584       Data time: 0.00(0.01)  Forward time: 0.15(0.50)  Batch time: 0.15(0.51)
2025-07-12 13:02:40,516   INFO  Train:   49/100 ( 49%) [   0/408 (  0%)]  Loss: 3.268 (3.27)  LR: 2.870e-03  Time cost: 00:03/24:55 [1:23:44/21:36:16]  Acc_iter 19585       Data time: 2.25(2.25)  Forward time: 1.42(1.42)  Batch time: 3.67(3.67)
2025-07-12 13:02:48,304   INFO  Train:   49/100 ( 49%) [  15/408 (  4%)]  Loss: 3.077 (3.67)  LR: 2.869e-03  Time cost: 00:11/04:41 [1:23:51/4:12:57]  Acc_iter 19600       Data time: 0.00(0.14)  Forward time: 0.30(0.57)  Batch time: 0.30(0.72)
2025-07-12 13:03:13,344   INFO  Train:   49/100 ( 49%) [  65/408 ( 16%)]  Loss: 3.804 (3.83)  LR: 2.865e-03  Time cost: 00:36/03:09 [1:24:16/3:14:55]  Acc_iter 19650       Data time: 0.00(0.04)  Forward time: 0.28(0.51)  Batch time: 0.29(0.55)
2025-07-12 13:03:38,508   INFO  Train:   49/100 ( 49%) [ 115/408 ( 28%)]  Loss: 3.269 (3.79)  LR: 2.861e-03  Time cost: 01:01/02:35 [1:24:42/3:06:55]  Acc_iter 19700       Data time: 0.00(0.02)  Forward time: 0.66(0.51)  Batch time: 0.67(0.53)
2025-07-12 13:04:02,928   INFO  Train:   49/100 ( 49%) [ 165/408 ( 40%)]  Loss: 3.355 (3.86)  LR: 2.857e-03  Time cost: 01:26/02:06 [1:25:06/3:01:55]  Acc_iter 19750       Data time: 0.01(0.02)  Forward time: 0.40(0.50)  Batch time: 0.41(0.52)
2025-07-12 13:04:28,050   INFO  Train:   49/100 ( 49%) [ 215/408 ( 53%)]  Loss: 2.948 (3.85)  LR: 2.853e-03  Time cost: 01:51/01:39 [1:25:31/3:00:11]  Acc_iter 19800       Data time: 0.00(0.01)  Forward time: 0.54(0.50)  Batch time: 0.54(0.51)
2025-07-12 13:04:53,458   INFO  Train:   49/100 ( 49%) [ 265/408 ( 65%)]  Loss: 3.354 (3.82)  LR: 2.849e-03  Time cost: 02:16/01:13 [1:25:57/2:59:19]  Acc_iter 19850       Data time: 0.00(0.01)  Forward time: 0.59(0.50)  Batch time: 0.60(0.51)
2025-07-12 13:05:19,165   INFO  Train:   49/100 ( 49%) [ 315/408 ( 77%)]  Loss: 3.916 (3.79)  LR: 2.845e-03  Time cost: 02:42/00:47 [1:26:22/2:58:55]  Acc_iter 19900       Data time: 0.00(0.01)  Forward time: 0.87(0.50)  Batch time: 0.87(0.51)
2025-07-12 13:05:43,882   INFO  Train:   49/100 ( 49%) [ 365/408 ( 89%)]  Loss: 4.392 (3.82)  LR: 2.840e-03  Time cost: 03:07/00:21 [1:26:47/2:57:35]  Acc_iter 19950       Data time: 0.00(0.01)  Forward time: 0.37(0.50)  Batch time: 0.37(0.51)
2025-07-12 13:06:03,100   INFO  Train:   49/100 ( 49%) [ 407/408 (100%)]  Loss: 4.110 (3.83)  LR: 2.837e-03  Time cost: 03:26/00:00 [1:27:06/2:55:19]  Acc_iter 19992       Data time: 0.00(0.01)  Forward time: 0.15(0.50)  Batch time: 0.15(0.51)
2025-07-12 13:06:08,038   INFO  Train:   50/100 ( 50%) [   0/408 (  0%)]  Loss: 4.247 (4.25)  LR: 2.837e-03  Time cost: 00:04/28:17 [1:27:11/24:02:27]  Acc_iter 19993       Data time: 3.32(3.32)  Forward time: 0.84(0.84)  Batch time: 4.16(4.16)
2025-07-12 13:06:11,708   INFO  Train:   50/100 ( 50%) [   7/408 (  2%)]  Loss: 4.631 (3.89)  LR: 2.836e-03  Time cost: 00:07/06:32 [1:27:15/5:39:18]  Acc_iter 20000       Data time: 0.00(0.42)  Forward time: 0.92(0.56)  Batch time: 0.92(0.98)
2025-07-12 13:06:36,912   INFO  Train:   50/100 ( 50%) [  57/408 ( 14%)]  Loss: 3.942 (3.82)  LR: 2.831e-03  Time cost: 00:33/03:19 [1:27:40/3:16:58]  Acc_iter 20050       Data time: 0.00(0.06)  Forward time: 0.57(0.51)  Batch time: 0.58(0.57)
2025-07-12 13:07:02,259   INFO  Train:   50/100 ( 50%) [ 107/408 ( 26%)]  Loss: 3.704 (3.85)  LR: 2.827e-03  Time cost: 00:58/02:42 [1:28:05/3:06:30]  Acc_iter 20100       Data time: 0.00(0.03)  Forward time: 0.40(0.51)  Batch time: 0.40(0.54)
2025-07-12 13:07:27,102   INFO  Train:   50/100 ( 50%) [ 157/408 ( 38%)]  Loss: 3.687 (3.82)  LR: 2.823e-03  Time cost: 01:23/02:12 [1:28:30/3:01:17]  Acc_iter 20150       Data time: 0.00(0.03)  Forward time: 0.28(0.50)  Batch time: 0.28(0.53)
2025-07-12 13:07:52,040   INFO  Train:   50/100 ( 50%) [ 207/408 ( 51%)]  Loss: 3.338 (3.84)  LR: 2.818e-03  Time cost: 01:48/01:44 [1:28:55/2:58:32]  Acc_iter 20200       Data time: 0.00(0.02)  Forward time: 0.35(0.50)  Batch time: 0.36(0.52)
2025-07-12 13:08:16,458   INFO  Train:   50/100 ( 50%) [ 257/408 ( 63%)]  Loss: 3.994 (3.83)  LR: 2.813e-03  Time cost: 02:12/01:17 [1:29:20/2:56:00]  Acc_iter 20250       Data time: 0.00(0.02)  Forward time: 0.47(0.50)  Batch time: 0.47(0.51)
2025-07-12 13:08:41,458   INFO  Train:   50/100 ( 50%) [ 307/408 ( 75%)]  Loss: 3.709 (3.81)  LR: 2.809e-03  Time cost: 02:37/00:51 [1:29:45/2:54:48]  Acc_iter 20300       Data time: 0.00(0.01)  Forward time: 0.55(0.50)  Batch time: 0.56(0.51)
2025-07-12 13:09:07,073   INFO  Train:   50/100 ( 50%) [ 357/408 ( 88%)]  Loss: 3.837 (3.83)  LR: 2.804e-03  Time cost: 03:03/00:26 [1:30:10/2:54:25]  Acc_iter 20350       Data time: 0.00(0.01)  Forward time: 0.66(0.50)  Batch time: 0.67(0.51)
2025-07-12 13:09:30,154   INFO  Train:   50/100 ( 50%) [ 407/408 (100%)]  Loss: 4.195 (3.81)  LR: 2.799e-03  Time cost: 03:26/00:00 [1:30:33/2:51:54]  Acc_iter 20400       Data time: 0.00(0.01)  Forward time: 0.15(0.49)  Batch time: 0.15(0.51)
2025-07-12 13:09:34,424   INFO  Train:   51/100 ( 51%) [   0/408 (  0%)]  Loss: 4.277 (4.28)  LR: 2.799e-03  Time cost: 00:03/23:59 [1:30:38/19:59:17]  Acc_iter 20401       Data time: 2.34(2.34)  Forward time: 1.18(1.18)  Batch time: 3.53(3.53)
2025-07-12 13:09:59,998   INFO  Train:   51/100 ( 51%) [  49/408 ( 12%)]  Loss: 3.959 (3.76)  LR: 2.794e-03  Time cost: 00:29/03:28 [1:31:03/3:17:24]  Acc_iter 20450       Data time: 0.00(0.05)  Forward time: 0.39(0.53)  Batch time: 0.39(0.58)
2025-07-12 13:10:25,251   INFO  Train:   51/100 ( 51%) [  99/408 ( 24%)]  Loss: 3.457 (3.72)  LR: 2.789e-03  Time cost: 00:54/02:47 [1:31:28/3:03:54]  Acc_iter 20500       Data time: 0.00(0.03)  Forward time: 0.25(0.52)  Batch time: 0.25(0.54)
2025-07-12 13:10:49,798   INFO  Train:   51/100 ( 51%) [ 149/408 ( 37%)]  Loss: 3.996 (3.73)  LR: 2.784e-03  Time cost: 01:18/02:16 [1:31:53/2:57:32]  Acc_iter 20550       Data time: 0.00(0.02)  Forward time: 0.47(0.51)  Batch time: 0.48(0.53)
2025-07-12 13:11:15,072   INFO  Train:   51/100 ( 51%) [ 199/408 ( 49%)]  Loss: 3.562 (3.72)  LR: 2.779e-03  Time cost: 01:44/01:48 [1:32:18/2:55:22]  Acc_iter 20600       Data time: 0.00(0.02)  Forward time: 0.35(0.51)  Batch time: 0.35(0.52)
2025-07-12 13:11:40,165   INFO  Train:   51/100 ( 51%) [ 249/408 ( 61%)]  Loss: 2.888 (3.71)  LR: 2.774e-03  Time cost: 02:09/01:22 [1:32:43/2:53:39]  Acc_iter 20650       Data time: 0.00(0.01)  Forward time: 0.63(0.50)  Batch time: 0.63(0.52)
2025-07-12 13:12:06,547   INFO  Train:   51/100 ( 51%) [ 299/408 ( 73%)]  Loss: 3.768 (3.74)  LR: 2.769e-03  Time cost: 02:35/00:56 [1:33:10/2:53:49]  Acc_iter 20700       Data time: 0.00(0.01)  Forward time: 0.69(0.51)  Batch time: 0.70(0.52)
2025-07-12 13:12:31,507   INFO  Train:   51/100 ( 51%) [ 349/408 ( 86%)]  Loss: 4.104 (3.74)  LR: 2.764e-03  Time cost: 03:00/00:30 [1:33:35/2:52:26]  Acc_iter 20750       Data time: 0.00(0.01)  Forward time: 0.45(0.51)  Batch time: 0.45(0.52)
2025-07-12 13:12:56,573   INFO  Train:   51/100 ( 51%) [ 399/408 ( 98%)]  Loss: 2.684 (3.73)  LR: 2.759e-03  Time cost: 03:25/00:04 [1:34:00/2:51:24]  Acc_iter 20800       Data time: 0.00(0.01)  Forward time: 0.41(0.50)  Batch time: 0.41(0.51)
2025-07-12 13:12:58,541   INFO  Train:   51/100 ( 51%) [ 407/408 (100%)]  Loss: 3.894 (3.72)  LR: 2.758e-03  Time cost: 03:27/00:00 [1:34:02/2:49:35]  Acc_iter 20808       Data time: 0.00(0.01)  Forward time: 0.13(0.50)  Batch time: 0.13(0.51)
2025-07-12 13:13:02,849   INFO  Train:   52/100 ( 52%) [   0/408 (  0%)]  Loss: 3.662 (3.66)  LR: 2.758e-03  Time cost: 00:03/24:03 [1:34:06/19:38:50]  Acc_iter 20809       Data time: 2.14(2.14)  Forward time: 1.40(1.40)  Batch time: 3.54(3.54)
2025-07-12 13:13:23,952   INFO  Train:   52/100 ( 52%) [  41/408 ( 10%)]  Loss: 5.608 (3.84)  LR: 2.754e-03  Time cost: 00:24/03:35 [1:34:27/3:15:05]  Acc_iter 20850       Data time: 0.00(0.05)  Forward time: 0.64(0.53)  Batch time: 0.64(0.59)
2025-07-12 13:13:48,153   INFO  Train:   52/100 ( 52%) [  91/408 ( 22%)]  Loss: 4.363 (3.70)  LR: 2.748e-03  Time cost: 00:48/02:48 [1:34:51/2:56:05]  Acc_iter 20900       Data time: 0.00(0.03)  Forward time: 0.44(0.50)  Batch time: 0.45(0.53)
2025-07-12 13:14:14,102   INFO  Train:   52/100 ( 52%) [ 141/408 ( 35%)]  Loss: 3.620 (3.61)  LR: 2.743e-03  Time cost: 01:14/02:20 [1:35:17/2:54:15]  Acc_iter 20950       Data time: 0.00(0.02)  Forward time: 0.40(0.51)  Batch time: 0.41(0.53)
2025-07-12 13:14:39,205   INFO  Train:   52/100 ( 52%) [ 191/408 ( 47%)]  Loss: 4.021 (3.67)  LR: 2.738e-03  Time cost: 01:39/01:52 [1:35:42/2:51:42]  Acc_iter 21000       Data time: 0.00(0.01)  Forward time: 0.71(0.51)  Batch time: 0.71(0.52)
2025-07-12 13:15:03,752   INFO  Train:   52/100 ( 52%) [ 241/408 ( 59%)]  Loss: 3.301 (3.62)  LR: 2.732e-03  Time cost: 02:04/01:25 [1:36:07/2:49:16]  Acc_iter 21050       Data time: 0.00(0.01)  Forward time: 0.54(0.50)  Batch time: 0.54(0.51)
2025-07-12 13:15:28,777   INFO  Train:   52/100 ( 52%) [ 291/408 ( 71%)]  Loss: 2.785 (3.63)  LR: 2.727e-03  Time cost: 02:29/00:59 [1:36:32/2:48:04]  Acc_iter 21100       Data time: 0.00(0.01)  Forward time: 0.58(0.50)  Batch time: 0.58(0.51)
2025-07-12 13:15:53,662   INFO  Train:   52/100 ( 52%) [ 341/408 ( 84%)]  Loss: 4.065 (3.64)  LR: 2.721e-03  Time cost: 02:54/00:34 [1:36:57/2:46:58]  Acc_iter 21150       Data time: 0.00(0.01)  Forward time: 0.48(0.50)  Batch time: 0.48(0.51)
2025-07-12 13:16:18,960   INFO  Train:   52/100 ( 52%) [ 391/408 ( 96%)]  Loss: 3.233 (3.65)  LR: 2.715e-03  Time cost: 03:19/00:08 [1:37:22/2:46:22]  Acc_iter 21200       Data time: 0.00(0.01)  Forward time: 0.50(0.50)  Batch time: 0.50(0.51)
2025-07-12 13:16:25,006   INFO  Train:   52/100 ( 52%) [ 407/408 (100%)]  Loss: 4.494 (3.66)  LR: 2.714e-03  Time cost: 03:25/00:00 [1:37:28/2:44:33]  Acc_iter 21216       Data time: 0.00(0.01)  Forward time: 0.17(0.50)  Batch time: 0.17(0.50)
2025-07-12 13:16:29,967   INFO  Train:   53/100 ( 53%) [   0/408 (  0%)]  Loss: 3.531 (3.53)  LR: 2.714e-03  Time cost: 00:04/29:01 [1:37:33/23:13:06]  Acc_iter 21217       Data time: 3.26(3.26)  Forward time: 1.01(1.01)  Batch time: 4.27(4.27)
2025-07-12 13:16:45,526   INFO  Train:   53/100 ( 53%) [  33/408 (  8%)]  Loss: 3.485 (3.77)  LR: 2.710e-03  Time cost: 00:19/03:38 [1:37:49/3:10:01]  Acc_iter 21250       Data time: 0.00(0.10)  Forward time: 0.51(0.48)  Batch time: 0.51(0.58)
2025-07-12 13:17:10,957   INFO  Train:   53/100 ( 53%) [  83/408 ( 20%)]  Loss: 4.971 (3.62)  LR: 2.704e-03  Time cost: 00:45/02:55 [1:38:14/2:55:06]  Acc_iter 21300       Data time: 0.00(0.04)  Forward time: 0.48(0.50)  Batch time: 0.49(0.54)
2025-07-12 13:17:35,557   INFO  Train:   53/100 ( 53%) [ 133/408 ( 33%)]  Loss: 3.453 (3.62)  LR: 2.698e-03  Time cost: 01:09/02:23 [1:38:39/2:49:00]  Acc_iter 21350       Data time: 0.00(0.03)  Forward time: 0.28(0.49)  Batch time: 0.29(0.52)
2025-07-12 13:18:00,622   INFO  Train:   53/100 ( 53%) [ 183/408 ( 45%)]  Loss: 2.691 (3.66)  LR: 2.692e-03  Time cost: 01:34/01:56 [1:39:04/2:46:48]  Acc_iter 21400       Data time: 0.00(0.02)  Forward time: 0.51(0.49)  Batch time: 0.51(0.52)
2025-07-12 13:18:25,348   INFO  Train:   53/100 ( 53%) [ 233/408 ( 57%)]  Loss: 3.840 (3.63)  LR: 2.687e-03  Time cost: 01:59/01:29 [1:39:28/2:44:54]  Acc_iter 21450       Data time: 0.00(0.02)  Forward time: 0.55(0.49)  Batch time: 0.55(0.51)
2025-07-12 13:18:50,220   INFO  Train:   53/100 ( 53%) [ 283/408 ( 69%)]  Loss: 2.927 (3.62)  LR: 2.681e-03  Time cost: 02:24/01:03 [1:39:53/2:43:41]  Acc_iter 21500       Data time: 0.00(0.02)  Forward time: 0.51(0.49)  Batch time: 0.51(0.51)
2025-07-12 13:19:15,515   INFO  Train:   53/100 ( 53%) [ 333/408 ( 82%)]  Loss: 3.525 (3.60)  LR: 2.675e-03  Time cost: 02:49/00:38 [1:40:19/2:43:07]  Acc_iter 21550       Data time: 0.01(0.01)  Forward time: 0.50(0.49)  Batch time: 0.51(0.51)
2025-07-12 13:19:39,991   INFO  Train:   53/100 ( 53%) [ 383/408 ( 94%)]  Loss: 3.652 (3.60)  LR: 2.669e-03  Time cost: 03:14/00:12 [1:40:43/2:41:55]  Acc_iter 21600       Data time: 0.00(0.01)  Forward time: 0.61(0.49)  Batch time: 0.61(0.51)
2025-07-12 13:19:50,388   INFO  Train:   53/100 ( 53%) [ 407/408 (100%)]  Loss: 3.545 (3.59)  LR: 2.666e-03  Time cost: 03:24/00:00 [1:40:54/2:40:20]  Acc_iter 21624       Data time: 0.00(0.01)  Forward time: 0.13(0.49)  Batch time: 0.14(0.50)
2025-07-12 13:19:54,579   INFO  Train:   54/100 ( 54%) [   0/408 (  0%)]  Loss: 2.578 (2.58)  LR: 2.666e-03  Time cost: 00:03/23:30 [1:40:58/18:25:04]  Acc_iter 21625       Data time: 2.04(2.04)  Forward time: 1.42(1.42)  Batch time: 3.46(3.46)
2025-07-12 13:20:07,259   INFO  Train:   54/100 ( 54%) [  25/408 (  6%)]  Loss: 2.726 (3.57)  LR: 2.663e-03  Time cost: 00:16/03:57 [1:41:10/3:18:06]  Acc_iter 21650       Data time: 0.00(0.08)  Forward time: 0.50(0.54)  Batch time: 0.50(0.62)
2025-07-12 13:20:33,062   INFO  Train:   54/100 ( 54%) [  75/408 ( 18%)]  Loss: 4.372 (3.53)  LR: 2.657e-03  Time cost: 00:41/03:03 [1:41:36/2:55:40]  Acc_iter 21700       Data time: 0.00(0.03)  Forward time: 0.64(0.52)  Batch time: 0.64(0.55)
2025-07-12 13:20:58,989   INFO  Train:   54/100 ( 54%) [ 125/408 ( 31%)]  Loss: 3.577 (3.44)  LR: 2.650e-03  Time cost: 01:07/02:32 [1:42:02/2:51:01]  Acc_iter 21750       Data time: 0.01(0.02)  Forward time: 0.41(0.52)  Batch time: 0.42(0.54)
2025-07-12 13:21:25,238   INFO  Train:   54/100 ( 54%) [ 175/408 ( 43%)]  Loss: 4.425 (3.48)  LR: 2.644e-03  Time cost: 01:34/02:04 [1:42:28/2:49:19]  Acc_iter 21800       Data time: 0.00(0.02)  Forward time: 0.33(0.52)  Batch time: 0.33(0.53)
2025-07-12 13:21:50,345   INFO  Train:   54/100 ( 54%) [ 225/408 ( 55%)]  Loss: 3.552 (3.50)  LR: 2.638e-03  Time cost: 01:59/01:36 [1:42:53/2:46:37]  Acc_iter 21850       Data time: 0.01(0.01)  Forward time: 0.61(0.51)  Batch time: 0.62(0.53)
2025-07-12 13:22:15,810   INFO  Train:   54/100 ( 54%) [ 275/408 ( 67%)]  Loss: 3.669 (3.53)  LR: 2.632e-03  Time cost: 02:24/01:09 [1:43:19/2:45:08]  Acc_iter 21900       Data time: 0.00(0.01)  Forward time: 0.35(0.51)  Batch time: 0.35(0.52)
2025-07-12 13:22:42,117   INFO  Train:   54/100 ( 54%) [ 325/408 ( 80%)]  Loss: 3.332 (3.56)  LR: 2.625e-03  Time cost: 02:50/00:43 [1:43:45/2:44:47]  Acc_iter 21950       Data time: 0.00(0.01)  Forward time: 0.48(0.51)  Batch time: 0.48(0.52)
2025-07-12 13:23:07,905   INFO  Train:   54/100 ( 54%) [ 375/408 ( 92%)]  Loss: 2.706 (3.55)  LR: 2.619e-03  Time cost: 03:16/00:17 [1:44:11/2:43:59]  Acc_iter 22000       Data time: 0.00(0.01)  Forward time: 0.76(0.51)  Batch time: 0.77(0.52)
2025-07-12 13:23:22,125   INFO  Train:   54/100 ( 54%) [ 407/408 (100%)]  Loss: 6.039 (3.55)  LR: 2.615e-03  Time cost: 03:31/00:00 [1:44:25/2:41:46]  Acc_iter 22032       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 13:23:26,756   INFO  Train:   55/100 ( 55%) [   0/408 (  0%)]  Loss: 3.676 (3.68)  LR: 2.615e-03  Time cost: 00:03/26:11 [1:44:30/20:05:04]  Acc_iter 22033       Data time: 2.95(2.95)  Forward time: 0.90(0.90)  Batch time: 3.85(3.85)
2025-07-12 13:23:35,193   INFO  Train:   55/100 ( 55%) [  17/408 (  4%)]  Loss: 2.586 (3.41)  LR: 2.613e-03  Time cost: 00:12/04:26 [1:44:38/3:33:21]  Acc_iter 22050       Data time: 0.00(0.17)  Forward time: 0.31(0.51)  Batch time: 0.32(0.68)
2025-07-12 13:24:00,271   INFO  Train:   55/100 ( 55%) [  67/408 ( 16%)]  Loss: 2.451 (3.53)  LR: 2.606e-03  Time cost: 00:37/03:07 [1:45:03/2:51:16]  Acc_iter 22100       Data time: 0.00(0.05)  Forward time: 0.39(0.50)  Batch time: 0.40(0.55)
2025-07-12 13:24:25,253   INFO  Train:   55/100 ( 55%) [ 117/408 ( 29%)]  Loss: 4.684 (3.56)  LR: 2.600e-03  Time cost: 01:02/02:33 [1:45:28/2:44:14]  Acc_iter 22150       Data time: 0.00(0.03)  Forward time: 0.43(0.50)  Batch time: 0.44(0.53)
2025-07-12 13:24:50,863   INFO  Train:   55/100 ( 55%) [ 167/408 ( 41%)]  Loss: 3.880 (3.55)  LR: 2.593e-03  Time cost: 01:27/02:06 [1:45:54/2:42:18]  Acc_iter 22200       Data time: 0.00(0.02)  Forward time: 0.40(0.50)  Batch time: 0.41(0.52)
2025-07-12 13:25:16,061   INFO  Train:   55/100 ( 55%) [ 217/408 ( 53%)]  Loss: 2.535 (3.55)  LR: 2.586e-03  Time cost: 01:53/01:39 [1:46:19/2:40:29]  Acc_iter 22250       Data time: 0.00(0.02)  Forward time: 0.40(0.50)  Batch time: 0.41(0.52)
2025-07-12 13:25:41,156   INFO  Train:   55/100 ( 55%) [ 267/408 ( 65%)]  Loss: 2.752 (3.52)  LR: 2.580e-03  Time cost: 02:18/01:12 [1:46:44/2:39:04]  Acc_iter 22300       Data time: 0.00(0.02)  Forward time: 0.45(0.50)  Batch time: 0.46(0.52)
2025-07-12 13:26:06,326   INFO  Train:   55/100 ( 55%) [ 317/408 ( 78%)]  Loss: 3.240 (3.53)  LR: 2.573e-03  Time cost: 02:43/00:46 [1:47:09/2:38:02]  Acc_iter 22350       Data time: 0.00(0.01)  Forward time: 0.67(0.50)  Batch time: 0.67(0.51)
2025-07-12 13:26:31,088   INFO  Train:   55/100 ( 55%) [ 367/408 ( 90%)]  Loss: 4.629 (3.52)  LR: 2.566e-03  Time cost: 03:08/00:20 [1:47:34/2:36:49]  Acc_iter 22400       Data time: 0.00(0.01)  Forward time: 0.52(0.50)  Batch time: 0.53(0.51)
2025-07-12 13:26:49,540   INFO  Train:   55/100 ( 55%) [ 407/408 (100%)]  Loss: 4.215 (3.54)  LR: 2.561e-03  Time cost: 03:26/00:00 [1:47:53/2:34:59]  Acc_iter 22440       Data time: 0.00(0.01)  Forward time: 0.13(0.50)  Batch time: 0.13(0.51)
2025-07-12 13:26:53,844   INFO  Train:   56/100 ( 56%) [   0/408 (  0%)]  Loss: 3.288 (3.29)  LR: 2.561e-03  Time cost: 00:03/24:26 [1:47:57/18:19:38]  Acc_iter 22441       Data time: 2.97(2.97)  Forward time: 0.62(0.62)  Batch time: 3.59(3.59)
2025-07-12 13:26:58,160   INFO  Train:   56/100 ( 56%) [   9/408 (  2%)]  Loss: 3.980 (4.11)  LR: 2.559e-03  Time cost: 00:07/05:15 [1:48:01/4:01:54]  Acc_iter 22450       Data time: 0.00(0.30)  Forward time: 0.29(0.49)  Batch time: 0.29(0.79)
2025-07-12 13:27:23,295   INFO  Train:   56/100 ( 56%) [  59/408 ( 14%)]  Loss: 3.357 (3.80)  LR: 2.553e-03  Time cost: 00:33/03:12 [1:48:26/2:47:59]  Acc_iter 22500       Data time: 0.00(0.05)  Forward time: 0.48(0.50)  Batch time: 0.49(0.55)
2025-07-12 13:27:48,597   INFO  Train:   56/100 ( 56%) [ 109/408 ( 27%)]  Loss: 4.307 (3.65)  LR: 2.546e-03  Time cost: 00:58/02:38 [1:48:52/2:41:20]  Acc_iter 22550       Data time: 0.00(0.03)  Forward time: 0.57(0.50)  Batch time: 0.57(0.53)
2025-07-12 13:28:14,210   INFO  Train:   56/100 ( 56%) [ 159/408 ( 39%)]  Loss: 4.293 (3.59)  LR: 2.539e-03  Time cost: 01:23/02:10 [1:49:17/2:39:10]  Acc_iter 22600       Data time: 0.00(0.02)  Forward time: 0.34(0.50)  Batch time: 0.35(0.52)
2025-07-12 13:28:40,070   INFO  Train:   56/100 ( 56%) [ 209/408 ( 51%)]  Loss: 3.618 (3.59)  LR: 2.532e-03  Time cost: 01:49/01:44 [1:49:43/2:38:12]  Acc_iter 22650       Data time: 0.00(0.02)  Forward time: 0.35(0.50)  Batch time: 0.35(0.52)
2025-07-12 13:29:06,122   INFO  Train:   56/100 ( 56%) [ 259/408 ( 63%)]  Loss: 3.065 (3.56)  LR: 2.525e-03  Time cost: 02:15/01:17 [1:50:09/2:37:39]  Acc_iter 22700       Data time: 0.00(0.02)  Forward time: 0.85(0.51)  Batch time: 0.85(0.52)
2025-07-12 13:29:31,247   INFO  Train:   56/100 ( 56%) [ 309/408 ( 76%)]  Loss: 3.450 (3.54)  LR: 2.518e-03  Time cost: 02:40/00:51 [1:50:34/2:36:14]  Acc_iter 22750       Data time: 0.00(0.01)  Forward time: 0.57(0.51)  Batch time: 0.57(0.52)
2025-07-12 13:29:57,261   INFO  Train:   56/100 ( 56%) [ 359/408 ( 88%)]  Loss: 2.432 (3.50)  LR: 2.511e-03  Time cost: 03:07/00:25 [1:51:00/2:35:51]  Acc_iter 22800       Data time: 0.00(0.01)  Forward time: 0.32(0.51)  Batch time: 0.32(0.52)
2025-07-12 13:30:20,302   INFO  Train:   56/100 ( 56%) [ 407/408 (100%)]  Loss: 2.305 (3.49)  LR: 2.504e-03  Time cost: 03:30/00:00 [1:51:23/2:34:02]  Acc_iter 22848       Data time: 0.00(0.01)  Forward time: 0.15(0.50)  Batch time: 0.15(0.51)
2025-07-12 13:30:25,361   INFO  Train:   57/100 ( 57%) [   0/408 (  0%)]  Loss: 3.053 (3.05)  LR: 2.504e-03  Time cost: 00:04/28:21 [1:51:29/20:47:55]  Acc_iter 22849       Data time: 3.18(3.18)  Forward time: 0.99(0.99)  Batch time: 4.17(4.17)
2025-07-12 13:30:25,798   INFO  Train:   57/100 ( 57%) [   1/408 (  0%)]  Loss: 2.410 (2.73)  LR: 2.504e-03  Time cost: 00:04/15:37 [1:51:29/11:29:20]  Acc_iter 22850       Data time: 0.01(1.59)  Forward time: 0.43(0.71)  Batch time: 0.44(2.30)
2025-07-12 13:30:50,982   INFO  Train:   57/100 ( 57%) [  51/408 ( 12%)]  Loss: 3.616 (3.49)  LR: 2.496e-03  Time cost: 00:29/03:24 [1:51:54/2:50:55]  Acc_iter 22900       Data time: 0.00(0.07)  Forward time: 0.30(0.51)  Batch time: 0.31(0.57)
2025-07-12 13:31:17,335   INFO  Train:   57/100 ( 57%) [ 101/408 ( 25%)]  Loss: 3.518 (3.48)  LR: 2.489e-03  Time cost: 00:56/02:48 [1:52:20/2:43:45]  Acc_iter 22950       Data time: 0.00(0.04)  Forward time: 0.66(0.51)  Batch time: 0.67(0.55)
2025-07-12 13:31:42,206   INFO  Train:   57/100 ( 57%) [ 151/408 ( 37%)]  Loss: 3.535 (3.46)  LR: 2.482e-03  Time cost: 01:21/02:16 [1:52:45/2:38:07]  Acc_iter 23000       Data time: 0.00(0.03)  Forward time: 0.54(0.51)  Batch time: 0.54(0.53)
2025-07-12 13:32:07,580   INFO  Train:   57/100 ( 57%) [ 201/408 ( 49%)]  Loss: 4.770 (3.48)  LR: 2.475e-03  Time cost: 01:46/01:49 [1:53:11/2:35:49]  Acc_iter 23050       Data time: 0.00(0.02)  Forward time: 0.44(0.51)  Batch time: 0.44(0.53)
2025-07-12 13:32:32,146   INFO  Train:   57/100 ( 57%) [ 251/408 ( 62%)]  Loss: 2.801 (3.45)  LR: 2.467e-03  Time cost: 02:10/01:21 [1:53:35/2:33:18]  Acc_iter 23100       Data time: 0.00(0.02)  Forward time: 0.44(0.50)  Batch time: 0.45(0.52)
2025-07-12 13:32:57,089   INFO  Train:   57/100 ( 57%) [ 301/408 ( 74%)]  Loss: 3.924 (3.45)  LR: 2.460e-03  Time cost: 02:35/00:55 [1:54:00/2:31:51]  Acc_iter 23150       Data time: 0.00(0.01)  Forward time: 0.33(0.50)  Batch time: 0.33(0.52)
2025-07-12 13:33:22,409   INFO  Train:   57/100 ( 57%) [ 351/408 ( 86%)]  Loss: 3.643 (3.46)  LR: 2.452e-03  Time cost: 03:01/00:29 [1:54:26/2:31:01]  Acc_iter 23200       Data time: 0.00(0.01)  Forward time: 0.64(0.50)  Batch time: 0.64(0.51)
2025-07-12 13:33:46,938   INFO  Train:   57/100 ( 57%) [ 401/408 ( 98%)]  Loss: 2.658 (3.45)  LR: 2.445e-03  Time cost: 03:25/00:03 [1:54:50/2:29:42]  Acc_iter 23250       Data time: 0.00(0.01)  Forward time: 0.21(0.50)  Batch time: 0.21(0.51)
2025-07-12 13:33:48,464   INFO  Train:   57/100 ( 57%) [ 407/408 (100%)]  Loss: 2.876 (3.45)  LR: 2.444e-03  Time cost: 03:27/00:00 [1:54:52/2:28:33]  Acc_iter 23256       Data time: 0.00(0.01)  Forward time: 0.17(0.50)  Batch time: 0.17(0.51)
2025-07-12 13:33:53,473   INFO  Train:   58/100 ( 58%) [   0/408 (  0%)]  Loss: 2.753 (2.75)  LR: 2.444e-03  Time cost: 00:04/28:04 [1:54:57/20:07:29]  Acc_iter 23257       Data time: 2.43(2.43)  Forward time: 1.70(1.70)  Batch time: 4.13(4.13)
2025-07-12 13:34:16,037   INFO  Train:   58/100 ( 58%) [  43/408 ( 11%)]  Loss: 3.589 (3.26)  LR: 2.438e-03  Time cost: 00:26/03:41 [1:55:19/2:56:57]  Acc_iter 23300       Data time: 0.00(0.06)  Forward time: 0.77(0.55)  Batch time: 0.78(0.61)
2025-07-12 13:34:40,957   INFO  Train:   58/100 ( 58%) [  93/408 ( 23%)]  Loss: 3.516 (3.43)  LR: 2.430e-03  Time cost: 00:51/02:52 [1:55:44/2:39:41]  Acc_iter 23350       Data time: 0.00(0.03)  Forward time: 0.39(0.52)  Batch time: 0.39(0.55)
2025-07-12 13:35:06,427   INFO  Train:   58/100 ( 58%) [ 143/408 ( 35%)]  Loss: 3.218 (3.44)  LR: 2.422e-03  Time cost: 01:17/02:21 [1:56:10/2:35:14]  Acc_iter 23400       Data time: 0.00(0.02)  Forward time: 0.31(0.51)  Batch time: 0.32(0.54)
2025-07-12 13:35:33,045   INFO  Train:   58/100 ( 58%) [ 193/408 ( 47%)]  Loss: 3.314 (3.43)  LR: 2.415e-03  Time cost: 01:43/01:54 [1:56:36/2:34:34]  Acc_iter 23450       Data time: 0.00(0.02)  Forward time: 0.48(0.52)  Batch time: 0.49(0.53)
2025-07-12 13:35:58,035   INFO  Train:   58/100 ( 58%) [ 243/408 ( 60%)]  Loss: 3.193 (3.43)  LR: 2.407e-03  Time cost: 02:08/01:27 [1:57:01/2:32:04]  Acc_iter 23500       Data time: 0.00(0.01)  Forward time: 0.57(0.51)  Batch time: 0.57(0.53)
2025-07-12 13:36:23,741   INFO  Train:   58/100 ( 58%) [ 293/408 ( 72%)]  Loss: 2.958 (3.40)  LR: 2.399e-03  Time cost: 02:34/01:00 [1:57:27/2:30:59]  Acc_iter 23550       Data time: 0.00(0.01)  Forward time: 0.42(0.51)  Batch time: 0.43(0.53)
2025-07-12 13:36:49,566   INFO  Train:   58/100 ( 58%) [ 343/408 ( 84%)]  Loss: 2.380 (3.37)  LR: 2.392e-03  Time cost: 03:00/00:34 [1:57:53/2:30:11]  Acc_iter 23600       Data time: 0.00(0.01)  Forward time: 0.48(0.51)  Batch time: 0.49(0.52)
2025-07-12 13:37:15,463   INFO  Train:   58/100 ( 58%) [ 393/408 ( 96%)]  Loss: 2.647 (3.37)  LR: 2.384e-03  Time cost: 03:26/00:07 [1:58:19/2:29:32]  Acc_iter 23650       Data time: 0.00(0.01)  Forward time: 0.31(0.51)  Batch time: 0.32(0.52)
2025-07-12 13:37:20,878   INFO  Train:   58/100 ( 58%) [ 407/408 (100%)]  Loss: 3.245 (3.36)  LR: 2.382e-03  Time cost: 03:31/00:00 [1:58:24/2:28:04]  Acc_iter 23664       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 13:37:25,485   INFO  Train:   59/100 ( 59%) [   0/408 (  0%)]  Loss: 4.314 (4.31)  LR: 2.382e-03  Time cost: 00:03/25:59 [1:58:29/18:11:30]  Acc_iter 23665       Data time: 3.02(3.02)  Forward time: 0.80(0.80)  Batch time: 3.82(3.82)
2025-07-12 13:37:43,758   INFO  Train:   59/100 ( 59%) [  35/408 (  9%)]  Loss: 3.184 (3.41)  LR: 2.376e-03  Time cost: 00:22/03:48 [1:58:47/2:54:55]  Acc_iter 23700       Data time: 0.04(0.09)  Forward time: 0.33(0.52)  Batch time: 0.37(0.61)
2025-07-12 13:38:09,499   INFO  Train:   59/100 ( 59%) [  85/408 ( 21%)]  Loss: 3.872 (3.38)  LR: 2.368e-03  Time cost: 00:47/02:59 [1:59:13/2:38:04]  Acc_iter 23750       Data time: 0.01(0.04)  Forward time: 0.66(0.52)  Batch time: 0.67(0.56)
2025-07-12 13:38:35,860   INFO  Train:   59/100 ( 59%) [ 135/408 ( 33%)]  Loss: 3.242 (3.32)  LR: 2.361e-03  Time cost: 01:14/02:28 [1:59:39/2:34:35]  Acc_iter 23800       Data time: 0.00(0.03)  Forward time: 0.50(0.52)  Batch time: 0.51(0.55)
2025-07-12 13:39:01,950   INFO  Train:   59/100 ( 59%) [ 185/408 ( 45%)]  Loss: 4.271 (3.40)  LR: 2.353e-03  Time cost: 01:40/02:00 [2:00:05/2:32:19]  Acc_iter 23850       Data time: 0.00(0.02)  Forward time: 0.37(0.52)  Batch time: 0.37(0.54)
2025-07-12 13:39:26,963   INFO  Train:   59/100 ( 59%) [ 235/408 ( 58%)]  Loss: 4.239 (3.38)  LR: 2.345e-03  Time cost: 02:05/01:31 [2:00:30/2:29:33]  Acc_iter 23900       Data time: 0.00(0.02)  Forward time: 0.52(0.51)  Batch time: 0.52(0.53)
2025-07-12 13:39:51,901   INFO  Train:   59/100 ( 59%) [ 285/408 ( 70%)]  Loss: 3.150 (3.34)  LR: 2.337e-03  Time cost: 02:30/01:04 [2:00:55/2:27:31]  Acc_iter 23950       Data time: 0.00(0.01)  Forward time: 0.34(0.51)  Batch time: 0.34(0.53)
2025-07-12 13:40:16,443   INFO  Train:   59/100 ( 59%) [ 335/408 ( 82%)]  Loss: 2.212 (3.34)  LR: 2.329e-03  Time cost: 02:54/00:37 [2:01:20/2:25:39]  Acc_iter 24000       Data time: 0.00(0.01)  Forward time: 0.75(0.51)  Batch time: 0.75(0.52)
2025-07-12 13:40:42,238   INFO  Train:   59/100 ( 59%) [ 385/408 ( 94%)]  Loss: 6.049 (3.32)  LR: 2.321e-03  Time cost: 03:20/00:11 [2:01:45/2:25:04]  Acc_iter 24050       Data time: 0.00(0.01)  Forward time: 0.51(0.51)  Batch time: 0.51(0.52)
2025-07-12 13:40:51,198   INFO  Train:   59/100 ( 59%) [ 407/408 (100%)]  Loss: 6.229 (3.33)  LR: 2.317e-03  Time cost: 03:29/00:00 [2:01:54/2:23:11]  Acc_iter 24072       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.14(0.51)
2025-07-12 13:40:55,226   INFO  Train:   60/100 ( 60%) [   0/408 (  0%)]  Loss: 2.747 (2.75)  LR: 2.317e-03  Time cost: 00:03/21:21 [2:01:58/14:35:29]  Acc_iter 24073       Data time: 1.98(1.98)  Forward time: 1.16(1.16)  Batch time: 3.14(3.14)
2025-07-12 13:41:09,866   INFO  Train:   60/100 ( 60%) [  27/408 (  7%)]  Loss: 3.107 (3.23)  LR: 2.313e-03  Time cost: 00:17/04:01 [2:02:13/2:56:45]  Acc_iter 24100       Data time: 0.00(0.07)  Forward time: 0.36(0.56)  Batch time: 0.37(0.63)
2025-07-12 13:41:36,379   INFO  Train:   60/100 ( 60%) [  77/408 ( 19%)]  Loss: 4.453 (3.28)  LR: 2.304e-03  Time cost: 00:44/03:07 [2:02:40/2:37:35]  Acc_iter 24150       Data time: 0.00(0.03)  Forward time: 0.37(0.54)  Batch time: 0.38(0.57)
2025-07-12 13:42:02,582   INFO  Train:   60/100 ( 60%) [ 127/408 ( 31%)]  Loss: 6.068 (3.33)  LR: 2.296e-03  Time cost: 01:10/02:34 [2:03:06/2:32:22]  Acc_iter 24200       Data time: 0.00(0.02)  Forward time: 0.42(0.53)  Batch time: 0.42(0.55)
2025-07-12 13:42:29,159   INFO  Train:   60/100 ( 60%) [ 177/408 ( 43%)]  Loss: 3.786 (3.33)  LR: 2.288e-03  Time cost: 01:37/02:05 [2:03:32/2:30:26]  Acc_iter 24250       Data time: 0.00(0.02)  Forward time: 0.58(0.53)  Batch time: 0.59(0.55)
2025-07-12 13:42:54,412   INFO  Train:   60/100 ( 60%) [ 227/408 ( 56%)]  Loss: 4.154 (3.28)  LR: 2.280e-03  Time cost: 02:02/01:37 [2:03:58/2:27:33]  Acc_iter 24300       Data time: 0.01(0.01)  Forward time: 0.47(0.52)  Batch time: 0.49(0.54)
2025-07-12 13:43:19,950   INFO  Train:   60/100 ( 60%) [ 277/408 ( 68%)]  Loss: 2.575 (3.27)  LR: 2.272e-03  Time cost: 02:27/01:09 [2:04:23/2:25:50]  Acc_iter 24350       Data time: 0.00(0.01)  Forward time: 0.39(0.52)  Batch time: 0.39(0.53)
2025-07-12 13:43:45,302   INFO  Train:   60/100 ( 60%) [ 327/408 ( 80%)]  Loss: 2.621 (3.25)  LR: 2.263e-03  Time cost: 02:53/00:42 [2:04:48/2:24:21]  Acc_iter 24400       Data time: 0.00(0.01)  Forward time: 0.62(0.52)  Batch time: 0.62(0.53)
2025-07-12 13:44:11,031   INFO  Train:   60/100 ( 60%) [ 377/408 ( 92%)]  Loss: 2.921 (3.24)  LR: 2.255e-03  Time cost: 03:18/00:16 [2:05:14/2:23:25]  Acc_iter 24450       Data time: 0.00(0.01)  Forward time: 0.66(0.52)  Batch time: 0.66(0.53)
2025-07-12 13:44:24,361   INFO  Train:   60/100 ( 60%) [ 407/408 (100%)]  Loss: 2.656 (3.25)  LR: 2.250e-03  Time cost: 03:32/00:00 [2:05:28/2:21:31]  Acc_iter 24480       Data time: 0.00(0.01)  Forward time: 0.13(0.51)  Batch time: 0.14(0.52)
2025-07-12 13:44:28,965   INFO  Train:   61/100 ( 61%) [   0/408 (  0%)]  Loss: 3.095 (3.10)  LR: 2.250e-03  Time cost: 00:03/24:57 [2:05:32/16:38:29]  Acc_iter 24481       Data time: 2.23(2.23)  Forward time: 1.44(1.44)  Batch time: 3.67(3.67)
2025-07-12 13:44:38,525   INFO  Train:   61/100 ( 61%) [  19/408 (  5%)]  Loss: 3.486 (3.10)  LR: 2.247e-03  Time cost: 00:13/04:17 [2:05:42/2:59:44]  Acc_iter 24500       Data time: 0.00(0.12)  Forward time: 0.53(0.55)  Batch time: 0.53(0.66)
2025-07-12 13:45:05,171   INFO  Train:   61/100 ( 61%) [  69/408 ( 17%)]  Loss: 3.083 (3.30)  LR: 2.238e-03  Time cost: 00:39/03:13 [2:06:08/2:34:17]  Acc_iter 24550       Data time: 0.00(0.04)  Forward time: 0.46(0.53)  Batch time: 0.46(0.57)
2025-07-12 13:45:31,297   INFO  Train:   61/100 ( 61%) [ 119/408 ( 29%)]  Loss: 2.638 (3.24)  LR: 2.230e-03  Time cost: 01:06/02:38 [2:06:34/2:28:30]  Acc_iter 24600       Data time: 0.00(0.02)  Forward time: 0.80(0.53)  Batch time: 0.80(0.55)
2025-07-12 13:45:56,663   INFO  Train:   61/100 ( 61%) [ 169/408 ( 41%)]  Loss: 2.401 (3.26)  LR: 2.222e-03  Time cost: 01:31/02:08 [2:07:00/2:24:40]  Acc_iter 24650       Data time: 0.00(0.02)  Forward time: 0.36(0.52)  Batch time: 0.36(0.54)
2025-07-12 13:46:22,668   INFO  Train:   61/100 ( 61%) [ 219/408 ( 54%)]  Loss: 2.714 (3.23)  LR: 2.213e-03  Time cost: 01:57/01:40 [2:07:26/2:23:10]  Acc_iter 24700       Data time: 0.00(0.01)  Forward time: 0.77(0.52)  Batch time: 0.77(0.53)
2025-07-12 13:46:47,623   INFO  Train:   61/100 ( 61%) [ 269/408 ( 66%)]  Loss: 2.901 (3.21)  LR: 2.205e-03  Time cost: 02:22/01:13 [2:07:51/2:21:01]  Acc_iter 24750       Data time: 0.01(0.01)  Forward time: 0.28(0.51)  Batch time: 0.30(0.53)
2025-07-12 13:47:12,794   INFO  Train:   61/100 ( 61%) [ 319/408 ( 78%)]  Loss: 3.713 (3.22)  LR: 2.196e-03  Time cost: 02:47/00:46 [2:08:16/2:19:35]  Acc_iter 24800       Data time: 0.00(0.01)  Forward time: 0.43(0.51)  Batch time: 0.43(0.52)
2025-07-12 13:47:38,147   INFO  Train:   61/100 ( 61%) [ 369/408 ( 90%)]  Loss: 4.009 (3.21)  LR: 2.188e-03  Time cost: 03:12/00:20 [2:08:41/2:18:34]  Acc_iter 24850       Data time: 0.00(0.01)  Forward time: 0.49(0.51)  Batch time: 0.49(0.52)
2025-07-12 13:47:55,477   INFO  Train:   61/100 ( 61%) [ 407/408 (100%)]  Loss: 3.491 (3.20)  LR: 2.181e-03  Time cost: 03:30/00:00 [2:08:59/2:16:37]  Acc_iter 24888       Data time: 0.00(0.01)  Forward time: 0.16(0.51)  Batch time: 0.17(0.52)
2025-07-12 13:47:59,693   INFO  Train:   62/100 ( 62%) [   0/408 (  0%)]  Loss: 3.580 (3.58)  LR: 2.181e-03  Time cost: 00:03/22:39 [2:09:03/14:43:44]  Acc_iter 24889       Data time: 2.23(2.23)  Forward time: 1.10(1.10)  Batch time: 3.33(3.33)
2025-07-12 13:48:06,075   INFO  Train:   62/100 ( 62%) [  11/408 (  3%)]  Loss: 3.663 (3.16)  LR: 2.179e-03  Time cost: 00:09/05:21 [2:09:09/3:34:32]  Acc_iter 24900       Data time: 0.00(0.19)  Forward time: 0.43(0.62)  Batch time: 0.43(0.81)
2025-07-12 13:48:31,488   INFO  Train:   62/100 ( 62%) [  61/408 ( 15%)]  Loss: 2.919 (3.29)  LR: 2.171e-03  Time cost: 00:35/03:16 [2:09:35/2:29:40]  Acc_iter 24950       Data time: 0.00(0.04)  Forward time: 0.31(0.53)  Batch time: 0.32(0.57)
2025-07-12 13:48:58,058   INFO  Train:   62/100 ( 62%) [ 111/408 ( 27%)]  Loss: 3.636 (3.24)  LR: 2.162e-03  Time cost: 01:01/02:43 [2:10:01/2:25:04]  Acc_iter 25000       Data time: 0.00(0.02)  Forward time: 0.88(0.53)  Batch time: 0.88(0.55)
2025-07-12 13:49:22,920   INFO  Train:   62/100 ( 62%) [ 161/408 ( 39%)]  Loss: 2.374 (3.23)  LR: 2.153e-03  Time cost: 01:26/02:11 [2:10:26/2:20:15]  Acc_iter 25050       Data time: 0.00(0.02)  Forward time: 0.66(0.52)  Batch time: 0.66(0.53)
2025-07-12 13:49:48,357   INFO  Train:   62/100 ( 62%) [ 211/408 ( 52%)]  Loss: 2.821 (3.21)  LR: 2.145e-03  Time cost: 01:51/01:44 [2:10:52/2:18:14]  Acc_iter 25100       Data time: 0.00(0.01)  Forward time: 0.26(0.51)  Batch time: 0.26(0.53)
2025-07-12 13:50:12,957   INFO  Train:   62/100 ( 62%) [ 261/408 ( 64%)]  Loss: 3.439 (3.19)  LR: 2.136e-03  Time cost: 02:16/01:16 [2:11:16/2:15:59]  Acc_iter 25150       Data time: 0.00(0.01)  Forward time: 0.41(0.51)  Batch time: 0.41(0.52)
2025-07-12 13:50:39,125   INFO  Train:   62/100 ( 62%) [ 311/408 ( 76%)]  Loss: 4.278 (3.20)  LR: 2.127e-03  Time cost: 02:42/00:50 [2:11:42/2:15:38]  Acc_iter 25200       Data time: 0.00(0.01)  Forward time: 0.64(0.51)  Batch time: 0.64(0.52)
2025-07-12 13:51:04,777   INFO  Train:   62/100 ( 62%) [ 361/408 ( 88%)]  Loss: 2.932 (3.19)  LR: 2.118e-03  Time cost: 03:08/00:24 [2:12:08/2:14:54]  Acc_iter 25250       Data time: 0.00(0.01)  Forward time: 0.67(0.51)  Batch time: 0.67(0.52)
2025-07-12 13:51:26,335   INFO  Train:   62/100 ( 62%) [ 407/408 (100%)]  Loss: 2.256 (3.19)  LR: 2.110e-03  Time cost: 03:29/00:00 [2:12:29/2:12:59]  Acc_iter 25296       Data time: 0.00(0.01)  Forward time: 0.12(0.51)  Batch time: 0.12(0.51)
2025-07-12 13:51:30,693   INFO  Train:   63/100 ( 63%) [   0/408 (  0%)]  Loss: 2.792 (2.79)  LR: 2.110e-03  Time cost: 00:03/23:39 [2:12:34/14:59:10]  Acc_iter 25297       Data time: 2.77(2.77)  Forward time: 0.71(0.71)  Batch time: 3.48(3.48)
2025-07-12 13:51:32,505   INFO  Train:   63/100 ( 63%) [   3/408 (  1%)]  Loss: 3.136 (3.39)  LR: 2.110e-03  Time cost: 00:05/08:55 [2:12:36/5:41:46]  Acc_iter 25300       Data time: 0.00(0.70)  Forward time: 0.44(0.63)  Batch time: 0.44(1.32)
2025-07-12 13:51:57,983   INFO  Train:   63/100 ( 63%) [  53/408 ( 13%)]  Loss: 3.144 (3.18)  LR: 2.101e-03  Time cost: 00:30/03:22 [2:13:01/2:26:44]  Acc_iter 25350       Data time: 0.00(0.06)  Forward time: 0.49(0.51)  Batch time: 0.49(0.57)
2025-07-12 13:52:22,886   INFO  Train:   63/100 ( 63%) [ 103/408 ( 25%)]  Loss: 3.494 (3.16)  LR: 2.092e-03  Time cost: 00:55/02:43 [2:13:26/2:17:24]  Acc_iter 25400       Data time: 0.00(0.03)  Forward time: 0.51(0.50)  Batch time: 0.52(0.54)
2025-07-12 13:52:47,978   INFO  Train:   63/100 ( 63%) [ 153/408 ( 38%)]  Loss: 3.589 (3.19)  LR: 2.083e-03  Time cost: 01:20/02:13 [2:13:51/2:14:10]  Acc_iter 25450       Data time: 0.00(0.02)  Forward time: 0.63(0.50)  Batch time: 0.64(0.52)
2025-07-12 13:53:13,193   INFO  Train:   63/100 ( 63%) [ 203/408 ( 50%)]  Loss: 3.883 (3.16)  LR: 2.074e-03  Time cost: 01:45/01:46 [2:14:16/2:12:28]  Acc_iter 25500       Data time: 0.00(0.02)  Forward time: 0.31(0.50)  Batch time: 0.31(0.52)
2025-07-12 13:53:38,626   INFO  Train:   63/100 ( 63%) [ 253/408 ( 62%)]  Loss: 2.678 (3.14)  LR: 2.065e-03  Time cost: 02:11/01:20 [2:14:42/2:11:30]  Acc_iter 25550       Data time: 0.00(0.01)  Forward time: 0.47(0.50)  Batch time: 0.48(0.52)
2025-07-12 13:54:03,767   INFO  Train:   63/100 ( 63%) [ 303/408 ( 74%)]  Loss: 2.556 (3.13)  LR: 2.056e-03  Time cost: 02:36/00:54 [2:15:07/2:10:28]  Acc_iter 25600       Data time: 0.00(0.01)  Forward time: 0.40(0.50)  Batch time: 0.40(0.51)
2025-07-12 13:54:29,255   INFO  Train:   63/100 ( 63%) [ 353/408 ( 87%)]  Loss: 3.400 (3.14)  LR: 2.047e-03  Time cost: 03:02/00:28 [2:15:32/2:09:51]  Acc_iter 25650       Data time: 0.00(0.01)  Forward time: 0.89(0.50)  Batch time: 0.90(0.51)
2025-07-12 13:54:53,920   INFO  Train:   63/100 ( 63%) [ 403/408 ( 99%)]  Loss: 4.948 (3.15)  LR: 2.038e-03  Time cost: 03:26/00:02 [2:15:57/2:08:46]  Acc_iter 25700       Data time: 0.00(0.01)  Forward time: 0.22(0.50)  Batch time: 0.22(0.51)
2025-07-12 13:54:54,808   INFO  Train:   63/100 ( 63%) [ 407/408 (100%)]  Loss: 5.999 (3.15)  LR: 2.038e-03  Time cost: 03:27/00:00 [2:15:58/2:08:01]  Acc_iter 25704       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.14(0.51)
2025-07-12 13:54:58,945   INFO  Train:   64/100 ( 64%) [   0/408 (  0%)]  Loss: 2.597 (2.60)  LR: 2.038e-03  Time cost: 00:03/22:24 [2:16:02/13:49:14]  Acc_iter 25705       Data time: 1.92(1.92)  Forward time: 1.37(1.37)  Batch time: 3.30(3.30)
2025-07-12 13:55:22,432   INFO  Train:   64/100 ( 64%) [  45/408 ( 11%)]  Loss: 2.608 (3.17)  LR: 2.029e-03  Time cost: 00:26/03:31 [2:16:26/2:26:03]  Acc_iter 25750       Data time: 0.00(0.05)  Forward time: 0.60(0.53)  Batch time: 0.60(0.58)
2025-07-12 13:55:47,391   INFO  Train:   64/100 ( 64%) [  95/408 ( 23%)]  Loss: 4.070 (3.13)  LR: 2.020e-03  Time cost: 00:51/02:48 [2:16:51/2:14:45]  Acc_iter 25800       Data time: 0.00(0.03)  Forward time: 0.30(0.51)  Batch time: 0.30(0.54)
2025-07-12 13:56:12,483   INFO  Train:   64/100 ( 64%) [ 145/408 ( 36%)]  Loss: 3.515 (3.12)  LR: 2.011e-03  Time cost: 01:16/02:18 [2:17:16/2:11:08]  Acc_iter 25850       Data time: 0.00(0.02)  Forward time: 0.65(0.51)  Batch time: 0.65(0.53)
2025-07-12 13:56:37,008   INFO  Train:   64/100 ( 64%) [ 195/408 ( 48%)]  Loss: 2.422 (3.08)  LR: 2.002e-03  Time cost: 01:41/01:50 [2:17:40/2:08:25]  Acc_iter 25900       Data time: 0.00(0.02)  Forward time: 0.34(0.50)  Batch time: 0.34(0.52)
2025-07-12 13:57:02,462   INFO  Train:   64/100 ( 64%) [ 245/408 ( 60%)]  Loss: 2.462 (3.06)  LR: 1.993e-03  Time cost: 02:06/01:24 [2:18:06/2:07:35]  Acc_iter 25950       Data time: 0.00(0.01)  Forward time: 0.40(0.50)  Batch time: 0.41(0.52)
2025-07-12 13:57:27,398   INFO  Train:   64/100 ( 64%) [ 295/408 ( 72%)]  Loss: 2.856 (3.09)  LR: 1.984e-03  Time cost: 02:31/00:57 [2:18:31/2:06:27]  Acc_iter 26000       Data time: 0.00(0.01)  Forward time: 0.54(0.50)  Batch time: 0.54(0.51)
2025-07-12 13:57:52,764   INFO  Train:   64/100 ( 64%) [ 345/408 ( 85%)]  Loss: 2.361 (3.08)  LR: 1.975e-03  Time cost: 02:57/00:32 [2:18:56/2:05:50]  Acc_iter 26050       Data time: 0.00(0.01)  Forward time: 0.69(0.50)  Batch time: 0.70(0.51)
2025-07-12 13:58:17,625   INFO  Train:   64/100 ( 64%) [ 395/408 ( 97%)]  Loss: 3.520 (3.09)  LR: 1.966e-03  Time cost: 03:21/00:06 [2:19:21/2:04:58]  Acc_iter 26100       Data time: 0.00(0.01)  Forward time: 0.30(0.50)  Batch time: 0.30(0.51)
2025-07-12 13:58:21,796   INFO  Train:   64/100 ( 64%) [ 407/408 (100%)]  Loss: 4.590 (3.08)  LR: 1.964e-03  Time cost: 03:26/00:00 [2:19:25/2:03:41]  Acc_iter 26112       Data time: 0.00(0.01)  Forward time: 0.16(0.50)  Batch time: 0.16(0.51)
2025-07-12 13:58:26,487   INFO  Train:   65/100 ( 65%) [   0/408 (  0%)]  Loss: 2.264 (2.26)  LR: 1.964e-03  Time cost: 00:03/25:47 [2:19:30/15:28:27]  Acc_iter 26113       Data time: 2.57(2.57)  Forward time: 1.22(1.22)  Batch time: 3.79(3.79)
2025-07-12 13:58:44,882   INFO  Train:   65/100 ( 65%) [  37/408 (  9%)]  Loss: 3.736 (3.15)  LR: 1.957e-03  Time cost: 00:22/03:36 [2:19:48/2:22:34]  Acc_iter 26150       Data time: 0.00(0.07)  Forward time: 0.37(0.51)  Batch time: 0.37(0.58)
2025-07-12 13:59:10,241   INFO  Train:   65/100 ( 65%) [  87/408 ( 21%)]  Loss: 3.630 (3.12)  LR: 1.948e-03  Time cost: 00:47/02:53 [2:20:13/2:11:28]  Acc_iter 26200       Data time: 0.00(0.03)  Forward time: 0.66(0.51)  Batch time: 0.67(0.54)
2025-07-12 13:59:35,232   INFO  Train:   65/100 ( 65%) [ 137/408 ( 34%)]  Loss: 2.572 (3.06)  LR: 1.938e-03  Time cost: 01:12/02:22 [2:20:38/2:07:28]  Acc_iter 26250       Data time: 0.00(0.02)  Forward time: 0.47(0.50)  Batch time: 0.47(0.53)
2025-07-12 14:00:00,978   INFO  Train:   65/100 ( 65%) [ 187/408 ( 46%)]  Loss: 2.428 (3.08)  LR: 1.929e-03  Time cost: 01:38/01:55 [2:21:04/2:06:20]  Acc_iter 26300       Data time: 0.00(0.02)  Forward time: 0.62(0.51)  Batch time: 0.63(0.52)
2025-07-12 14:00:25,905   INFO  Train:   65/100 ( 65%) [ 237/408 ( 58%)]  Loss: 2.345 (3.08)  LR: 1.920e-03  Time cost: 02:03/01:28 [2:21:29/2:04:41]  Acc_iter 26350       Data time: 0.00(0.01)  Forward time: 0.34(0.50)  Batch time: 0.35(0.52)
2025-07-12 14:00:50,864   INFO  Train:   65/100 ( 65%) [ 287/408 ( 70%)]  Loss: 2.453 (3.05)  LR: 1.911e-03  Time cost: 02:28/01:02 [2:21:54/2:03:28]  Acc_iter 26400       Data time: 0.00(0.01)  Forward time: 0.80(0.50)  Batch time: 0.80(0.51)
2025-07-12 14:01:15,661   INFO  Train:   65/100 ( 65%) [ 337/408 ( 83%)]  Loss: 2.626 (3.03)  LR: 1.901e-03  Time cost: 02:52/00:36 [2:22:19/2:02:23]  Acc_iter 26450       Data time: 0.00(0.01)  Forward time: 0.65(0.50)  Batch time: 0.65(0.51)
2025-07-12 14:01:41,186   INFO  Train:   65/100 ( 65%) [ 387/408 ( 95%)]  Loss: 2.271 (3.05)  LR: 1.892e-03  Time cost: 03:18/00:10 [2:22:44/2:01:56]  Acc_iter 26500       Data time: 0.00(0.01)  Forward time: 0.34(0.50)  Batch time: 0.34(0.51)
2025-07-12 14:01:49,267   INFO  Train:   65/100 ( 65%) [ 407/408 (100%)]  Loss: 3.510 (3.06)  LR: 1.888e-03  Time cost: 03:26/00:00 [2:22:52/2:00:30]  Acc_iter 26520       Data time: 0.00(0.01)  Forward time: 0.16(0.50)  Batch time: 0.16(0.51)
2025-07-12 14:01:54,454   INFO  Train:   66/100 ( 66%) [   0/408 (  0%)]  Loss: 3.032 (3.03)  LR: 1.888e-03  Time cost: 00:04/29:13 [2:22:58/17:02:42]  Acc_iter 26521       Data time: 3.47(3.47)  Forward time: 0.82(0.82)  Batch time: 4.30(4.30)
2025-07-12 14:02:08,716   INFO  Train:   66/100 ( 66%) [  29/408 (  7%)]  Loss: 2.263 (2.81)  LR: 1.883e-03  Time cost: 00:18/03:54 [2:23:12/2:26:56]  Acc_iter 26550       Data time: 0.00(0.12)  Forward time: 0.37(0.50)  Batch time: 0.37(0.62)
2025-07-12 14:02:33,701   INFO  Train:   66/100 ( 66%) [  79/408 ( 19%)]  Loss: 3.536 (2.99)  LR: 1.874e-03  Time cost: 00:43/02:59 [2:23:37/2:08:49]  Acc_iter 26600       Data time: 0.00(0.05)  Forward time: 0.44(0.50)  Batch time: 0.45(0.54)
2025-07-12 14:02:59,259   INFO  Train:   66/100 ( 66%) [ 129/408 ( 32%)]  Loss: 2.873 (3.01)  LR: 1.864e-03  Time cost: 01:09/02:28 [2:24:02/2:05:22]  Acc_iter 26650       Data time: 0.00(0.03)  Forward time: 0.45(0.50)  Batch time: 0.46(0.53)
2025-07-12 14:03:25,661   INFO  Train:   66/100 ( 66%) [ 179/408 ( 44%)]  Loss: 3.050 (2.97)  LR: 1.855e-03  Time cost: 01:35/02:01 [2:24:29/2:04:41]  Acc_iter 26700       Data time: 0.00(0.02)  Forward time: 0.39(0.51)  Batch time: 0.40(0.53)
2025-07-12 14:03:51,344   INFO  Train:   66/100 ( 66%) [ 229/408 ( 56%)]  Loss: 3.173 (3.00)  LR: 1.845e-03  Time cost: 02:01/01:34 [2:24:54/2:03:23]  Acc_iter 26750       Data time: 0.00(0.02)  Forward time: 0.67(0.51)  Batch time: 0.68(0.53)
2025-07-12 14:04:16,781   INFO  Train:   66/100 ( 66%) [ 279/408 ( 68%)]  Loss: 3.037 (3.01)  LR: 1.836e-03  Time cost: 02:26/01:07 [2:25:20/2:02:11]  Acc_iter 26800       Data time: 0.00(0.02)  Forward time: 0.32(0.51)  Batch time: 0.32(0.52)
2025-07-12 14:04:42,169   INFO  Train:   66/100 ( 66%) [ 329/408 ( 81%)]  Loss: 2.335 (3.00)  LR: 1.827e-03  Time cost: 02:52/00:41 [2:25:45/2:01:11]  Acc_iter 26850       Data time: 0.00(0.01)  Forward time: 0.25(0.51)  Batch time: 0.26(0.52)
2025-07-12 14:05:06,826   INFO  Train:   66/100 ( 66%) [ 379/408 ( 93%)]  Loss: 2.207 (3.03)  LR: 1.817e-03  Time cost: 03:16/00:15 [2:26:10/1:59:54]  Acc_iter 26900       Data time: 0.00(0.01)  Forward time: 0.56(0.50)  Batch time: 0.56(0.52)
2025-07-12 14:05:19,072   INFO  Train:   66/100 ( 66%) [ 407/408 (100%)]  Loss: 2.367 (3.02)  LR: 1.812e-03  Time cost: 03:28/00:00 [2:26:22/1:58:23]  Acc_iter 26928       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.14(0.51)
2025-07-12 14:05:23,463   INFO  Train:   67/100 ( 67%) [   0/408 (  0%)]  Loss: 2.651 (2.65)  LR: 1.812e-03  Time cost: 00:03/24:45 [2:26:27/14:01:30]  Acc_iter 26929       Data time: 2.34(2.34)  Forward time: 1.30(1.30)  Batch time: 3.64(3.64)
2025-07-12 14:05:34,567   INFO  Train:   67/100 ( 67%) [  21/408 (  5%)]  Loss: 3.156 (2.96)  LR: 1.808e-03  Time cost: 00:14/04:19 [2:26:38/2:34:42]  Acc_iter 26950       Data time: 0.00(0.11)  Forward time: 0.49(0.56)  Batch time: 0.49(0.67)
2025-07-12 14:05:59,948   INFO  Train:   67/100 ( 67%) [  71/408 ( 17%)]  Loss: 2.361 (2.90)  LR: 1.798e-03  Time cost: 00:40/03:07 [2:27:03/2:08:11]  Acc_iter 27000       Data time: 0.00(0.04)  Forward time: 0.27(0.52)  Batch time: 0.27(0.56)
2025-07-12 14:06:25,621   INFO  Train:   67/100 ( 67%) [ 121/408 ( 30%)]  Loss: 3.720 (2.97)  LR: 1.789e-03  Time cost: 01:05/02:34 [2:27:29/2:03:36]  Acc_iter 27050       Data time: 0.00(0.02)  Forward time: 0.69(0.52)  Batch time: 0.69(0.54)
2025-07-12 14:06:51,318   INFO  Train:   67/100 ( 67%) [ 171/408 ( 42%)]  Loss: 1.806 (2.97)  LR: 1.780e-03  Time cost: 01:31/02:06 [2:27:54/2:01:28]  Acc_iter 27100       Data time: 0.00(0.02)  Forward time: 0.57(0.51)  Batch time: 0.57(0.53)
2025-07-12 14:07:17,053   INFO  Train:   67/100 ( 67%) [ 221/408 ( 54%)]  Loss: 3.229 (2.96)  LR: 1.770e-03  Time cost: 01:57/01:38 [2:28:20/2:00:08]  Acc_iter 27150       Data time: 0.00(0.01)  Forward time: 0.44(0.51)  Batch time: 0.45(0.53)
2025-07-12 14:07:42,971   INFO  Train:   67/100 ( 67%) [ 271/408 ( 66%)]  Loss: 2.650 (2.96)  LR: 1.761e-03  Time cost: 02:23/01:12 [2:28:46/1:59:17]  Acc_iter 27200       Data time: 0.00(0.01)  Forward time: 0.61(0.51)  Batch time: 0.62(0.53)
2025-07-12 14:08:08,673   INFO  Train:   67/100 ( 67%) [ 321/408 ( 79%)]  Loss: 2.569 (2.95)  LR: 1.751e-03  Time cost: 02:48/00:45 [2:29:12/1:58:25]  Acc_iter 27250       Data time: 0.00(0.01)  Forward time: 0.63(0.51)  Batch time: 0.64(0.52)
2025-07-12 14:08:34,467   INFO  Train:   67/100 ( 67%) [ 371/408 ( 91%)]  Loss: 2.595 (2.94)  LR: 1.742e-03  Time cost: 03:14/00:19 [2:29:38/1:57:44]  Acc_iter 27300       Data time: 0.00(0.01)  Forward time: 0.33(0.51)  Batch time: 0.34(0.52)
2025-07-12 14:08:51,320   INFO  Train:   67/100 ( 67%) [ 407/408 (100%)]  Loss: 2.771 (2.94)  LR: 1.735e-03  Time cost: 03:31/00:00 [2:29:54/1:56:19]  Acc_iter 27336       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 14:08:56,704   INFO  Train:   68/100 ( 68%) [   0/408 (  0%)]  Loss: 2.840 (2.84)  LR: 1.735e-03  Time cost: 00:04/30:23 [2:30:00/16:43:10]  Acc_iter 27337       Data time: 3.28(3.28)  Forward time: 1.19(1.19)  Batch time: 4.47(4.47)
2025-07-12 14:09:03,209   INFO  Train:   68/100 ( 68%) [  13/408 (  3%)]  Loss: 2.716 (2.92)  LR: 1.732e-03  Time cost: 00:10/05:09 [2:30:06/2:55:44]  Acc_iter 27350       Data time: 0.01(0.24)  Forward time: 0.37(0.55)  Batch time: 0.38(0.78)
2025-07-12 14:09:28,382   INFO  Train:   68/100 ( 68%) [  63/408 ( 15%)]  Loss: 2.197 (2.81)  LR: 1.723e-03  Time cost: 00:36/03:14 [2:30:32/2:06:09]  Acc_iter 27400       Data time: 0.00(0.06)  Forward time: 0.33(0.51)  Batch time: 0.33(0.56)
2025-07-12 14:09:54,008   INFO  Train:   68/100 ( 68%) [ 113/408 ( 28%)]  Loss: 3.567 (2.97)  LR: 1.713e-03  Time cost: 01:01/02:39 [2:30:57/2:00:34]  Acc_iter 27450       Data time: 0.00(0.03)  Forward time: 0.55(0.51)  Batch time: 0.55(0.54)
2025-07-12 14:10:19,739   INFO  Train:   68/100 ( 68%) [ 163/408 ( 40%)]  Loss: 3.813 (2.94)  LR: 1.704e-03  Time cost: 01:27/02:10 [2:31:23/1:58:17]  Acc_iter 27500       Data time: 0.00(0.02)  Forward time: 0.96(0.51)  Batch time: 0.96(0.53)
2025-07-12 14:10:44,991   INFO  Train:   68/100 ( 68%) [ 213/408 ( 52%)]  Loss: 3.443 (2.92)  LR: 1.694e-03  Time cost: 01:52/01:42 [2:31:48/1:56:22]  Acc_iter 27550       Data time: 0.00(0.02)  Forward time: 0.80(0.51)  Batch time: 0.80(0.53)
2025-07-12 14:11:10,503   INFO  Train:   68/100 ( 68%) [ 263/408 ( 64%)]  Loss: 2.649 (2.93)  LR: 1.685e-03  Time cost: 02:18/01:15 [2:32:14/1:55:13]  Acc_iter 27600       Data time: 0.00(0.02)  Forward time: 0.84(0.51)  Batch time: 0.85(0.52)
2025-07-12 14:11:36,224   INFO  Train:   68/100 ( 68%) [ 313/408 ( 77%)]  Loss: 3.100 (2.90)  LR: 1.675e-03  Time cost: 02:43/00:49 [2:32:39/1:54:28]  Acc_iter 27650       Data time: 0.00(0.01)  Forward time: 0.72(0.51)  Batch time: 0.73(0.52)
2025-07-12 14:12:01,886   INFO  Train:   68/100 ( 68%) [ 363/408 ( 89%)]  Loss: 2.482 (2.89)  LR: 1.665e-03  Time cost: 03:09/00:23 [2:33:05/1:53:45]  Acc_iter 27700       Data time: 0.00(0.01)  Forward time: 0.69(0.51)  Batch time: 0.70(0.52)
2025-07-12 14:12:22,049   INFO  Train:   68/100 ( 68%) [ 407/408 (100%)]  Loss: 3.361 (2.89)  LR: 1.657e-03  Time cost: 03:29/00:00 [2:33:25/1:51:54]  Acc_iter 27744       Data time: 0.01(0.01)  Forward time: 0.16(0.50)  Batch time: 0.17(0.51)
2025-07-12 14:12:26,367   INFO  Train:   69/100 ( 69%) [   0/408 (  0%)]  Loss: 2.522 (2.52)  LR: 1.657e-03  Time cost: 00:03/23:22 [2:33:30/12:27:58]  Acc_iter 27745       Data time: 2.06(2.06)  Forward time: 1.38(1.38)  Batch time: 3.44(3.44)
2025-07-12 14:12:29,370   INFO  Train:   69/100 ( 69%) [   5/408 (  1%)]  Loss: 3.214 (3.06)  LR: 1.656e-03  Time cost: 00:06/07:12 [2:33:33/3:53:29]  Acc_iter 27750       Data time: 0.00(0.35)  Forward time: 0.41(0.73)  Batch time: 0.41(1.07)
2025-07-12 14:12:54,826   INFO  Train:   69/100 ( 69%) [  55/408 ( 13%)]  Loss: 3.929 (2.88)  LR: 1.646e-03  Time cost: 00:31/03:21 [2:33:58/2:03:25]  Acc_iter 27800       Data time: 0.00(0.04)  Forward time: 0.48(0.53)  Batch time: 0.48(0.57)
2025-07-12 14:13:20,670   INFO  Train:   69/100 ( 69%) [ 105/408 ( 26%)]  Loss: 2.909 (2.86)  LR: 1.637e-03  Time cost: 00:57/02:45 [2:34:24/1:57:34]  Acc_iter 27850       Data time: 0.00(0.02)  Forward time: 0.29(0.52)  Batch time: 0.30(0.54)
2025-07-12 14:13:46,974   INFO  Train:   69/100 ( 69%) [ 155/408 ( 38%)]  Loss: 3.592 (2.89)  LR: 1.627e-03  Time cost: 01:24/02:16 [2:34:50/1:55:50]  Acc_iter 27900       Data time: 0.00(0.02)  Forward time: 0.85(0.52)  Batch time: 0.86(0.54)
2025-07-12 14:14:12,677   INFO  Train:   69/100 ( 69%) [ 205/408 ( 50%)]  Loss: 3.017 (2.88)  LR: 1.618e-03  Time cost: 01:49/01:48 [2:35:16/1:54:06]  Acc_iter 27950       Data time: 0.00(0.01)  Forward time: 0.78(0.52)  Batch time: 0.79(0.53)
2025-07-12 14:14:38,296   INFO  Train:   69/100 ( 69%) [ 255/408 ( 62%)]  Loss: 2.364 (2.86)  LR: 1.608e-03  Time cost: 02:15/01:20 [2:35:41/1:52:48]  Acc_iter 28000       Data time: 0.01(0.01)  Forward time: 0.56(0.52)  Batch time: 0.56(0.53)
2025-07-12 14:15:03,518   INFO  Train:   69/100 ( 69%) [ 305/408 ( 75%)]  Loss: 2.221 (2.84)  LR: 1.598e-03  Time cost: 02:40/00:54 [2:36:07/1:51:31]  Acc_iter 28050       Data time: 0.00(0.01)  Forward time: 0.25(0.51)  Batch time: 0.25(0.52)
2025-07-12 14:15:29,085   INFO  Train:   69/100 ( 69%) [ 355/408 ( 87%)]  Loss: 2.443 (2.83)  LR: 1.589e-03  Time cost: 03:06/00:27 [2:36:32/1:50:41]  Acc_iter 28100       Data time: 0.00(0.01)  Forward time: 0.52(0.51)  Batch time: 0.52(0.52)
2025-07-12 14:15:53,414   INFO  Train:   69/100 ( 69%) [ 405/408 ( 99%)]  Loss: 3.241 (2.85)  LR: 1.579e-03  Time cost: 03:30/00:01 [2:36:57/1:49:18]  Acc_iter 28150       Data time: 0.00(0.01)  Forward time: 0.22(0.51)  Batch time: 0.22(0.52)
2025-07-12 14:15:53,837   INFO  Train:   69/100 ( 69%) [ 407/408 (100%)]  Loss: 3.118 (2.85)  LR: 1.579e-03  Time cost: 03:30/00:00 [2:36:57/1:48:58]  Acc_iter 28152       Data time: 0.00(0.01)  Forward time: 0.17(0.51)  Batch time: 0.17(0.52)
2025-07-12 14:15:58,374   INFO  Train:   70/100 ( 70%) [   0/408 (  0%)]  Loss: 2.705 (2.70)  LR: 1.579e-03  Time cost: 00:03/25:38 [2:37:02/13:14:57]  Acc_iter 28153       Data time: 2.64(2.64)  Forward time: 1.13(1.13)  Batch time: 3.77(3.77)
2025-07-12 14:16:23,064   INFO  Train:   70/100 ( 70%) [  47/408 ( 12%)]  Loss: 2.743 (2.72)  LR: 1.569e-03  Time cost: 00:28/03:34 [2:37:26/2:04:31]  Acc_iter 28200       Data time: 0.00(0.06)  Forward time: 0.66(0.53)  Batch time: 0.66(0.59)
2025-07-12 14:16:49,058   INFO  Train:   70/100 ( 70%) [  97/408 ( 24%)]  Loss: 2.640 (2.73)  LR: 1.560e-03  Time cost: 00:54/02:52 [2:37:52/1:56:14]  Acc_iter 28250       Data time: 0.00(0.03)  Forward time: 0.56(0.53)  Batch time: 0.57(0.56)
2025-07-12 14:17:14,741   INFO  Train:   70/100 ( 70%) [ 147/408 ( 36%)]  Loss: 3.887 (2.77)  LR: 1.550e-03  Time cost: 01:20/02:21 [2:38:18/1:52:48]  Acc_iter 28300       Data time: 0.00(0.02)  Forward time: 0.58(0.52)  Batch time: 0.58(0.54)
2025-07-12 14:17:40,916   INFO  Train:   70/100 ( 70%) [ 197/408 ( 48%)]  Loss: 4.326 (2.81)  LR: 1.541e-03  Time cost: 01:46/01:53 [2:38:44/1:51:25]  Acc_iter 28350       Data time: 0.00(0.02)  Forward time: 0.30(0.52)  Batch time: 0.31(0.54)
2025-07-12 14:18:05,435   INFO  Train:   70/100 ( 70%) [ 247/408 ( 61%)]  Loss: 2.328 (2.82)  LR: 1.531e-03  Time cost: 02:10/01:24 [2:39:09/1:49:02]  Acc_iter 28400       Data time: 0.00(0.01)  Forward time: 0.44(0.51)  Batch time: 0.44(0.53)
2025-07-12 14:18:30,341   INFO  Train:   70/100 ( 70%) [ 297/408 ( 73%)]  Loss: 2.611 (2.84)  LR: 1.521e-03  Time cost: 02:35/00:58 [2:39:33/1:47:34]  Acc_iter 28450       Data time: 0.00(0.01)  Forward time: 0.54(0.51)  Batch time: 0.54(0.52)
2025-07-12 14:18:55,530   INFO  Train:   70/100 ( 70%) [ 347/408 ( 85%)]  Loss: 1.939 (2.81)  LR: 1.512e-03  Time cost: 03:00/00:31 [2:39:59/1:46:35]  Acc_iter 28500       Data time: 0.00(0.01)  Forward time: 0.38(0.51)  Batch time: 0.38(0.52)
2025-07-12 14:19:20,199   INFO  Train:   70/100 ( 70%) [ 397/408 ( 97%)]  Loss: 3.585 (2.80)  LR: 1.502e-03  Time cost: 03:25/00:05 [2:40:23/1:45:28]  Acc_iter 28550       Data time: 0.00(0.01)  Forward time: 0.41(0.51)  Batch time: 0.42(0.52)
2025-07-12 14:19:23,459   INFO  Train:   70/100 ( 70%) [ 407/408 (100%)]  Loss: 4.166 (2.80)  LR: 1.500e-03  Time cost: 03:28/00:00 [2:40:27/1:44:26]  Acc_iter 28560       Data time: 0.00(0.01)  Forward time: 0.16(0.50)  Batch time: 0.17(0.51)
2025-07-12 14:19:27,395   INFO  Train:   71/100 ( 71%) [   0/408 (  0%)]  Loss: 3.097 (3.10)  LR: 1.500e-03  Time cost: 00:03/21:48 [2:40:31/10:54:08]  Acc_iter 28561       Data time: 2.08(2.08)  Forward time: 1.13(1.13)  Batch time: 3.21(3.21)
2025-07-12 14:19:47,147   INFO  Train:   71/100 ( 71%) [  39/408 ( 10%)]  Loss: 2.243 (2.79)  LR: 1.493e-03  Time cost: 00:22/03:31 [2:40:50/1:56:42]  Acc_iter 28600       Data time: 0.00(0.06)  Forward time: 0.25(0.52)  Batch time: 0.26(0.57)
2025-07-12 14:20:12,686   INFO  Train:   71/100 ( 71%) [  89/408 ( 22%)]  Loss: 2.354 (2.76)  LR: 1.483e-03  Time cost: 00:48/02:51 [2:41:16/1:49:07]  Acc_iter 28650       Data time: 0.00(0.03)  Forward time: 0.31(0.51)  Batch time: 0.32(0.54)
2025-07-12 14:20:39,456   INFO  Train:   71/100 ( 71%) [ 139/408 ( 34%)]  Loss: 2.162 (2.76)  LR: 1.473e-03  Time cost: 01:15/02:24 [2:41:43/1:48:25]  Acc_iter 28700       Data time: 0.00(0.02)  Forward time: 0.44(0.52)  Batch time: 0.45(0.54)
2025-07-12 14:21:05,238   INFO  Train:   71/100 ( 71%) [ 189/408 ( 46%)]  Loss: 2.708 (2.77)  LR: 1.464e-03  Time cost: 01:41/01:56 [2:42:08/1:46:49]  Acc_iter 28750       Data time: 0.01(0.01)  Forward time: 0.70(0.52)  Batch time: 0.71(0.53)
2025-07-12 14:21:30,536   INFO  Train:   71/100 ( 71%) [ 239/408 ( 59%)]  Loss: 2.830 (2.79)  LR: 1.454e-03  Time cost: 02:06/01:28 [2:42:34/1:45:17]  Acc_iter 28800       Data time: 0.01(0.01)  Forward time: 0.35(0.51)  Batch time: 0.35(0.53)
2025-07-12 14:21:56,159   INFO  Train:   71/100 ( 71%) [ 289/408 ( 71%)]  Loss: 3.283 (2.78)  LR: 1.444e-03  Time cost: 02:31/01:02 [2:42:59/1:44:22]  Acc_iter 28850       Data time: 0.01(0.01)  Forward time: 0.43(0.51)  Batch time: 0.44(0.52)
2025-07-12 14:22:21,277   INFO  Train:   71/100 ( 71%) [ 339/408 ( 83%)]  Loss: 1.916 (2.78)  LR: 1.435e-03  Time cost: 02:57/00:35 [2:43:24/1:43:18]  Acc_iter 28900       Data time: 0.00(0.01)  Forward time: 0.41(0.51)  Batch time: 0.41(0.52)
2025-07-12 14:22:47,064   INFO  Train:   71/100 ( 71%) [ 389/408 ( 95%)]  Loss: 2.382 (2.77)  LR: 1.425e-03  Time cost: 03:22/00:09 [2:43:50/1:42:44]  Acc_iter 28950       Data time: 0.00(0.01)  Forward time: 0.50(0.51)  Batch time: 0.51(0.52)
2025-07-12 14:22:54,696   INFO  Train:   71/100 ( 71%) [ 407/408 (100%)]  Loss: 2.261 (2.76)  LR: 1.422e-03  Time cost: 03:30/00:00 [2:43:58/1:41:45]  Acc_iter 28968       Data time: 0.00(0.01)  Forward time: 0.20(0.51)  Batch time: 0.20(0.52)
2025-07-12 14:22:59,520   INFO  Train:   72/100 ( 72%) [   0/408 (  0%)]  Loss: 2.926 (2.93)  LR: 1.422e-03  Time cost: 00:03/26:36 [2:44:03/12:51:42]  Acc_iter 28969       Data time: 2.95(2.95)  Forward time: 0.96(0.96)  Batch time: 3.91(3.91)
2025-07-12 14:23:16,111   INFO  Train:   72/100 ( 72%) [  31/408 (  8%)]  Loss: 2.666 (2.65)  LR: 1.416e-03  Time cost: 00:20/04:01 [2:44:19/2:06:01]  Acc_iter 29000       Data time: 0.01(0.10)  Forward time: 0.52(0.54)  Batch time: 0.52(0.64)
2025-07-12 14:23:41,682   INFO  Train:   72/100 ( 72%) [  81/408 ( 20%)]  Loss: 2.945 (2.67)  LR: 1.406e-03  Time cost: 00:46/03:03 [2:44:45/1:50:02]  Acc_iter 29050       Data time: 0.00(0.04)  Forward time: 0.55(0.52)  Batch time: 0.55(0.56)
2025-07-12 14:24:08,147   INFO  Train:   72/100 ( 72%) [ 131/408 ( 32%)]  Loss: 2.187 (2.70)  LR: 1.396e-03  Time cost: 01:12/02:32 [2:45:11/1:47:10]  Acc_iter 29100       Data time: 0.00(0.03)  Forward time: 0.69(0.52)  Batch time: 0.69(0.55)
2025-07-12 14:24:33,462   INFO  Train:   72/100 ( 72%) [ 181/408 ( 44%)]  Loss: 1.964 (2.67)  LR: 1.387e-03  Time cost: 01:37/02:02 [2:45:37/1:44:24]  Acc_iter 29150       Data time: 0.00(0.02)  Forward time: 0.40(0.52)  Batch time: 0.40(0.54)
2025-07-12 14:24:58,561   INFO  Train:   72/100 ( 72%) [ 231/408 ( 57%)]  Loss: 3.230 (2.69)  LR: 1.377e-03  Time cost: 02:02/01:33 [2:46:02/1:42:28]  Acc_iter 29200       Data time: 0.00(0.02)  Forward time: 0.29(0.51)  Batch time: 0.30(0.53)
2025-07-12 14:25:24,043   INFO  Train:   72/100 ( 72%) [ 281/408 ( 69%)]  Loss: 2.311 (2.68)  LR: 1.368e-03  Time cost: 02:28/01:06 [2:46:27/1:41:20]  Acc_iter 29250       Data time: 0.00(0.01)  Forward time: 0.46(0.51)  Batch time: 0.47(0.53)
2025-07-12 14:25:49,672   INFO  Train:   72/100 ( 72%) [ 331/408 ( 81%)]  Loss: 3.075 (2.68)  LR: 1.358e-03  Time cost: 02:54/00:40 [2:46:53/1:40:29]  Acc_iter 29300       Data time: 0.00(0.01)  Forward time: 0.91(0.51)  Batch time: 0.91(0.52)
2025-07-12 14:26:15,854   INFO  Train:   72/100 ( 72%) [ 381/408 ( 93%)]  Loss: 2.495 (2.69)  LR: 1.348e-03  Time cost: 03:20/00:14 [2:47:19/1:40:02]  Acc_iter 29350       Data time: 0.00(0.01)  Forward time: 0.89(0.51)  Batch time: 0.89(0.52)
2025-07-12 14:26:26,622   INFO  Train:   72/100 ( 72%) [ 407/408 (100%)]  Loss: 4.458 (2.72)  LR: 1.343e-03  Time cost: 03:31/00:00 [2:47:30/1:38:28]  Acc_iter 29376       Data time: 0.00(0.01)  Forward time: 0.17(0.51)  Batch time: 0.17(0.52)
2025-07-12 14:26:31,374   INFO  Train:   73/100 ( 73%) [   0/408 (  0%)]  Loss: 2.297 (2.30)  LR: 1.343e-03  Time cost: 00:03/26:23 [2:47:35/12:19:00]  Acc_iter 29377       Data time: 2.47(2.47)  Forward time: 1.41(1.41)  Batch time: 3.88(3.88)
2025-07-12 14:26:43,895   INFO  Train:   73/100 ( 73%) [  23/408 (  6%)]  Loss: 3.097 (2.68)  LR: 1.339e-03  Time cost: 00:16/04:23 [2:47:47/2:09:51]  Acc_iter 29400       Data time: 0.00(0.11)  Forward time: 0.93(0.58)  Batch time: 0.94(0.68)
2025-07-12 14:27:09,851   INFO  Train:   73/100 ( 73%) [  73/408 ( 18%)]  Loss: 2.735 (2.78)  LR: 1.329e-03  Time cost: 00:42/03:11 [2:48:13/1:48:17]  Acc_iter 29450       Data time: 0.00(0.04)  Forward time: 0.59(0.53)  Batch time: 0.59(0.57)
2025-07-12 14:27:36,616   INFO  Train:   73/100 ( 73%) [ 123/408 ( 30%)]  Loss: 3.106 (2.72)  LR: 1.320e-03  Time cost: 01:09/02:38 [2:48:40/1:44:59]  Acc_iter 29500       Data time: 0.05(0.02)  Forward time: 0.89(0.53)  Batch time: 0.94(0.56)
2025-07-12 14:28:01,729   INFO  Train:   73/100 ( 73%) [ 173/408 ( 42%)]  Loss: 2.083 (2.70)  LR: 1.310e-03  Time cost: 01:34/02:07 [2:49:05/1:41:33]  Acc_iter 29550       Data time: 0.00(0.02)  Forward time: 0.46(0.52)  Batch time: 0.47(0.54)
2025-07-12 14:28:26,879   INFO  Train:   73/100 ( 73%) [ 223/408 ( 55%)]  Loss: 2.385 (2.69)  LR: 1.301e-03  Time cost: 01:59/01:38 [2:49:30/1:39:29]  Acc_iter 29600       Data time: 0.00(0.02)  Forward time: 0.53(0.52)  Batch time: 0.54(0.53)
2025-07-12 14:28:53,172   INFO  Train:   73/100 ( 73%) [ 273/408 ( 67%)]  Loss: 3.448 (2.68)  LR: 1.291e-03  Time cost: 02:25/01:11 [2:49:56/1:38:48]  Acc_iter 29650       Data time: 0.00(0.01)  Forward time: 1.10(0.52)  Batch time: 1.11(0.53)
2025-07-12 14:29:18,025   INFO  Train:   73/100 ( 73%) [ 323/408 ( 79%)]  Loss: 2.728 (2.69)  LR: 1.282e-03  Time cost: 02:50/00:44 [2:50:21/1:37:22]  Acc_iter 29700       Data time: 0.00(0.01)  Forward time: 0.56(0.51)  Batch time: 0.56(0.53)
2025-07-12 14:29:43,763   INFO  Train:   73/100 ( 73%) [ 373/408 ( 91%)]  Loss: 1.963 (2.71)  LR: 1.272e-03  Time cost: 03:16/00:18 [2:50:47/1:36:39]  Acc_iter 29750       Data time: 0.00(0.01)  Forward time: 0.48(0.51)  Batch time: 0.49(0.52)
2025-07-12 14:29:58,746   INFO  Train:   73/100 ( 73%) [ 407/408 (100%)]  Loss: 5.100 (2.70)  LR: 1.266e-03  Time cost: 03:31/00:00 [2:51:02/1:35:04]  Acc_iter 29784       Data time: 0.00(0.01)  Forward time: 0.14(0.51)  Batch time: 0.14(0.52)
2025-07-12 14:30:03,197   INFO  Train:   74/100 ( 74%) [   0/408 (  0%)]  Loss: 1.843 (1.84)  LR: 1.265e-03  Time cost: 00:03/24:16 [2:51:06/10:55:12]  Acc_iter 29785       Data time: 2.16(2.16)  Forward time: 1.41(1.41)  Batch time: 3.57(3.57)
2025-07-12 14:30:11,713   INFO  Train:   74/100 ( 74%) [  15/408 (  4%)]  Loss: 2.032 (2.65)  LR: 1.263e-03  Time cost: 00:12/04:56 [2:51:15/2:18:29]  Acc_iter 29800       Data time: 0.00(0.14)  Forward time: 0.39(0.62)  Batch time: 0.40(0.76)
2025-07-12 14:30:38,094   INFO  Train:   74/100 ( 74%) [  65/408 ( 16%)]  Loss: 2.427 (2.59)  LR: 1.253e-03  Time cost: 00:38/03:19 [2:51:41/1:46:22]  Acc_iter 29850       Data time: 0.00(0.04)  Forward time: 0.59(0.55)  Batch time: 0.59(0.58)
2025-07-12 14:31:03,254   INFO  Train:   74/100 ( 74%) [ 115/408 ( 28%)]  Loss: 3.006 (2.66)  LR: 1.244e-03  Time cost: 01:03/02:40 [2:52:06/1:39:39]  Acc_iter 29900       Data time: 0.00(0.02)  Forward time: 0.58(0.53)  Batch time: 0.59(0.55)
2025-07-12 14:31:28,772   INFO  Train:   74/100 ( 74%) [ 165/408 ( 40%)]  Loss: 4.241 (2.66)  LR: 1.234e-03  Time cost: 01:29/02:10 [2:52:32/1:37:07]  Acc_iter 29950       Data time: 0.00(0.02)  Forward time: 0.60(0.52)  Batch time: 0.60(0.54)
2025-07-12 14:31:54,125   INFO  Train:   74/100 ( 74%) [ 215/408 ( 53%)]  Loss: 2.221 (2.67)  LR: 1.225e-03  Time cost: 01:54/01:42 [2:52:57/1:35:25]  Acc_iter 30000       Data time: 0.00(0.01)  Forward time: 0.37(0.52)  Batch time: 0.37(0.53)
2025-07-12 14:32:19,741   INFO  Train:   74/100 ( 74%) [ 265/408 ( 65%)]  Loss: 2.803 (2.68)  LR: 1.215e-03  Time cost: 02:20/01:15 [2:53:23/1:34:22]  Acc_iter 30050       Data time: 0.00(0.01)  Forward time: 0.47(0.51)  Batch time: 0.47(0.53)
2025-07-12 14:32:44,625   INFO  Train:   74/100 ( 74%) [ 315/408 ( 77%)]  Loss: 4.117 (2.66)  LR: 1.206e-03  Time cost: 02:44/00:48 [2:53:48/1:33:07]  Acc_iter 30100       Data time: 0.05(0.01)  Forward time: 0.58(0.51)  Batch time: 0.64(0.52)
2025-07-12 14:33:09,268   INFO  Train:   74/100 ( 74%) [ 365/408 ( 89%)]  Loss: 2.739 (2.67)  LR: 1.196e-03  Time cost: 03:09/00:22 [2:54:12/1:31:58]  Acc_iter 30150       Data time: 0.00(0.01)  Forward time: 0.32(0.51)  Batch time: 0.32(0.52)
2025-07-12 14:33:28,782   INFO  Train:   74/100 ( 74%) [ 407/408 (100%)]  Loss: 1.999 (2.66)  LR: 1.188e-03  Time cost: 03:29/00:00 [2:54:32/1:30:38]  Acc_iter 30192       Data time: 0.00(0.01)  Forward time: 0.15(0.50)  Batch time: 0.16(0.51)
2025-07-12 14:33:33,013   INFO  Train:   75/100 ( 75%) [   0/408 (  0%)]  Loss: 2.766 (2.77)  LR: 1.188e-03  Time cost: 00:03/22:52 [2:54:36/9:54:35]  Acc_iter 30193       Data time: 2.49(2.49)  Forward time: 0.88(0.88)  Batch time: 3.36(3.36)
2025-07-12 14:33:37,031   INFO  Train:   75/100 ( 75%) [   7/408 (  2%)]  Loss: 3.244 (2.88)  LR: 1.187e-03  Time cost: 00:07/06:09 [2:54:40/2:43:00]  Acc_iter 30200       Data time: 0.00(0.31)  Forward time: 0.46(0.61)  Batch time: 0.46(0.92)
2025-07-12 14:34:02,558   INFO  Train:   75/100 ( 75%) [  57/408 ( 14%)]  Loss: 1.984 (2.63)  LR: 1.177e-03  Time cost: 00:32/03:19 [2:55:06/1:39:46]  Acc_iter 30250       Data time: 0.00(0.05)  Forward time: 0.56(0.52)  Batch time: 0.57(0.57)
2025-07-12 14:34:28,547   INFO  Train:   75/100 ( 75%) [ 107/408 ( 26%)]  Loss: 2.699 (2.66)  LR: 1.168e-03  Time cost: 00:58/02:44 [2:55:32/1:35:26]  Acc_iter 30300       Data time: 0.00(0.03)  Forward time: 0.56(0.52)  Batch time: 0.57(0.55)
2025-07-12 14:34:54,010   INFO  Train:   75/100 ( 75%) [ 157/408 ( 38%)]  Loss: 1.845 (2.68)  LR: 1.159e-03  Time cost: 01:24/02:14 [2:55:57/1:33:00]  Acc_iter 30350       Data time: 0.00(0.02)  Forward time: 0.24(0.51)  Batch time: 0.24(0.53)
2025-07-12 14:35:19,673   INFO  Train:   75/100 ( 75%) [ 207/408 ( 51%)]  Loss: 3.181 (2.64)  LR: 1.149e-03  Time cost: 01:50/01:46 [2:56:23/1:31:41]  Acc_iter 30400       Data time: 0.00(0.02)  Forward time: 0.55(0.51)  Batch time: 0.55(0.53)
2025-07-12 14:35:45,573   INFO  Train:   75/100 ( 75%) [ 257/408 ( 63%)]  Loss: 2.815 (2.65)  LR: 1.140e-03  Time cost: 02:15/01:19 [2:56:49/1:30:53]  Acc_iter 30450       Data time: 0.00(0.01)  Forward time: 0.39(0.51)  Batch time: 0.39(0.53)
2025-07-12 14:36:10,415   INFO  Train:   75/100 ( 75%) [ 307/408 ( 75%)]  Loss: 2.152 (2.62)  LR: 1.131e-03  Time cost: 02:40/00:52 [2:57:14/1:29:36]  Acc_iter 30500       Data time: 0.00(0.01)  Forward time: 0.43(0.51)  Batch time: 0.44(0.52)
2025-07-12 14:36:35,262   INFO  Train:   75/100 ( 75%) [ 357/408 ( 88%)]  Loss: 1.742 (2.63)  LR: 1.121e-03  Time cost: 03:05/00:26 [2:57:38/1:28:34]  Acc_iter 30550       Data time: 0.00(0.01)  Forward time: 0.64(0.51)  Batch time: 0.65(0.52)
2025-07-12 14:36:58,775   INFO  Train:   75/100 ( 75%) [ 407/408 (100%)]  Loss: 2.301 (2.62)  LR: 1.112e-03  Time cost: 03:29/00:00 [2:58:02/1:27:08]  Acc_iter 30600       Data time: 0.00(0.01)  Forward time: 0.18(0.50)  Batch time: 0.18(0.51)
2025-07-12 14:37:03,140   INFO  Train:   76/100 ( 76%) [   0/408 (  0%)]  Loss: 3.769 (3.77)  LR: 1.112e-03  Time cost: 00:03/23:55 [2:58:06/9:58:13]  Acc_iter 30601       Data time: 2.05(2.05)  Forward time: 1.47(1.47)  Batch time: 3.52(3.52)
2025-07-12 14:37:29,053   INFO  Train:   76/100 ( 76%) [  49/408 ( 12%)]  Loss: 2.511 (2.53)  LR: 1.103e-03  Time cost: 00:29/03:31 [2:58:32/1:39:35]  Acc_iter 30650       Data time: 0.00(0.05)  Forward time: 0.25(0.54)  Batch time: 0.25(0.59)
2025-07-12 14:37:55,900   INFO  Train:   76/100 ( 76%) [  99/408 ( 24%)]  Loss: 2.608 (2.52)  LR: 1.093e-03  Time cost: 00:56/02:53 [2:58:59/1:34:44]  Acc_iter 30700       Data time: 0.00(0.03)  Forward time: 0.40(0.54)  Batch time: 0.41(0.56)
2025-07-12 14:38:20,602   INFO  Train:   76/100 ( 76%) [ 149/408 ( 37%)]  Loss: 2.460 (2.51)  LR: 1.084e-03  Time cost: 01:20/02:19 [2:59:24/1:30:26]  Acc_iter 30750       Data time: 0.00(0.02)  Forward time: 0.29(0.52)  Batch time: 0.30(0.54)
2025-07-12 14:38:46,578   INFO  Train:   76/100 ( 76%) [ 199/408 ( 49%)]  Loss: 2.606 (2.53)  LR: 1.075e-03  Time cost: 01:46/01:51 [2:59:50/1:29:08]  Acc_iter 30800       Data time: 0.00(0.02)  Forward time: 0.60(0.52)  Batch time: 0.60(0.53)
2025-07-12 14:39:11,804   INFO  Train:   76/100 ( 76%) [ 249/408 ( 61%)]  Loss: 2.686 (2.55)  LR: 1.066e-03  Time cost: 02:12/01:24 [3:00:15/1:27:41]  Acc_iter 30850       Data time: 0.00(0.01)  Forward time: 0.56(0.52)  Batch time: 0.56(0.53)
2025-07-12 14:39:36,786   INFO  Train:   76/100 ( 76%) [ 299/408 ( 73%)]  Loss: 2.709 (2.53)  LR: 1.056e-03  Time cost: 02:37/00:57 [3:00:40/1:26:26]  Acc_iter 30900       Data time: 0.00(0.01)  Forward time: 0.29(0.51)  Batch time: 0.29(0.52)
2025-07-12 14:40:02,515   INFO  Train:   76/100 ( 76%) [ 349/408 ( 86%)]  Loss: 2.994 (2.52)  LR: 1.047e-03  Time cost: 03:02/00:30 [3:01:06/1:25:47]  Acc_iter 30950       Data time: 0.00(0.01)  Forward time: 0.59(0.51)  Batch time: 0.60(0.52)
2025-07-12 14:40:27,905   INFO  Train:   76/100 ( 76%) [ 399/408 ( 98%)]  Loss: 2.511 (2.53)  LR: 1.038e-03  Time cost: 03:28/00:04 [3:01:31/1:25:03]  Acc_iter 31000       Data time: 0.00(0.01)  Forward time: 0.38(0.51)  Batch time: 0.39(0.52)
2025-07-12 14:40:29,806   INFO  Train:   76/100 ( 76%) [ 407/408 (100%)]  Loss: 1.825 (2.52)  LR: 1.037e-03  Time cost: 03:30/00:00 [3:01:33/1:24:04]  Acc_iter 31008       Data time: 0.00(0.01)  Forward time: 0.16(0.51)  Batch time: 0.17(0.52)
2025-07-12 14:40:34,203   INFO  Train:   77/100 ( 77%) [   0/408 (  0%)]  Loss: 2.872 (2.87)  LR: 1.036e-03  Time cost: 00:03/24:08 [3:01:37/9:39:18]  Acc_iter 31009       Data time: 2.35(2.35)  Forward time: 1.20(1.20)  Batch time: 3.55(3.55)
2025-07-12 14:40:54,671   INFO  Train:   77/100 ( 77%) [  41/408 ( 10%)]  Loss: 2.083 (2.47)  LR: 1.029e-03  Time cost: 00:24/03:29 [3:01:58/1:32:56]  Acc_iter 31050       Data time: 0.00(0.06)  Forward time: 0.58(0.51)  Batch time: 0.58(0.57)
2025-07-12 14:41:19,273   INFO  Train:   77/100 ( 77%) [  91/408 ( 22%)]  Loss: 1.875 (2.47)  LR: 1.020e-03  Time cost: 00:48/02:47 [3:02:22/1:25:26]  Acc_iter 31100       Data time: 0.01(0.03)  Forward time: 0.43(0.50)  Batch time: 0.45(0.53)
2025-07-12 14:41:44,485   INFO  Train:   77/100 ( 77%) [ 141/408 ( 35%)]  Loss: 3.885 (2.51)  LR: 1.011e-03  Time cost: 01:13/02:18 [3:02:48/1:23:37]  Acc_iter 31150       Data time: 0.00(0.02)  Forward time: 0.65(0.50)  Batch time: 0.66(0.52)
2025-07-12 14:42:09,894   INFO  Train:   77/100 ( 77%) [ 191/408 ( 47%)]  Loss: 2.509 (2.48)  LR: 1.002e-03  Time cost: 01:39/01:52 [3:03:13/1:22:42]  Acc_iter 31200       Data time: 0.00(0.02)  Forward time: 0.53(0.50)  Batch time: 0.53(0.52)
2025-07-12 14:42:35,182   INFO  Train:   77/100 ( 77%) [ 241/408 ( 59%)]  Loss: 2.389 (2.52)  LR: 9.926e-04  Time cost: 02:04/01:25 [3:03:38/1:21:54]  Acc_iter 31250       Data time: 0.00(0.01)  Forward time: 0.37(0.50)  Batch time: 0.37(0.51)
2025-07-12 14:43:00,027   INFO  Train:   77/100 ( 77%) [ 291/408 ( 71%)]  Loss: 1.886 (2.51)  LR: 9.836e-04  Time cost: 02:29/00:59 [3:04:03/1:21:00]  Acc_iter 31300       Data time: 0.00(0.01)  Forward time: 0.31(0.50)  Batch time: 0.31(0.51)
2025-07-12 14:43:25,454   INFO  Train:   77/100 ( 77%) [ 341/408 ( 84%)]  Loss: 2.676 (2.53)  LR: 9.745e-04  Time cost: 02:54/00:34 [3:04:29/1:20:30]  Acc_iter 31350       Data time: 0.00(0.01)  Forward time: 0.38(0.50)  Batch time: 0.38(0.51)
2025-07-12 14:43:51,050   INFO  Train:   77/100 ( 77%) [ 391/408 ( 96%)]  Loss: 3.396 (2.53)  LR: 9.655e-04  Time cost: 03:20/00:08 [3:04:54/1:20:05]  Acc_iter 31400       Data time: 0.00(0.01)  Forward time: 0.27(0.50)  Batch time: 0.28(0.51)
2025-07-12 14:43:57,501   INFO  Train:   77/100 ( 77%) [ 407/408 (100%)]  Loss: 3.788 (2.53)  LR: 9.626e-04  Time cost: 03:26/00:00 [3:05:01/1:19:18]  Acc_iter 31416       Data time: 0.00(0.01)  Forward time: 0.15(0.50)  Batch time: 0.15(0.51)
2025-07-12 14:44:01,619   INFO  Train:   78/100 ( 78%) [   0/408 (  0%)]  Loss: 2.023 (2.02)  LR: 9.625e-04  Time cost: 00:03/22:46 [3:05:05/8:43:49]  Acc_iter 31417       Data time: 1.97(1.97)  Forward time: 1.37(1.37)  Batch time: 3.35(3.35)
2025-07-12 14:44:18,367   INFO  Train:   78/100 ( 78%) [  33/408 (  8%)]  Loss: 2.281 (2.45)  LR: 9.565e-04  Time cost: 00:20/03:41 [3:05:22/1:32:07]  Acc_iter 31450       Data time: 0.00(0.06)  Forward time: 0.54(0.53)  Batch time: 0.54(0.59)
2025-07-12 14:44:44,396   INFO  Train:   78/100 ( 78%) [  83/408 ( 20%)]  Loss: 1.925 (2.52)  LR: 9.476e-04  Time cost: 00:46/02:58 [3:05:48/1:25:07]  Acc_iter 31500       Data time: 0.00(0.03)  Forward time: 0.31(0.52)  Batch time: 0.32(0.55)
2025-07-12 14:45:09,946   INFO  Train:   78/100 ( 78%) [ 133/408 ( 33%)]  Loss: 1.585 (2.47)  LR: 9.386e-04  Time cost: 01:11/02:27 [3:06:13/1:22:28]  Acc_iter 31550       Data time: 0.00(0.02)  Forward time: 0.34(0.52)  Batch time: 0.35(0.53)
2025-07-12 14:45:36,049   INFO  Train:   78/100 ( 78%) [ 183/408 ( 45%)]  Loss: 3.708 (2.50)  LR: 9.297e-04  Time cost: 01:37/01:59 [3:06:39/1:21:29]  Acc_iter 31600       Data time: 0.00(0.01)  Forward time: 0.97(0.52)  Batch time: 0.97(0.53)
2025-07-12 14:46:01,495   INFO  Train:   78/100 ( 78%) [ 233/408 ( 57%)]  Loss: 1.795 (2.49)  LR: 9.208e-04  Time cost: 02:03/01:32 [3:07:05/1:20:18]  Acc_iter 31650       Data time: 0.00(0.01)  Forward time: 0.53(0.51)  Batch time: 0.53(0.53)
2025-07-12 14:46:26,082   INFO  Train:   78/100 ( 78%) [ 283/408 ( 69%)]  Loss: 1.705 (2.47)  LR: 9.120e-04  Time cost: 02:27/01:05 [3:07:29/1:18:56]  Acc_iter 31700       Data time: 0.00(0.01)  Forward time: 0.41(0.51)  Batch time: 0.42(0.52)
2025-07-12 14:46:51,523   INFO  Train:   78/100 ( 78%) [ 333/408 ( 82%)]  Loss: 2.641 (2.49)  LR: 9.031e-04  Time cost: 02:53/00:38 [3:07:55/1:18:14]  Acc_iter 31750       Data time: 0.01(0.01)  Forward time: 0.67(0.51)  Batch time: 0.68(0.52)
2025-07-12 14:47:16,242   INFO  Train:   78/100 ( 78%) [ 383/408 ( 94%)]  Loss: 1.964 (2.48)  LR: 8.943e-04  Time cost: 03:17/00:12 [3:08:19/1:17:20]  Acc_iter 31800       Data time: 0.00(0.01)  Forward time: 0.38(0.51)  Batch time: 0.38(0.52)
2025-07-12 14:47:26,409   INFO  Train:   78/100 ( 78%) [ 407/408 (100%)]  Loss: 2.715 (2.48)  LR: 8.901e-04  Time cost: 03:28/00:00 [3:08:30/1:16:19]  Acc_iter 31824       Data time: 0.00(0.01)  Forward time: 0.16(0.50)  Batch time: 0.16(0.51)
2025-07-12 14:47:31,306   INFO  Train:   79/100 ( 79%) [   0/408 (  0%)]  Loss: 2.344 (2.34)  LR: 8.899e-04  Time cost: 00:03/27:10 [3:08:34/9:57:53]  Acc_iter 31825       Data time: 2.63(2.63)  Forward time: 1.37(1.37)  Batch time: 4.00(4.00)
2025-07-12 14:47:43,645   INFO  Train:   79/100 ( 79%) [  25/408 (  6%)]  Loss: 2.046 (2.31)  LR: 8.855e-04  Time cost: 00:16/04:00 [3:08:47/1:33:43]  Acc_iter 31850       Data time: 0.00(0.10)  Forward time: 0.56(0.52)  Batch time: 0.56(0.63)
2025-07-12 14:48:09,109   INFO  Train:   79/100 ( 79%) [  75/408 ( 18%)]  Loss: 1.839 (2.47)  LR: 8.768e-04  Time cost: 00:41/03:03 [3:09:12/1:21:35]  Acc_iter 31900       Data time: 0.00(0.04)  Forward time: 0.58(0.51)  Batch time: 0.58(0.55)
2025-07-12 14:48:34,887   INFO  Train:   79/100 ( 79%) [ 125/408 ( 31%)]  Loss: 1.689 (2.47)  LR: 8.680e-04  Time cost: 01:07/02:31 [3:09:38/1:19:07]  Acc_iter 31950       Data time: 0.01(0.02)  Forward time: 0.44(0.51)  Batch time: 0.46(0.54)
2025-07-12 14:49:00,806   INFO  Train:   79/100 ( 79%) [ 175/408 ( 43%)]  Loss: 2.023 (2.45)  LR: 8.593e-04  Time cost: 01:33/02:03 [3:10:04/1:17:55]  Acc_iter 32000       Data time: 0.00(0.02)  Forward time: 0.60(0.51)  Batch time: 0.60(0.53)
2025-07-12 14:49:26,557   INFO  Train:   79/100 ( 79%) [ 225/408 ( 55%)]  Loss: 1.948 (2.45)  LR: 8.506e-04  Time cost: 01:59/01:36 [3:10:30/1:16:57]  Acc_iter 32050       Data time: 0.00(0.02)  Forward time: 0.33(0.51)  Batch time: 0.33(0.53)
2025-07-12 14:49:52,259   INFO  Train:   79/100 ( 79%) [ 275/408 ( 67%)]  Loss: 2.415 (2.46)  LR: 8.419e-04  Time cost: 02:24/01:09 [3:10:55/1:16:09]  Acc_iter 32100       Data time: 0.00(0.01)  Forward time: 0.71(0.51)  Batch time: 0.72(0.53)
2025-07-12 14:50:17,732   INFO  Train:   79/100 ( 79%) [ 325/408 ( 80%)]  Loss: 2.788 (2.45)  LR: 8.333e-04  Time cost: 02:50/00:43 [3:11:21/1:15:22]  Acc_iter 32150       Data time: 0.00(0.01)  Forward time: 0.37(0.51)  Batch time: 0.37(0.52)
2025-07-12 14:50:43,657   INFO  Train:   79/100 ( 79%) [ 375/408 ( 92%)]  Loss: 3.476 (2.45)  LR: 8.247e-04  Time cost: 03:16/00:17 [3:11:47/1:14:51]  Acc_iter 32200       Data time: 0.00(0.01)  Forward time: 0.47(0.51)  Batch time: 0.47(0.52)
2025-07-12 14:50:58,018   INFO  Train:   79/100 ( 79%) [ 407/408 (100%)]  Loss: 1.791 (2.46)  LR: 8.192e-04  Time cost: 03:30/00:00 [3:12:01/1:13:45]  Acc_iter 32232       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 14:51:02,835   INFO  Train:   80/100 ( 80%) [   0/408 (  0%)]  Loss: 2.249 (2.25)  LR: 8.190e-04  Time cost: 00:04/27:30 [3:12:06/9:37:46]  Acc_iter 32233       Data time: 3.22(3.22)  Forward time: 0.82(0.82)  Batch time: 4.05(4.05)
2025-07-12 14:51:11,235   INFO  Train:   80/100 ( 80%) [  17/408 (  4%)]  Loss: 2.912 (2.33)  LR: 8.161e-04  Time cost: 00:12/04:30 [3:12:14/1:38:32]  Acc_iter 32250       Data time: 0.00(0.18)  Forward time: 0.46(0.51)  Batch time: 0.46(0.69)
2025-07-12 14:51:37,724   INFO  Train:   80/100 ( 80%) [  67/408 ( 16%)]  Loss: 2.470 (2.40)  LR: 8.076e-04  Time cost: 00:38/03:15 [3:12:41/1:21:07]  Acc_iter 32300       Data time: 0.00(0.05)  Forward time: 0.39(0.52)  Batch time: 0.39(0.57)
2025-07-12 14:52:04,552   INFO  Train:   80/100 ( 80%) [ 117/408 ( 29%)]  Loss: 1.950 (2.38)  LR: 7.990e-04  Time cost: 01:05/02:42 [3:13:08/1:18:29]  Acc_iter 32350       Data time: 0.00(0.03)  Forward time: 0.38(0.53)  Batch time: 0.38(0.56)
2025-07-12 14:52:30,249   INFO  Train:   80/100 ( 80%) [ 167/408 ( 41%)]  Loss: 2.432 (2.40)  LR: 7.906e-04  Time cost: 01:31/02:11 [3:13:33/1:16:13]  Acc_iter 32400       Data time: 0.00(0.02)  Forward time: 0.49(0.52)  Batch time: 0.50(0.54)
2025-07-12 14:52:56,208   INFO  Train:   80/100 ( 80%) [ 217/408 ( 53%)]  Loss: 2.340 (2.39)  LR: 7.821e-04  Time cost: 01:57/01:42 [3:13:59/1:14:57]  Acc_iter 32450       Data time: 0.00(0.02)  Forward time: 0.42(0.52)  Batch time: 0.43(0.54)
2025-07-12 14:53:21,324   INFO  Train:   80/100 ( 80%) [ 267/408 ( 65%)]  Loss: 1.740 (2.40)  LR: 7.736e-04  Time cost: 02:22/01:14 [3:14:24/1:13:34]  Acc_iter 32500       Data time: 0.00(0.02)  Forward time: 0.31(0.52)  Batch time: 0.32(0.53)
2025-07-12 14:53:47,575   INFO  Train:   80/100 ( 80%) [ 317/408 ( 78%)]  Loss: 2.693 (2.41)  LR: 7.652e-04  Time cost: 02:48/00:48 [3:14:51/1:12:59]  Acc_iter 32550       Data time: 0.00(0.01)  Forward time: 0.51(0.52)  Batch time: 0.52(0.53)
2025-07-12 14:54:13,195   INFO  Train:   80/100 ( 80%) [ 367/408 ( 90%)]  Loss: 2.137 (2.39)  LR: 7.569e-04  Time cost: 03:14/00:21 [3:15:16/1:12:12]  Acc_iter 32600       Data time: 0.00(0.01)  Forward time: 0.56(0.52)  Batch time: 0.57(0.53)
2025-07-12 14:54:32,212   INFO  Train:   80/100 ( 80%) [ 407/408 (100%)]  Loss: 1.929 (2.38)  LR: 7.502e-04  Time cost: 03:33/00:00 [3:15:35/1:11:08]  Acc_iter 32640       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 14:54:36,090   INFO  Train:   81/100 ( 81%) [   0/408 (  0%)]  Loss: 2.150 (2.15)  LR: 7.500e-04  Time cost: 00:03/21:12 [3:15:39/7:04:09]  Acc_iter 32641       Data time: 2.09(2.09)  Forward time: 1.02(1.02)  Batch time: 3.12(3.12)
2025-07-12 14:54:41,210   INFO  Train:   81/100 ( 81%) [   9/408 (  2%)]  Loss: 3.123 (2.29)  LR: 7.485e-04  Time cost: 00:08/05:28 [3:15:44/1:51:55]  Acc_iter 32650       Data time: 0.00(0.21)  Forward time: 0.59(0.61)  Batch time: 0.60(0.82)
2025-07-12 14:55:07,326   INFO  Train:   81/100 ( 81%) [  59/408 ( 14%)]  Loss: 1.764 (2.40)  LR: 7.402e-04  Time cost: 00:34/03:19 [3:16:10/1:17:18]  Acc_iter 32700       Data time: 0.00(0.04)  Forward time: 0.58(0.53)  Batch time: 0.58(0.57)
2025-07-12 14:55:33,095   INFO  Train:   81/100 ( 81%) [ 109/408 ( 27%)]  Loss: 2.407 (2.39)  LR: 7.319e-04  Time cost: 01:00/02:43 [3:16:36/1:13:20]  Acc_iter 32750       Data time: 0.00(0.02)  Forward time: 0.35(0.52)  Batch time: 0.35(0.55)
2025-07-12 14:55:59,961   INFO  Train:   81/100 ( 81%) [ 159/408 ( 39%)]  Loss: 1.798 (2.37)  LR: 7.237e-04  Time cost: 01:26/02:15 [3:17:03/1:12:30]  Acc_iter 32800       Data time: 0.00(0.02)  Forward time: 0.34(0.53)  Batch time: 0.35(0.54)
2025-07-12 14:56:26,353   INFO  Train:   81/100 ( 81%) [ 209/408 ( 51%)]  Loss: 2.214 (2.39)  LR: 7.155e-04  Time cost: 01:53/01:47 [3:17:29/1:11:32]  Acc_iter 32850       Data time: 0.00(0.01)  Forward time: 0.37(0.53)  Batch time: 0.37(0.54)
2025-07-12 14:56:52,583   INFO  Train:   81/100 ( 81%) [ 259/408 ( 63%)]  Loss: 2.005 (2.40)  LR: 7.073e-04  Time cost: 02:19/01:20 [3:17:56/1:10:42]  Acc_iter 32900       Data time: 0.01(0.01)  Forward time: 0.40(0.52)  Batch time: 0.41(0.54)
2025-07-12 14:57:17,815   INFO  Train:   81/100 ( 81%) [ 309/408 ( 76%)]  Loss: 2.667 (2.38)  LR: 6.991e-04  Time cost: 02:44/00:52 [3:18:21/1:09:34]  Acc_iter 32950       Data time: 0.00(0.01)  Forward time: 0.35(0.52)  Batch time: 0.35(0.53)
2025-07-12 14:57:43,871   INFO  Train:   81/100 ( 81%) [ 359/408 ( 88%)]  Loss: 2.949 (2.39)  LR: 6.910e-04  Time cost: 03:10/00:25 [3:18:47/1:08:56]  Acc_iter 33000       Data time: 0.00(0.01)  Forward time: 0.41(0.52)  Batch time: 0.41(0.53)
2025-07-12 14:58:06,191   INFO  Train:   81/100 ( 81%) [ 407/408 (100%)]  Loss: 6.365 (2.38)  LR: 6.832e-04  Time cost: 03:33/00:00 [3:19:09/1:07:31]  Acc_iter 33048       Data time: 0.00(0.01)  Forward time: 0.14(0.51)  Batch time: 0.14(0.52)
2025-07-12 14:58:10,723   INFO  Train:   82/100 ( 82%) [   0/408 (  0%)]  Loss: 2.547 (2.55)  LR: 6.831e-04  Time cost: 00:03/25:50 [3:19:14/8:11:05]  Acc_iter 33049       Data time: 2.73(2.73)  Forward time: 1.07(1.07)  Batch time: 3.80(3.80)
2025-07-12 14:58:11,324   INFO  Train:   82/100 ( 82%) [   1/408 (  0%)]  Loss: 1.978 (2.26)  LR: 6.829e-04  Time cost: 00:04/14:55 [3:19:14/4:44:19]  Acc_iter 33050       Data time: 0.01(1.37)  Forward time: 0.60(0.83)  Batch time: 0.60(2.20)
2025-07-12 14:58:36,367   INFO  Train:   82/100 ( 82%) [  51/408 ( 12%)]  Loss: 2.094 (2.22)  LR: 6.748e-04  Time cost: 00:29/03:22 [3:19:40/1:12:40]  Acc_iter 33100       Data time: 0.00(0.06)  Forward time: 0.35(0.51)  Batch time: 0.35(0.57)
2025-07-12 14:59:01,167   INFO  Train:   82/100 ( 82%) [ 101/408 ( 25%)]  Loss: 2.602 (2.23)  LR: 6.668e-04  Time cost: 00:54/02:43 [3:20:04/1:07:48]  Acc_iter 33150       Data time: 0.00(0.03)  Forward time: 0.28(0.50)  Batch time: 0.29(0.53)
2025-07-12 14:59:26,508   INFO  Train:   82/100 ( 82%) [ 151/408 ( 37%)]  Loss: 1.786 (2.27)  LR: 6.588e-04  Time cost: 01:19/02:14 [3:20:30/1:06:19]  Acc_iter 33200       Data time: 0.00(0.02)  Forward time: 0.50(0.50)  Batch time: 0.51(0.52)
2025-07-12 14:59:52,257   INFO  Train:   82/100 ( 82%) [ 201/408 ( 49%)]  Loss: 3.090 (2.35)  LR: 6.509e-04  Time cost: 01:45/01:47 [3:20:55/1:05:37]  Acc_iter 33250       Data time: 0.00(0.02)  Forward time: 0.41(0.50)  Batch time: 0.41(0.52)
2025-07-12 15:00:17,534   INFO  Train:   82/100 ( 82%) [ 251/408 ( 62%)]  Loss: 1.622 (2.34)  LR: 6.430e-04  Time cost: 02:10/01:21 [3:21:21/1:04:47]  Acc_iter 33300       Data time: 0.00(0.01)  Forward time: 0.84(0.50)  Batch time: 0.84(0.52)
2025-07-12 15:00:42,023   INFO  Train:   82/100 ( 82%) [ 301/408 ( 74%)]  Loss: 2.132 (2.36)  LR: 6.351e-04  Time cost: 02:35/00:54 [3:21:45/1:03:46]  Acc_iter 33350       Data time: 0.00(0.01)  Forward time: 0.56(0.50)  Batch time: 0.56(0.51)
2025-07-12 15:01:08,196   INFO  Train:   82/100 ( 82%) [ 351/408 ( 86%)]  Loss: 2.272 (2.37)  LR: 6.272e-04  Time cost: 03:01/00:29 [3:22:11/1:03:31]  Acc_iter 33400       Data time: 0.00(0.01)  Forward time: 0.61(0.50)  Batch time: 0.61(0.51)
2025-07-12 15:01:33,012   INFO  Train:   82/100 ( 82%) [ 401/408 ( 98%)]  Loss: 2.838 (2.37)  LR: 6.194e-04  Time cost: 03:26/00:03 [3:22:36/1:02:48]  Acc_iter 33450       Data time: 0.00(0.01)  Forward time: 0.25(0.50)  Batch time: 0.25(0.51)
2025-07-12 15:01:34,321   INFO  Train:   82/100 ( 82%) [ 407/408 (100%)]  Loss: 1.187 (2.36)  LR: 6.185e-04  Time cost: 03:27/00:00 [3:22:37/1:02:13]  Acc_iter 33456       Data time: 0.00(0.01)  Forward time: 0.12(0.50)  Batch time: 0.13(0.51)
2025-07-12 15:01:38,589   INFO  Train:   83/100 ( 83%) [   0/408 (  0%)]  Loss: 2.175 (2.18)  LR: 6.183e-04  Time cost: 00:03/23:44 [3:22:42/7:07:27]  Acc_iter 33457       Data time: 2.59(2.59)  Forward time: 0.90(0.90)  Batch time: 3.49(3.49)
2025-07-12 15:02:01,192   INFO  Train:   83/100 ( 83%) [  43/408 ( 11%)]  Loss: 1.677 (2.30)  LR: 6.117e-04  Time cost: 00:26/03:36 [3:23:04/1:12:10]  Acc_iter 33500       Data time: 0.00(0.06)  Forward time: 0.68(0.53)  Batch time: 0.68(0.59)
2025-07-12 15:02:27,292   INFO  Train:   83/100 ( 83%) [  93/408 ( 23%)]  Loss: 2.870 (2.38)  LR: 6.039e-04  Time cost: 00:52/02:54 [3:23:30/1:07:06]  Acc_iter 33550       Data time: 0.00(0.03)  Forward time: 0.53(0.52)  Batch time: 0.53(0.56)
2025-07-12 15:02:52,219   INFO  Train:   83/100 ( 83%) [ 143/408 ( 35%)]  Loss: 2.461 (2.33)  LR: 5.962e-04  Time cost: 01:17/02:21 [3:23:55/1:04:16]  Acc_iter 33600       Data time: 0.00(0.02)  Forward time: 0.36(0.51)  Batch time: 0.36(0.54)
2025-07-12 15:03:16,564   INFO  Train:   83/100 ( 83%) [ 193/408 ( 47%)]  Loss: 3.041 (2.33)  LR: 5.886e-04  Time cost: 01:41/01:52 [3:24:20/1:02:20]  Acc_iter 33650       Data time: 0.00(0.02)  Forward time: 0.39(0.51)  Batch time: 0.39(0.52)
2025-07-12 15:03:41,945   INFO  Train:   83/100 ( 83%) [ 243/408 ( 60%)]  Loss: 2.065 (2.32)  LR: 5.809e-04  Time cost: 02:06/01:25 [3:24:45/1:01:31]  Acc_iter 33700       Data time: 0.00(0.01)  Forward time: 0.65(0.51)  Batch time: 0.66(0.52)
2025-07-12 15:04:07,071   INFO  Train:   83/100 ( 83%) [ 293/408 ( 72%)]  Loss: 2.074 (2.33)  LR: 5.733e-04  Time cost: 02:31/00:59 [3:25:10/1:00:44]  Acc_iter 33750       Data time: 0.00(0.01)  Forward time: 0.56(0.50)  Batch time: 0.56(0.52)
2025-07-12 15:04:32,232   INFO  Train:   83/100 ( 83%) [ 343/408 ( 84%)]  Loss: 2.511 (2.31)  LR: 5.658e-04  Time cost: 02:57/00:33 [3:25:35/1:00:05]  Acc_iter 33800       Data time: 0.00(0.01)  Forward time: 0.53(0.50)  Batch time: 0.54(0.51)
2025-07-12 15:04:57,339   INFO  Train:   83/100 ( 83%) [ 393/408 ( 96%)]  Loss: 1.890 (2.31)  LR: 5.583e-04  Time cost: 03:22/00:07 [3:26:00/59:27]  Acc_iter 33850       Data time: 0.00(0.01)  Forward time: 0.43(0.50)  Batch time: 0.44(0.51)
2025-07-12 15:05:02,282   INFO  Train:   83/100 ( 83%) [ 407/408 (100%)]  Loss: 1.845 (2.31)  LR: 5.562e-04  Time cost: 03:27/00:00 [3:26:05/58:42]  Acc_iter 33864       Data time: 0.00(0.01)  Forward time: 0.19(0.50)  Batch time: 0.19(0.51)
2025-07-12 15:05:07,065   INFO  Train:   84/100 ( 84%) [   0/408 (  0%)]  Loss: 1.893 (1.89)  LR: 5.560e-04  Time cost: 00:03/26:13 [3:26:10/7:25:50]  Acc_iter 33865       Data time: 2.66(2.66)  Forward time: 1.20(1.20)  Batch time: 3.86(3.86)
2025-07-12 15:05:25,020   INFO  Train:   84/100 ( 84%) [  35/408 (  9%)]  Loss: 2.102 (2.32)  LR: 5.508e-04  Time cost: 00:21/03:45 [3:26:28/1:09:41]  Acc_iter 33900       Data time: 0.00(0.08)  Forward time: 0.67(0.53)  Batch time: 0.67(0.61)
2025-07-12 15:05:50,416   INFO  Train:   84/100 ( 84%) [  85/408 ( 21%)]  Loss: 1.850 (2.25)  LR: 5.434e-04  Time cost: 00:47/02:57 [3:26:54/1:02:40]  Acc_iter 33950       Data time: 0.00(0.04)  Forward time: 0.50(0.51)  Batch time: 0.50(0.55)
2025-07-12 15:06:15,685   INFO  Train:   84/100 ( 84%) [ 135/408 ( 33%)]  Loss: 2.006 (2.28)  LR: 5.360e-04  Time cost: 01:12/02:25 [3:27:19/1:00:24]  Acc_iter 34000       Data time: 0.00(0.02)  Forward time: 0.72(0.51)  Batch time: 0.73(0.53)
2025-07-12 15:06:40,805   INFO  Train:   84/100 ( 84%) [ 185/408 ( 45%)]  Loss: 2.358 (2.26)  LR: 5.286e-04  Time cost: 01:37/01:57 [3:27:44/59:02]  Acc_iter 34050       Data time: 0.00(0.02)  Forward time: 0.38(0.51)  Batch time: 0.38(0.52)
2025-07-12 15:07:06,597   INFO  Train:   84/100 ( 84%) [ 235/408 ( 58%)]  Loss: 2.600 (2.25)  LR: 5.213e-04  Time cost: 02:03/01:30 [3:28:10/58:23]  Acc_iter 34100       Data time: 0.00(0.02)  Forward time: 0.69(0.51)  Batch time: 0.69(0.52)
2025-07-12 15:07:32,029   INFO  Train:   84/100 ( 84%) [ 285/408 ( 70%)]  Loss: 1.892 (2.27)  LR: 5.140e-04  Time cost: 02:28/01:04 [3:28:35/57:40]  Acc_iter 34150       Data time: 0.00(0.01)  Forward time: 0.67(0.51)  Batch time: 0.67(0.52)
2025-07-12 15:07:57,991   INFO  Train:   84/100 ( 84%) [ 335/408 ( 82%)]  Loss: 1.812 (2.27)  LR: 5.068e-04  Time cost: 02:54/00:37 [3:29:01/57:13]  Acc_iter 34200       Data time: 0.00(0.01)  Forward time: 0.73(0.51)  Batch time: 0.73(0.52)
2025-07-12 15:08:23,968   INFO  Train:   84/100 ( 84%) [ 385/408 ( 94%)]  Loss: 2.120 (2.28)  LR: 4.996e-04  Time cost: 03:20/00:11 [3:29:27/56:47]  Acc_iter 34250       Data time: 0.00(0.01)  Forward time: 0.51(0.51)  Batch time: 0.51(0.52)
2025-07-12 15:08:33,269   INFO  Train:   84/100 ( 84%) [ 407/408 (100%)]  Loss: 1.787 (2.28)  LR: 4.965e-04  Time cost: 03:30/00:00 [3:29:36/56:01]  Acc_iter 34272       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.14(0.51)
2025-07-12 15:08:37,660   INFO  Train:   85/100 ( 85%) [   0/408 (  0%)]  Loss: 1.330 (1.33)  LR: 4.963e-04  Time cost: 00:03/23:47 [3:29:41/6:20:38]  Acc_iter 34273       Data time: 2.20(2.20)  Forward time: 1.30(1.30)  Batch time: 3.50(3.50)
2025-07-12 15:08:51,868   INFO  Train:   85/100 ( 85%) [  27/408 (  7%)]  Loss: 1.291 (2.21)  LR: 4.925e-04  Time cost: 00:17/04:00 [3:29:55/1:08:31]  Acc_iter 34300       Data time: 0.00(0.08)  Forward time: 0.56(0.55)  Batch time: 0.56(0.63)
2025-07-12 15:09:16,933   INFO  Train:   85/100 ( 85%) [  77/408 ( 19%)]  Loss: 2.468 (2.21)  LR: 4.854e-04  Time cost: 00:42/03:01 [3:30:20/58:57]  Acc_iter 34350       Data time: 0.00(0.03)  Forward time: 0.47(0.52)  Batch time: 0.47(0.55)
2025-07-12 15:09:42,324   INFO  Train:   85/100 ( 85%) [ 127/408 ( 31%)]  Loss: 2.008 (2.22)  LR: 4.783e-04  Time cost: 01:08/02:29 [3:30:45/56:48]  Acc_iter 34400       Data time: 0.00(0.02)  Forward time: 0.45(0.51)  Batch time: 0.45(0.53)
2025-07-12 15:10:07,311   INFO  Train:   85/100 ( 85%) [ 177/408 ( 43%)]  Loss: 2.494 (2.23)  LR: 4.713e-04  Time cost: 01:33/02:00 [3:31:10/55:23]  Acc_iter 34450       Data time: 0.00(0.02)  Forward time: 0.31(0.51)  Batch time: 0.32(0.52)
2025-07-12 15:10:32,746   INFO  Train:   85/100 ( 85%) [ 227/408 ( 56%)]  Loss: 1.974 (2.24)  LR: 4.643e-04  Time cost: 01:58/01:34 [3:31:36/54:37]  Acc_iter 34500       Data time: 0.00(0.01)  Forward time: 0.54(0.51)  Batch time: 0.55(0.52)
2025-07-12 15:10:57,843   INFO  Train:   85/100 ( 85%) [ 277/408 ( 68%)]  Loss: 2.888 (2.26)  LR: 4.573e-04  Time cost: 02:23/01:07 [3:32:01/53:50]  Acc_iter 34550       Data time: 0.00(0.01)  Forward time: 0.33(0.51)  Batch time: 0.34(0.52)
2025-07-12 15:11:23,534   INFO  Train:   85/100 ( 85%) [ 327/408 ( 80%)]  Loss: 1.767 (2.24)  LR: 4.504e-04  Time cost: 02:49/00:41 [3:32:27/53:22]  Acc_iter 34600       Data time: 0.00(0.01)  Forward time: 0.67(0.51)  Batch time: 0.68(0.52)
2025-07-12 15:11:48,848   INFO  Train:   85/100 ( 85%) [ 377/408 ( 92%)]  Loss: 1.642 (2.23)  LR: 4.436e-04  Time cost: 03:14/00:15 [3:32:52/52:48]  Acc_iter 34650       Data time: 0.00(0.01)  Forward time: 0.50(0.51)  Batch time: 0.50(0.52)
2025-07-12 15:12:01,282   INFO  Train:   85/100 ( 85%) [ 407/408 (100%)]  Loss: 1.790 (2.24)  LR: 4.395e-04  Time cost: 03:27/00:00 [3:33:04/51:47]  Acc_iter 34680       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.14(0.51)
2025-07-12 15:12:06,074   INFO  Train:   86/100 ( 86%) [   0/408 (  0%)]  Loss: 1.408 (1.41)  LR: 4.394e-04  Time cost: 00:03/26:44 [3:33:09/6:41:09]  Acc_iter 34681       Data time: 2.84(2.84)  Forward time: 1.09(1.09)  Batch time: 3.93(3.93)
2025-07-12 15:12:15,788   INFO  Train:   86/100 ( 86%) [  19/408 (  5%)]  Loss: 1.733 (2.20)  LR: 4.368e-04  Time cost: 00:13/04:25 [3:33:19/1:09:22]  Acc_iter 34700       Data time: 0.00(0.15)  Forward time: 0.53(0.54)  Batch time: 0.53(0.68)
2025-07-12 15:12:41,107   INFO  Train:   86/100 ( 86%) [  69/408 ( 17%)]  Loss: 1.950 (2.26)  LR: 4.300e-04  Time cost: 00:38/03:08 [3:33:44/56:08]  Acc_iter 34750       Data time: 0.00(0.04)  Forward time: 0.55(0.51)  Batch time: 0.55(0.56)
2025-07-12 15:13:06,068   INFO  Train:   86/100 ( 86%) [ 119/408 ( 29%)]  Loss: 1.605 (2.25)  LR: 4.233e-04  Time cost: 01:03/02:33 [3:34:09/53:16]  Acc_iter 34800       Data time: 0.00(0.03)  Forward time: 0.30(0.50)  Batch time: 0.30(0.53)
2025-07-12 15:13:31,358   INFO  Train:   86/100 ( 86%) [ 169/408 ( 41%)]  Loss: 2.279 (2.27)  LR: 4.166e-04  Time cost: 01:29/02:05 [3:34:35/52:03]  Acc_iter 34850       Data time: 0.00(0.02)  Forward time: 0.40(0.50)  Batch time: 0.41(0.52)
2025-07-12 15:13:56,401   INFO  Train:   86/100 ( 86%) [ 219/408 ( 54%)]  Loss: 1.623 (2.25)  LR: 4.100e-04  Time cost: 01:54/01:38 [3:35:00/51:04]  Acc_iter 34900       Data time: 0.00(0.02)  Forward time: 0.53(0.50)  Batch time: 0.53(0.52)
2025-07-12 15:14:22,312   INFO  Train:   86/100 ( 86%) [ 269/408 ( 66%)]  Loss: 2.399 (2.24)  LR: 4.034e-04  Time cost: 02:20/01:12 [3:35:25/50:37]  Acc_iter 34950       Data time: 0.00(0.01)  Forward time: 0.69(0.50)  Batch time: 0.69(0.52)
2025-07-12 15:14:47,973   INFO  Train:   86/100 ( 86%) [ 319/408 ( 78%)]  Loss: 1.812 (2.24)  LR: 3.968e-04  Time cost: 02:45/00:46 [3:35:51/50:06]  Acc_iter 35000       Data time: 0.00(0.01)  Forward time: 0.56(0.51)  Batch time: 0.57(0.52)
2025-07-12 15:15:12,893   INFO  Train:   86/100 ( 86%) [ 369/408 ( 90%)]  Loss: 2.200 (2.23)  LR: 3.903e-04  Time cost: 03:10/00:20 [3:36:16/49:24]  Acc_iter 35050       Data time: 0.00(0.01)  Forward time: 0.33(0.50)  Batch time: 0.33(0.52)
2025-07-12 15:15:29,855   INFO  Train:   86/100 ( 86%) [ 407/408 (100%)]  Loss: 3.051 (2.21)  LR: 3.854e-04  Time cost: 03:27/00:00 [3:36:33/48:28]  Acc_iter 35088       Data time: 0.00(0.01)  Forward time: 0.14(0.50)  Batch time: 0.14(0.51)
2025-07-12 15:15:34,998   INFO  Train:   87/100 ( 87%) [   0/408 (  0%)]  Loss: 2.401 (2.40)  LR: 3.853e-04  Time cost: 00:04/29:16 [3:36:38/6:49:46]  Acc_iter 35089       Data time: 3.36(3.36)  Forward time: 0.95(0.95)  Batch time: 4.30(4.30)
2025-07-12 15:15:40,440   INFO  Train:   87/100 ( 87%) [  11/408 (  3%)]  Loss: 1.805 (2.29)  LR: 3.839e-04  Time cost: 00:09/05:22 [3:36:44/1:17:10]  Acc_iter 35100       Data time: 0.00(0.28)  Forward time: 0.37(0.53)  Batch time: 0.38(0.81)
2025-07-12 15:16:05,960   INFO  Train:   87/100 ( 87%) [  61/408 ( 15%)]  Loss: 3.420 (2.13)  LR: 3.775e-04  Time cost: 00:35/03:17 [3:37:09/53:34]  Acc_iter 35150       Data time: 0.00(0.06)  Forward time: 0.43(0.51)  Batch time: 0.43(0.57)
2025-07-12 15:16:31,476   INFO  Train:   87/100 ( 87%) [ 111/408 ( 27%)]  Loss: 1.596 (2.14)  LR: 3.711e-04  Time cost: 01:00/02:41 [3:37:35/50:39]  Acc_iter 35200       Data time: 0.01(0.03)  Forward time: 0.44(0.51)  Batch time: 0.45(0.54)
2025-07-12 15:16:57,833   INFO  Train:   87/100 ( 87%) [ 161/408 ( 39%)]  Loss: 2.587 (2.17)  LR: 3.648e-04  Time cost: 01:27/02:12 [3:38:01/49:45]  Acc_iter 35250       Data time: 0.00(0.02)  Forward time: 0.69(0.51)  Batch time: 0.69(0.54)
2025-07-12 15:17:23,882   INFO  Train:   87/100 ( 87%) [ 211/408 ( 52%)]  Loss: 2.235 (2.18)  LR: 3.585e-04  Time cost: 01:53/01:45 [3:38:27/48:57]  Acc_iter 35300       Data time: 0.00(0.02)  Forward time: 0.49(0.51)  Batch time: 0.49(0.53)
2025-07-12 15:17:49,205   INFO  Train:   87/100 ( 87%) [ 261/408 ( 64%)]  Loss: 2.339 (2.19)  LR: 3.523e-04  Time cost: 02:18/01:17 [3:38:52/48:01]  Acc_iter 35350       Data time: 0.00(0.02)  Forward time: 0.33(0.51)  Batch time: 0.34(0.53)
2025-07-12 15:18:14,384   INFO  Train:   87/100 ( 87%) [ 311/408 ( 76%)]  Loss: 1.857 (2.21)  LR: 3.461e-04  Time cost: 02:43/00:50 [3:39:18/47:13]  Acc_iter 35400       Data time: 0.00(0.01)  Forward time: 0.76(0.51)  Batch time: 0.77(0.52)
2025-07-12 15:18:39,657   INFO  Train:   87/100 ( 87%) [ 361/408 ( 88%)]  Loss: 1.857 (2.19)  LR: 3.400e-04  Time cost: 03:08/00:24 [3:39:43/46:33]  Acc_iter 35450       Data time: 0.00(0.01)  Forward time: 0.34(0.51)  Batch time: 0.34(0.52)
2025-07-12 15:19:01,154   INFO  Train:   87/100 ( 87%) [ 407/408 (100%)]  Loss: 2.290 (2.20)  LR: 3.344e-04  Time cost: 03:30/00:00 [3:40:04/45:36]  Acc_iter 35496       Data time: 0.00(0.01)  Forward time: 0.16(0.50)  Batch time: 0.16(0.52)
2025-07-12 15:19:05,711   INFO  Train:   88/100 ( 88%) [   0/408 (  0%)]  Loss: 1.990 (1.99)  LR: 3.343e-04  Time cost: 00:03/25:07 [3:40:09/5:26:43]  Acc_iter 35497       Data time: 2.75(2.75)  Forward time: 0.94(0.94)  Batch time: 3.70(3.70)
2025-07-12 15:19:07,467   INFO  Train:   88/100 ( 88%) [   3/408 (  1%)]  Loss: 1.919 (2.16)  LR: 3.339e-04  Time cost: 00:05/09:11 [3:40:11/2:00:24]  Acc_iter 35500       Data time: 0.00(0.69)  Forward time: 0.42(0.67)  Batch time: 0.42(1.36)
2025-07-12 15:19:33,179   INFO  Train:   88/100 ( 88%) [  53/408 ( 13%)]  Loss: 2.788 (2.11)  LR: 3.279e-04  Time cost: 00:31/03:24 [3:40:36/50:30]  Acc_iter 35550       Data time: 0.00(0.06)  Forward time: 0.53(0.52)  Batch time: 0.54(0.58)
2025-07-12 15:19:58,505   INFO  Train:   88/100 ( 88%) [ 103/408 ( 25%)]  Loss: 1.585 (2.13)  LR: 3.219e-04  Time cost: 00:56/02:45 [3:41:02/47:05]  Acc_iter 35600       Data time: 0.00(0.03)  Forward time: 0.42(0.51)  Batch time: 0.42(0.54)
2025-07-12 15:20:24,093   INFO  Train:   88/100 ( 88%) [ 153/408 ( 38%)]  Loss: 2.458 (2.10)  LR: 3.160e-04  Time cost: 01:22/02:15 [3:41:27/45:45]  Acc_iter 35650       Data time: 0.00(0.02)  Forward time: 0.41(0.51)  Batch time: 0.41(0.53)
2025-07-12 15:20:49,212   INFO  Train:   88/100 ( 88%) [ 203/408 ( 50%)]  Loss: 3.001 (2.11)  LR: 3.101e-04  Time cost: 01:47/01:47 [3:41:52/44:40]  Acc_iter 35700       Data time: 0.00(0.02)  Forward time: 0.46(0.51)  Batch time: 0.46(0.53)
2025-07-12 15:21:14,372   INFO  Train:   88/100 ( 88%) [ 253/408 ( 62%)]  Loss: 1.676 (2.11)  LR: 3.043e-04  Time cost: 02:12/01:20 [3:42:18/43:52]  Acc_iter 35750       Data time: 0.00(0.01)  Forward time: 0.56(0.51)  Batch time: 0.56(0.52)
2025-07-12 15:21:39,674   INFO  Train:   88/100 ( 88%) [ 303/408 ( 74%)]  Loss: 2.613 (2.11)  LR: 2.985e-04  Time cost: 02:37/00:54 [3:42:43/43:13]  Acc_iter 35800       Data time: 0.00(0.01)  Forward time: 0.31(0.51)  Batch time: 0.31(0.52)
2025-07-12 15:22:04,606   INFO  Train:   88/100 ( 88%) [ 353/408 ( 87%)]  Loss: 1.981 (2.14)  LR: 2.928e-04  Time cost: 03:02/00:28 [3:43:08/42:33]  Acc_iter 35850       Data time: 0.00(0.01)  Forward time: 0.32(0.50)  Batch time: 0.33(0.52)
2025-07-12 15:22:29,705   INFO  Train:   88/100 ( 88%) [ 403/408 ( 99%)]  Loss: 1.963 (2.14)  LR: 2.871e-04  Time cost: 03:27/00:02 [3:43:33/41:59]  Acc_iter 35900       Data time: 0.00(0.01)  Forward time: 0.26(0.50)  Batch time: 0.27(0.51)
2025-07-12 15:22:30,626   INFO  Train:   88/100 ( 88%) [ 407/408 (100%)]  Loss: 1.583 (2.14)  LR: 2.866e-04  Time cost: 03:28/00:00 [3:43:34/41:43]  Acc_iter 35904       Data time: 0.00(0.01)  Forward time: 0.13(0.50)  Batch time: 0.14(0.51)
2025-07-12 15:22:34,810   INFO  Train:   89/100 ( 89%) [   0/408 (  0%)]  Loss: 2.079 (2.08)  LR: 2.865e-04  Time cost: 00:03/22:35 [3:43:38/4:31:04]  Acc_iter 35905       Data time: 2.07(2.07)  Forward time: 1.26(1.26)  Batch time: 3.32(3.32)
2025-07-12 15:22:59,010   INFO  Train:   89/100 ( 89%) [  45/408 ( 11%)]  Loss: 1.770 (2.16)  LR: 2.814e-04  Time cost: 00:27/03:37 [3:44:02/48:22]  Acc_iter 35950       Data time: 0.00(0.05)  Forward time: 0.69(0.55)  Batch time: 0.69(0.60)
2025-07-12 15:23:25,410   INFO  Train:   89/100 ( 89%) [  95/408 ( 23%)]  Loss: 2.036 (2.14)  LR: 2.758e-04  Time cost: 00:53/02:55 [3:44:29/44:56]  Acc_iter 36000       Data time: 0.00(0.03)  Forward time: 0.48(0.54)  Batch time: 0.48(0.56)
2025-07-12 15:23:50,646   INFO  Train:   89/100 ( 89%) [ 145/408 ( 36%)]  Loss: 2.134 (2.14)  LR: 2.703e-04  Time cost: 01:19/02:22 [3:44:54/42:55]  Acc_iter 36050       Data time: 0.01(0.02)  Forward time: 0.31(0.52)  Batch time: 0.32(0.54)
2025-07-12 15:24:16,014   INFO  Train:   89/100 ( 89%) [ 195/408 ( 48%)]  Loss: 1.727 (2.16)  LR: 2.648e-04  Time cost: 01:44/01:53 [3:45:19/41:47]  Acc_iter 36100       Data time: 0.00(0.01)  Forward time: 0.41(0.52)  Batch time: 0.41(0.53)
2025-07-12 15:24:41,404   INFO  Train:   89/100 ( 89%) [ 245/408 ( 60%)]  Loss: 1.834 (2.16)  LR: 2.594e-04  Time cost: 02:09/01:26 [3:45:45/40:56]  Acc_iter 36150       Data time: 0.02(0.01)  Forward time: 0.66(0.52)  Batch time: 0.68(0.53)
2025-07-12 15:25:06,984   INFO  Train:   89/100 ( 89%) [ 295/408 ( 72%)]  Loss: 2.069 (2.16)  LR: 2.540e-04  Time cost: 02:35/00:59 [3:46:10/40:17]  Acc_iter 36200       Data time: 0.00(0.01)  Forward time: 0.65(0.51)  Batch time: 0.65(0.53)
2025-07-12 15:25:32,479   INFO  Train:   89/100 ( 89%) [ 345/408 ( 85%)]  Loss: 1.702 (2.16)  LR: 2.487e-04  Time cost: 03:00/00:32 [3:46:36/39:40]  Acc_iter 36250       Data time: 0.00(0.01)  Forward time: 0.71(0.51)  Batch time: 0.71(0.52)
2025-07-12 15:25:57,969   INFO  Train:   89/100 ( 89%) [ 395/408 ( 97%)]  Loss: 1.922 (2.16)  LR: 2.434e-04  Time cost: 03:26/00:06 [3:47:01/39:06]  Acc_iter 36300       Data time: 0.00(0.01)  Forward time: 0.28(0.51)  Batch time: 0.28(0.52)
2025-07-12 15:26:02,252   INFO  Train:   89/100 ( 89%) [ 407/408 (100%)]  Loss: 3.924 (2.16)  LR: 2.421e-04  Time cost: 03:30/00:00 [3:47:05/38:38]  Acc_iter 36312       Data time: 0.00(0.01)  Forward time: 0.17(0.51)  Batch time: 0.17(0.52)
2025-07-12 15:26:06,813   INFO  Train:   90/100 ( 90%) [   0/408 (  0%)]  Loss: 1.716 (1.72)  LR: 2.420e-04  Time cost: 00:03/25:59 [3:47:10/4:45:51]  Acc_iter 36313       Data time: 2.85(2.85)  Forward time: 0.97(0.97)  Batch time: 3.82(3.82)
2025-07-12 15:26:25,528   INFO  Train:   90/100 ( 90%) [  37/408 (  9%)]  Loss: 1.745 (2.06)  LR: 2.382e-04  Time cost: 00:22/03:40 [3:47:29/43:59]  Acc_iter 36350       Data time: 0.00(0.08)  Forward time: 0.49(0.51)  Batch time: 0.49(0.59)
2025-07-12 15:26:51,766   INFO  Train:   90/100 ( 90%) [  87/408 ( 21%)]  Loss: 1.541 (2.07)  LR: 2.330e-04  Time cost: 00:48/02:57 [3:47:55/40:39]  Acc_iter 36400       Data time: 0.00(0.04)  Forward time: 0.81(0.52)  Batch time: 0.82(0.55)
2025-07-12 15:27:17,722   INFO  Train:   90/100 ( 90%) [ 137/408 ( 34%)]  Loss: 1.473 (2.10)  LR: 2.279e-04  Time cost: 01:14/02:26 [3:48:21/39:16]  Acc_iter 36450       Data time: 0.00(0.02)  Forward time: 0.51(0.52)  Batch time: 0.51(0.54)
2025-07-12 15:27:42,503   INFO  Train:   90/100 ( 90%) [ 187/408 ( 46%)]  Loss: 1.604 (2.12)  LR: 2.228e-04  Time cost: 01:39/01:56 [3:48:46/37:56]  Acc_iter 36500       Data time: 0.00(0.02)  Forward time: 0.53(0.51)  Batch time: 0.53(0.53)
2025-07-12 15:28:07,907   INFO  Train:   90/100 ( 90%) [ 237/408 ( 58%)]  Loss: 1.874 (2.13)  LR: 2.178e-04  Time cost: 02:04/01:29 [3:49:11/37:11]  Acc_iter 36550       Data time: 0.00(0.02)  Forward time: 0.44(0.51)  Batch time: 0.44(0.52)
2025-07-12 15:28:33,594   INFO  Train:   90/100 ( 90%) [ 287/408 ( 70%)]  Loss: 2.766 (2.15)  LR: 2.128e-04  Time cost: 02:30/01:03 [3:49:37/36:36]  Acc_iter 36600       Data time: 0.00(0.01)  Forward time: 0.71(0.51)  Batch time: 0.72(0.52)
2025-07-12 15:28:59,223   INFO  Train:   90/100 ( 90%) [ 337/408 ( 83%)]  Loss: 2.920 (2.15)  LR: 2.079e-04  Time cost: 02:56/00:37 [3:50:02/36:04]  Acc_iter 36650       Data time: 0.00(0.01)  Forward time: 0.36(0.51)  Batch time: 0.36(0.52)
2025-07-12 15:29:25,398   INFO  Train:   90/100 ( 90%) [ 387/408 ( 95%)]  Loss: 1.663 (2.14)  LR: 2.030e-04  Time cost: 03:22/00:10 [3:50:29/35:39]  Acc_iter 36700       Data time: 0.00(0.01)  Forward time: 0.54(0.51)  Batch time: 0.54(0.52)
2025-07-12 15:29:34,038   INFO  Train:   90/100 ( 90%) [ 407/408 (100%)]  Loss: 1.892 (2.14)  LR: 2.011e-04  Time cost: 03:31/00:00 [3:50:37/35:10]  Acc_iter 36720       Data time: 0.00(0.01)  Forward time: 0.19(0.51)  Batch time: 0.19(0.52)
2025-07-12 15:29:38,849   INFO  Train:   91/100 ( 91%) [   0/408 (  0%)]  Loss: 2.486 (2.49)  LR: 2.010e-04  Time cost: 00:03/26:33 [3:50:42/4:25:30]  Acc_iter 36721       Data time: 2.92(2.92)  Forward time: 0.98(0.98)  Batch time: 3.90(3.90)
2025-07-12 15:29:53,630   INFO  Train:   91/100 ( 91%) [  29/408 (  7%)]  Loss: 1.645 (2.20)  LR: 1.982e-04  Time cost: 00:18/03:56 [3:50:57/42:03]  Acc_iter 36750       Data time: 0.00(0.10)  Forward time: 0.82(0.52)  Batch time: 0.82(0.62)
2025-07-12 15:30:19,093   INFO  Train:   91/100 ( 91%) [  79/408 ( 19%)]  Loss: 1.911 (2.16)  LR: 1.935e-04  Time cost: 00:44/03:01 [3:51:22/36:47]  Acc_iter 36800       Data time: 0.01(0.04)  Forward time: 0.45(0.51)  Batch time: 0.46(0.55)
2025-07-12 15:30:45,093   INFO  Train:   91/100 ( 91%) [ 129/408 ( 32%)]  Loss: 1.756 (2.13)  LR: 1.888e-04  Time cost: 01:10/02:30 [3:51:48/35:31]  Acc_iter 36850       Data time: 0.00(0.03)  Forward time: 0.37(0.51)  Batch time: 0.38(0.54)
2025-07-12 15:31:11,959   INFO  Train:   91/100 ( 91%) [ 179/408 ( 44%)]  Loss: 3.387 (2.12)  LR: 1.841e-04  Time cost: 01:37/02:03 [3:52:15/35:02]  Acc_iter 36900       Data time: 0.00(0.02)  Forward time: 0.82(0.52)  Batch time: 0.83(0.54)
2025-07-12 15:31:37,775   INFO  Train:   91/100 ( 91%) [ 229/408 ( 56%)]  Loss: 2.227 (2.11)  LR: 1.795e-04  Time cost: 02:02/01:35 [3:52:41/34:16]  Acc_iter 36950       Data time: 0.00(0.02)  Forward time: 0.58(0.52)  Batch time: 0.58(0.53)
2025-07-12 15:32:02,659   INFO  Train:   91/100 ( 91%) [ 279/408 ( 68%)]  Loss: 1.856 (2.11)  LR: 1.750e-04  Time cost: 02:27/01:08 [3:53:06/33:25]  Acc_iter 37000       Data time: 0.03(0.02)  Forward time: 0.42(0.51)  Batch time: 0.45(0.53)
2025-07-12 15:32:28,975   INFO  Train:   91/100 ( 91%) [ 329/408 ( 81%)]  Loss: 1.808 (2.10)  LR: 1.705e-04  Time cost: 02:54/00:41 [3:53:32/32:58]  Acc_iter 37050       Data time: 0.00(0.01)  Forward time: 0.42(0.51)  Batch time: 0.43(0.53)
2025-07-12 15:32:53,784   INFO  Train:   91/100 ( 91%) [ 379/408 ( 93%)]  Loss: 2.184 (2.10)  LR: 1.661e-04  Time cost: 03:18/00:15 [3:53:57/32:16]  Acc_iter 37100       Data time: 0.01(0.01)  Forward time: 0.58(0.51)  Batch time: 0.58(0.52)
2025-07-12 15:33:06,589   INFO  Train:   91/100 ( 91%) [ 407/408 (100%)]  Loss: 1.315 (2.10)  LR: 1.636e-04  Time cost: 03:31/00:00 [3:54:10/31:45]  Acc_iter 37128       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 15:33:11,044   INFO  Train:   92/100 ( 92%) [   0/408 (  0%)]  Loss: 1.995 (1.99)  LR: 1.635e-04  Time cost: 00:03/24:05 [3:54:14/3:36:49]  Acc_iter 37129       Data time: 1.85(1.85)  Forward time: 1.69(1.69)  Batch time: 3.54(3.54)
2025-07-12 15:33:22,261   INFO  Train:   92/100 ( 92%) [  21/408 (  5%)]  Loss: 3.445 (2.10)  LR: 1.617e-04  Time cost: 00:14/04:19 [3:54:25/40:49]  Acc_iter 37150       Data time: 0.00(0.09)  Forward time: 0.47(0.58)  Batch time: 0.48(0.67)
2025-07-12 15:33:47,552   INFO  Train:   92/100 ( 92%) [  71/408 ( 17%)]  Loss: 1.824 (2.07)  LR: 1.574e-04  Time cost: 00:40/03:07 [3:54:51/33:23]  Acc_iter 37200       Data time: 0.00(0.03)  Forward time: 0.60(0.53)  Batch time: 0.60(0.56)
2025-07-12 15:34:13,079   INFO  Train:   92/100 ( 92%) [ 121/408 ( 30%)]  Loss: 1.511 (2.12)  LR: 1.531e-04  Time cost: 01:05/02:34 [3:55:16/31:48]  Acc_iter 37250       Data time: 0.00(0.02)  Forward time: 0.49(0.52)  Batch time: 0.49(0.54)
2025-07-12 15:34:37,949   INFO  Train:   92/100 ( 92%) [ 171/408 ( 42%)]  Loss: 2.182 (2.13)  LR: 1.489e-04  Time cost: 01:30/02:04 [3:55:41/30:41]  Acc_iter 37300       Data time: 0.00(0.01)  Forward time: 0.48(0.51)  Batch time: 0.49(0.53)
2025-07-12 15:35:03,466   INFO  Train:   92/100 ( 92%) [ 221/408 ( 54%)]  Loss: 1.708 (2.11)  LR: 1.447e-04  Time cost: 01:55/01:37 [3:56:07/30:02]  Acc_iter 37350       Data time: 0.00(0.01)  Forward time: 0.66(0.51)  Batch time: 0.66(0.52)
2025-07-12 15:35:29,272   INFO  Train:   92/100 ( 92%) [ 271/408 ( 66%)]  Loss: 2.485 (2.11)  LR: 1.406e-04  Time cost: 02:21/01:11 [3:56:32/29:32]  Acc_iter 37400       Data time: 0.00(0.01)  Forward time: 0.59(0.51)  Batch time: 0.60(0.52)
2025-07-12 15:35:54,915   INFO  Train:   92/100 ( 92%) [ 321/408 ( 79%)]  Loss: 1.863 (2.12)  LR: 1.366e-04  Time cost: 02:47/00:45 [3:56:58/29:02]  Acc_iter 37450       Data time: 0.00(0.01)  Forward time: 1.09(0.51)  Batch time: 1.09(0.52)
2025-07-12 15:36:18,959   INFO  Train:   92/100 ( 92%) [ 371/408 ( 91%)]  Loss: 2.405 (2.10)  LR: 1.326e-04  Time cost: 03:11/00:19 [3:57:22/28:18]  Acc_iter 37500       Data time: 0.00(0.01)  Forward time: 0.28(0.51)  Batch time: 0.28(0.51)
2025-07-12 15:36:34,824   INFO  Train:   92/100 ( 92%) [ 407/408 (100%)]  Loss: 2.042 (2.10)  LR: 1.298e-04  Time cost: 03:27/00:00 [3:57:38/27:39]  Acc_iter 37536       Data time: 0.00(0.01)  Forward time: 0.13(0.50)  Batch time: 0.13(0.51)
2025-07-12 15:36:38,725   INFO  Train:   93/100 ( 93%) [   0/408 (  0%)]  Loss: 1.768 (1.77)  LR: 1.297e-04  Time cost: 00:03/21:19 [3:57:42/2:50:35]  Acc_iter 37537       Data time: 2.46(2.46)  Forward time: 0.68(0.68)  Batch time: 3.14(3.14)
2025-07-12 15:36:46,361   INFO  Train:   93/100 ( 93%) [  13/408 (  3%)]  Loss: 1.493 (2.13)  LR: 1.287e-04  Time cost: 00:10/05:03 [3:57:50/41:41]  Acc_iter 37550       Data time: 0.00(0.18)  Forward time: 0.54(0.59)  Batch time: 0.54(0.77)
2025-07-12 15:37:11,970   INFO  Train:   93/100 ( 93%) [  63/408 ( 15%)]  Loss: 1.624 (2.12)  LR: 1.248e-04  Time cost: 00:36/03:16 [3:58:15/30:19]  Acc_iter 37600       Data time: 0.00(0.04)  Forward time: 0.40(0.53)  Batch time: 0.40(0.57)
2025-07-12 15:37:37,838   INFO  Train:   93/100 ( 93%) [ 113/408 ( 28%)]  Loss: 2.355 (2.13)  LR: 1.210e-04  Time cost: 01:02/02:41 [3:58:41/28:40]  Acc_iter 37650       Data time: 0.00(0.03)  Forward time: 0.36(0.52)  Batch time: 0.36(0.55)
2025-07-12 15:38:03,950   INFO  Train:   93/100 ( 93%) [ 163/408 ( 40%)]  Loss: 2.876 (2.09)  LR: 1.172e-04  Time cost: 01:28/02:12 [3:59:07/27:50]  Acc_iter 37700       Data time: 0.00(0.02)  Forward time: 0.36(0.52)  Batch time: 0.37(0.54)
2025-07-12 15:38:29,749   INFO  Train:   93/100 ( 93%) [ 213/408 ( 52%)]  Loss: 2.222 (2.10)  LR: 1.135e-04  Time cost: 01:54/01:44 [3:59:33/27:07]  Acc_iter 37750       Data time: 0.00(0.02)  Forward time: 0.56(0.52)  Batch time: 0.56(0.53)
2025-07-12 15:38:55,528   INFO  Train:   93/100 ( 93%) [ 263/408 ( 64%)]  Loss: 1.941 (2.11)  LR: 1.099e-04  Time cost: 02:19/01:16 [3:59:59/26:30]  Acc_iter 37800       Data time: 0.00(0.01)  Forward time: 0.71(0.52)  Batch time: 0.71(0.53)
2025-07-12 15:39:20,598   INFO  Train:   93/100 ( 93%) [ 313/408 ( 77%)]  Loss: 1.795 (2.10)  LR: 1.063e-04  Time cost: 02:45/00:49 [4:00:24/25:50]  Acc_iter 37850       Data time: 0.00(0.01)  Forward time: 0.39(0.51)  Batch time: 0.39(0.53)
2025-07-12 15:39:46,392   INFO  Train:   93/100 ( 93%) [ 363/408 ( 89%)]  Loss: 2.203 (2.10)  LR: 1.028e-04  Time cost: 03:10/00:23 [4:00:50/25:20]  Acc_iter 37900       Data time: 0.00(0.01)  Forward time: 0.52(0.51)  Batch time: 0.52(0.52)
2025-07-12 15:40:07,097   INFO  Train:   93/100 ( 93%) [ 407/408 (100%)]  Loss: 1.437 (2.10)  LR: 9.973e-05  Time cost: 03:31/00:00 [4:01:10/24:41]  Acc_iter 37944       Data time: 0.00(0.01)  Forward time: 0.16(0.51)  Batch time: 0.16(0.52)
2025-07-12 15:40:11,948   INFO  Train:   94/100 ( 94%) [   0/408 (  0%)]  Loss: 1.831 (1.83)  LR: 9.966e-05  Time cost: 00:03/26:50 [4:01:15/3:07:56]  Acc_iter 37945       Data time: 3.07(3.07)  Forward time: 0.88(0.88)  Batch time: 3.95(3.95)
2025-07-12 15:40:14,667   INFO  Train:   94/100 ( 94%) [   5/408 (  1%)]  Loss: 2.184 (1.87)  LR: 9.931e-05  Time cost: 00:06/07:27 [4:01:18/52:47]  Acc_iter 37950       Data time: 0.00(0.52)  Forward time: 0.57(0.59)  Batch time: 0.57(1.11)
2025-07-12 15:40:40,962   INFO  Train:   94/100 ( 94%) [  55/408 ( 13%)]  Loss: 2.652 (2.07)  LR: 9.590e-05  Time cost: 00:32/03:27 [4:01:44/27:28]  Acc_iter 38000       Data time: 0.00(0.06)  Forward time: 0.30(0.53)  Batch time: 0.30(0.59)
2025-07-12 15:41:06,380   INFO  Train:   94/100 ( 94%) [ 105/408 ( 26%)]  Loss: 2.151 (2.04)  LR: 9.254e-05  Time cost: 00:58/02:46 [4:02:10/25:15]  Acc_iter 38050       Data time: 0.00(0.03)  Forward time: 0.32(0.52)  Batch time: 0.32(0.55)
2025-07-12 15:41:32,324   INFO  Train:   94/100 ( 94%) [ 155/408 ( 38%)]  Loss: 2.329 (2.04)  LR: 8.924e-05  Time cost: 01:24/02:16 [4:02:35/24:19]  Acc_iter 38100       Data time: 0.00(0.02)  Forward time: 0.74(0.52)  Batch time: 0.74(0.54)
2025-07-12 15:41:58,117   INFO  Train:   94/100 ( 94%) [ 205/408 ( 50%)]  Loss: 2.325 (2.05)  LR: 8.600e-05  Time cost: 01:50/01:48 [4:03:01/23:37]  Acc_iter 38150       Data time: 0.00(0.02)  Forward time: 0.96(0.52)  Batch time: 0.96(0.53)
2025-07-12 15:42:23,249   INFO  Train:   94/100 ( 94%) [ 255/408 ( 62%)]  Loss: 1.460 (2.05)  LR: 8.282e-05  Time cost: 02:15/01:20 [4:03:26/22:54]  Acc_iter 38200       Data time: 0.01(0.02)  Forward time: 0.31(0.51)  Batch time: 0.32(0.53)
2025-07-12 15:42:48,690   INFO  Train:   94/100 ( 94%) [ 305/408 ( 75%)]  Loss: 1.849 (2.05)  LR: 7.970e-05  Time cost: 02:40/00:54 [4:03:52/22:19]  Acc_iter 38250       Data time: 0.00(0.01)  Forward time: 0.73(0.51)  Batch time: 0.74(0.53)
2025-07-12 15:43:14,158   INFO  Train:   94/100 ( 94%) [ 355/408 ( 87%)]  Loss: 2.286 (2.08)  LR: 7.663e-05  Time cost: 03:06/00:27 [4:04:17/21:47]  Acc_iter 38300       Data time: 0.00(0.01)  Forward time: 0.30(0.51)  Batch time: 0.31(0.52)
2025-07-12 15:43:37,353   INFO  Train:   94/100 ( 94%) [ 405/408 ( 99%)]  Loss: 1.876 (2.08)  LR: 7.362e-05  Time cost: 03:29/00:01 [4:04:40/21:03]  Acc_iter 38350       Data time: 0.00(0.01)  Forward time: 0.27(0.50)  Batch time: 0.27(0.52)
2025-07-12 15:43:37,763   INFO  Train:   94/100 ( 94%) [ 407/408 (100%)]  Loss: 2.010 (2.08)  LR: 7.350e-05  Time cost: 03:29/00:00 [4:04:41/20:59]  Acc_iter 38352       Data time: 0.00(0.01)  Forward time: 0.19(0.50)  Batch time: 0.19(0.51)
2025-07-12 15:43:42,781   INFO  Train:   95/100 ( 95%) [   0/408 (  0%)]  Loss: 2.899 (2.90)  LR: 7.344e-05  Time cost: 00:04/28:39 [4:04:46/2:51:58]  Acc_iter 38353       Data time: 3.40(3.40)  Forward time: 0.81(0.81)  Batch time: 4.21(4.21)
2025-07-12 15:44:05,559   INFO  Train:   95/100 ( 95%) [  47/408 ( 12%)]  Loss: 1.843 (2.20)  LR: 7.067e-05  Time cost: 00:26/03:22 [4:05:09/22:30]  Acc_iter 38400       Data time: 0.00(0.08)  Forward time: 0.67(0.49)  Batch time: 0.67(0.56)
2025-07-12 15:44:32,356   INFO  Train:   95/100 ( 95%) [  97/408 ( 24%)]  Loss: 1.817 (2.10)  LR: 6.779e-05  Time cost: 00:53/02:50 [4:05:35/21:30]  Acc_iter 38450       Data time: 0.00(0.04)  Forward time: 0.65(0.51)  Batch time: 0.65(0.55)
2025-07-12 15:44:58,561   INFO  Train:   95/100 ( 95%) [ 147/408 ( 36%)]  Loss: 2.239 (2.10)  LR: 6.495e-05  Time cost: 01:19/02:21 [4:06:02/20:43]  Acc_iter 38500       Data time: 0.00(0.03)  Forward time: 0.74(0.51)  Batch time: 0.75(0.54)
2025-07-12 15:45:24,341   INFO  Train:   95/100 ( 95%) [ 197/408 ( 48%)]  Loss: 2.134 (2.08)  LR: 6.218e-05  Time cost: 01:45/01:52 [4:06:27/20:02]  Acc_iter 38550       Data time: 0.00(0.02)  Forward time: 0.48(0.51)  Batch time: 0.48(0.53)
2025-07-12 15:45:49,924   INFO  Train:   95/100 ( 95%) [ 247/408 ( 61%)]  Loss: 1.817 (2.06)  LR: 5.947e-05  Time cost: 02:11/01:25 [4:06:53/19:25]  Acc_iter 38600       Data time: 0.00(0.02)  Forward time: 0.77(0.51)  Batch time: 0.77(0.53)
2025-07-12 15:46:15,517   INFO  Train:   95/100 ( 95%) [ 297/408 ( 73%)]  Loss: 1.539 (2.06)  LR: 5.682e-05  Time cost: 02:36/00:58 [4:07:19/18:52]  Acc_iter 38650       Data time: 0.00(0.02)  Forward time: 0.60(0.51)  Batch time: 0.60(0.53)
2025-07-12 15:46:41,757   INFO  Train:   95/100 ( 95%) [ 347/408 ( 85%)]  Loss: 1.647 (2.06)  LR: 5.422e-05  Time cost: 03:03/00:32 [4:07:45/18:25]  Acc_iter 38700       Data time: 0.00(0.01)  Forward time: 0.50(0.51)  Batch time: 0.50(0.53)
2025-07-12 15:47:07,157   INFO  Train:   95/100 ( 95%) [ 397/408 ( 97%)]  Loss: 1.938 (2.06)  LR: 5.169e-05  Time cost: 03:28/00:05 [4:08:10/17:54]  Acc_iter 38750       Data time: 0.00(0.01)  Forward time: 0.65(0.51)  Batch time: 0.66(0.52)
2025-07-12 15:47:10,260   INFO  Train:   95/100 ( 95%) [ 407/408 (100%)]  Loss: 2.061 (2.06)  LR: 5.119e-05  Time cost: 03:31/00:00 [4:08:13/17:38]  Acc_iter 38760       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 15:47:14,359   INFO  Train:   96/100 ( 96%) [   0/408 (  0%)]  Loss: 2.764 (2.76)  LR: 5.114e-05  Time cost: 00:03/21:41 [4:08:18/1:48:26]  Acc_iter 38761       Data time: 1.86(1.86)  Forward time: 1.33(1.33)  Batch time: 3.19(3.19)
2025-07-12 15:47:35,757   INFO  Train:   96/100 ( 96%) [  39/408 ( 10%)]  Loss: 2.182 (2.10)  LR: 4.922e-05  Time cost: 00:24/03:46 [4:08:39/20:29]  Acc_iter 38800       Data time: 0.00(0.05)  Forward time: 0.36(0.56)  Batch time: 0.36(0.61)
2025-07-12 15:48:01,737   INFO  Train:   96/100 ( 96%) [  89/408 ( 22%)]  Loss: 2.246 (2.08)  LR: 4.680e-05  Time cost: 00:50/02:59 [4:09:05/18:16]  Acc_iter 38850       Data time: 0.00(0.03)  Forward time: 0.73(0.54)  Batch time: 0.73(0.56)
2025-07-12 15:48:27,460   INFO  Train:   96/100 ( 96%) [ 139/408 ( 34%)]  Loss: 3.386 (2.08)  LR: 4.445e-05  Time cost: 01:16/02:26 [4:09:31/17:15]  Acc_iter 38900       Data time: 0.00(0.02)  Forward time: 0.59(0.53)  Batch time: 0.59(0.54)
2025-07-12 15:48:52,780   INFO  Train:   96/100 ( 96%) [ 189/408 ( 46%)]  Loss: 2.105 (2.05)  LR: 4.215e-05  Time cost: 01:41/01:57 [4:09:56/16:29]  Acc_iter 38950       Data time: 0.00(0.01)  Forward time: 0.91(0.52)  Batch time: 0.91(0.53)
2025-07-12 15:49:18,595   INFO  Train:   96/100 ( 96%) [ 239/408 ( 59%)]  Loss: 2.178 (2.04)  LR: 3.992e-05  Time cost: 02:07/01:29 [4:10:22/15:56]  Acc_iter 39000       Data time: 0.00(0.01)  Forward time: 0.64(0.52)  Batch time: 0.64(0.53)
2025-07-12 15:49:44,150   INFO  Train:   96/100 ( 96%) [ 289/408 ( 71%)]  Loss: 2.830 (2.04)  LR: 3.774e-05  Time cost: 02:32/01:02 [4:10:47/15:23]  Acc_iter 39050       Data time: 0.00(0.01)  Forward time: 0.46(0.52)  Batch time: 0.46(0.53)
2025-07-12 15:50:08,993   INFO  Train:   96/100 ( 96%) [ 339/408 ( 83%)]  Loss: 2.916 (2.05)  LR: 3.563e-05  Time cost: 02:57/00:36 [4:11:12/14:49]  Acc_iter 39100       Data time: 0.00(0.01)  Forward time: 0.54(0.51)  Batch time: 0.54(0.52)
2025-07-12 15:50:33,857   INFO  Train:   96/100 ( 96%) [ 389/408 ( 95%)]  Loss: 2.704 (2.06)  LR: 3.357e-05  Time cost: 03:22/00:09 [4:11:37/14:18]  Acc_iter 39150       Data time: 0.00(0.01)  Forward time: 0.36(0.51)  Batch time: 0.36(0.52)
2025-07-12 15:50:41,162   INFO  Train:   96/100 ( 96%) [ 407/408 (100%)]  Loss: 2.107 (2.06)  LR: 3.285e-05  Time cost: 03:29/00:00 [4:11:44/14:00]  Acc_iter 39168       Data time: 0.05(0.01)  Forward time: 0.17(0.51)  Batch time: 0.22(0.51)
2025-07-12 15:50:45,741   INFO  Train:   97/100 ( 97%) [   0/408 (  0%)]  Loss: 2.697 (2.70)  LR: 3.281e-05  Time cost: 00:03/25:58 [4:11:49/1:43:55]  Acc_iter 39169       Data time: 2.99(2.99)  Forward time: 0.83(0.83)  Batch time: 3.82(3.82)
2025-07-12 15:51:01,102   INFO  Train:   97/100 ( 97%) [  31/408 (  8%)]  Loss: 1.504 (2.22)  LR: 3.158e-05  Time cost: 00:19/03:45 [4:12:04/15:59]  Acc_iter 39200       Data time: 0.00(0.10)  Forward time: 0.57(0.50)  Batch time: 0.57(0.60)
2025-07-12 15:51:26,170   INFO  Train:   97/100 ( 97%) [  81/408 ( 20%)]  Loss: 2.051 (2.09)  LR: 2.965e-05  Time cost: 00:44/02:56 [4:12:29/13:56]  Acc_iter 39250       Data time: 0.00(0.04)  Forward time: 0.57(0.50)  Batch time: 0.57(0.54)
2025-07-12 15:51:50,866   INFO  Train:   97/100 ( 97%) [ 131/408 ( 32%)]  Loss: 2.945 (2.09)  LR: 2.777e-05  Time cost: 01:08/02:24 [4:12:54/13:03]  Acc_iter 39300       Data time: 0.00(0.03)  Forward time: 0.32(0.50)  Batch time: 0.32(0.52)
2025-07-12 15:52:15,721   INFO  Train:   97/100 ( 97%) [ 181/408 ( 44%)]  Loss: 3.370 (2.09)  LR: 2.596e-05  Time cost: 01:33/01:56 [4:13:19/12:27]  Acc_iter 39350       Data time: 0.00(0.02)  Forward time: 0.48(0.50)  Batch time: 0.48(0.52)
2025-07-12 15:52:40,450   INFO  Train:   97/100 ( 97%) [ 231/408 ( 57%)]  Loss: 1.459 (2.08)  LR: 2.421e-05  Time cost: 01:58/01:30 [4:13:44/11:55]  Acc_iter 39400       Data time: 0.00(0.02)  Forward time: 0.73(0.49)  Batch time: 0.73(0.51)
2025-07-12 15:53:05,139   INFO  Train:   97/100 ( 97%) [ 281/408 ( 69%)]  Loss: 1.789 (2.08)  LR: 2.252e-05  Time cost: 02:23/01:04 [4:14:08/11:26]  Acc_iter 39450       Data time: 0.00(0.01)  Forward time: 0.43(0.49)  Batch time: 0.44(0.51)
2025-07-12 15:53:30,527   INFO  Train:   97/100 ( 97%) [ 331/408 ( 81%)]  Loss: 1.928 (2.07)  LR: 2.089e-05  Time cost: 02:48/00:39 [4:14:34/11:00]  Acc_iter 39500       Data time: 0.00(0.01)  Forward time: 0.80(0.49)  Batch time: 0.81(0.51)
2025-07-12 15:53:57,476   INFO  Train:   97/100 ( 97%) [ 381/408 ( 93%)]  Loss: 1.833 (2.06)  LR: 1.932e-05  Time cost: 03:15/00:13 [4:15:01/10:40]  Acc_iter 39550       Data time: 0.00(0.01)  Forward time: 0.45(0.50)  Batch time: 0.45(0.51)
2025-07-12 15:54:08,430   INFO  Train:   97/100 ( 97%) [ 407/408 (100%)]  Loss: 2.726 (2.06)  LR: 1.853e-05  Time cost: 03:26/00:00 [4:15:12/10:20]  Acc_iter 39576       Data time: 0.00(0.01)  Forward time: 0.18(0.50)  Batch time: 0.19(0.51)
2025-07-12 15:54:12,888   INFO  Train:   98/100 ( 98%) [   0/408 (  0%)]  Loss: 1.672 (1.67)  LR: 1.850e-05  Time cost: 00:03/24:18 [4:15:16/1:12:54]  Acc_iter 39577       Data time: 2.55(2.55)  Forward time: 1.02(1.02)  Batch time: 3.57(3.57)
2025-07-12 15:54:25,029   INFO  Train:   98/100 ( 98%) [  23/408 (  6%)]  Loss: 1.820 (1.95)  LR: 1.781e-05  Time cost: 00:15/04:12 [4:15:28/13:06]  Acc_iter 39600       Data time: 0.00(0.11)  Forward time: 0.35(0.54)  Batch time: 0.35(0.65)
2025-07-12 15:54:51,362   INFO  Train:   98/100 ( 98%) [  73/408 ( 18%)]  Loss: 1.985 (2.04)  LR: 1.636e-05  Time cost: 00:42/03:10 [4:15:55/10:54]  Acc_iter 39650       Data time: 0.00(0.04)  Forward time: 0.49(0.53)  Batch time: 0.50(0.57)
2025-07-12 15:55:17,560   INFO  Train:   98/100 ( 98%) [ 123/408 ( 30%)]  Loss: 2.035 (2.02)  LR: 1.498e-05  Time cost: 01:08/02:36 [4:16:21/10:05]  Acc_iter 39700       Data time: 0.00(0.02)  Forward time: 0.56(0.53)  Batch time: 0.57(0.55)
2025-07-12 15:55:43,349   INFO  Train:   98/100 ( 98%) [ 173/408 ( 42%)]  Loss: 2.062 (2.03)  LR: 1.365e-05  Time cost: 01:34/02:07 [4:16:46/09:27]  Acc_iter 39750       Data time: 0.00(0.02)  Forward time: 0.65(0.52)  Batch time: 0.65(0.54)
2025-07-12 15:56:08,892   INFO  Train:   98/100 ( 98%) [ 223/408 ( 55%)]  Loss: 2.101 (2.06)  LR: 1.239e-05  Time cost: 01:59/01:38 [4:17:12/08:54]  Acc_iter 39800       Data time: 0.00(0.02)  Forward time: 0.42(0.52)  Batch time: 0.42(0.53)
2025-07-12 15:56:34,325   INFO  Train:   98/100 ( 98%) [ 273/408 ( 67%)]  Loss: 3.429 (2.08)  LR: 1.119e-05  Time cost: 02:25/01:11 [4:17:37/08:23]  Acc_iter 39850       Data time: 0.00(0.01)  Forward time: 0.38(0.52)  Batch time: 0.38(0.53)
2025-07-12 15:57:00,002   INFO  Train:   98/100 ( 98%) [ 323/408 ( 79%)]  Loss: 1.763 (2.08)  LR: 1.005e-05  Time cost: 02:50/00:44 [4:18:03/07:54]  Acc_iter 39900       Data time: 0.00(0.01)  Forward time: 0.68(0.52)  Batch time: 0.68(0.53)
2025-07-12 15:57:24,758   INFO  Train:   98/100 ( 98%) [ 373/408 ( 91%)]  Loss: 2.684 (2.08)  LR: 8.966e-06  Time cost: 03:15/00:18 [4:18:28/07:24]  Acc_iter 39950       Data time: 0.00(0.01)  Forward time: 0.36(0.51)  Batch time: 0.36(0.52)
2025-07-12 15:57:40,379   INFO  Train:   98/100 ( 98%) [ 407/408 (100%)]  Loss: 2.947 (2.09)  LR: 8.267e-06  Time cost: 03:31/00:00 [4:18:44/07:02]  Acc_iter 39984       Data time: 0.00(0.01)  Forward time: 0.13(0.51)  Batch time: 0.13(0.52)
2025-07-12 15:57:45,189   INFO  Train:   99/100 ( 99%) [   0/408 (  0%)]  Loss: 2.355 (2.35)  LR: 8.247e-06  Time cost: 00:03/26:38 [4:18:48/53:17]  Acc_iter 39985       Data time: 3.14(3.14)  Forward time: 0.78(0.78)  Batch time: 3.92(3.92)
2025-07-12 15:57:52,968   INFO  Train:   99/100 ( 99%) [  15/408 (  4%)]  Loss: 1.848 (1.80)  LR: 7.948e-06  Time cost: 00:11/04:47 [4:18:56/09:45]  Acc_iter 40000       Data time: 0.00(0.20)  Forward time: 0.55(0.53)  Batch time: 0.55(0.73)
2025-07-12 15:58:19,536   INFO  Train:   99/100 ( 99%) [  65/408 ( 16%)]  Loss: 1.996 (2.05)  LR: 6.991e-06  Time cost: 00:38/03:18 [4:19:23/07:15]  Acc_iter 40050       Data time: 0.00(0.05)  Forward time: 0.46(0.53)  Batch time: 0.46(0.58)
2025-07-12 15:58:45,042   INFO  Train:   99/100 ( 99%) [ 115/408 ( 28%)]  Loss: 1.511 (2.03)  LR: 6.096e-06  Time cost: 01:03/02:41 [4:19:48/06:25]  Acc_iter 40100       Data time: 0.00(0.03)  Forward time: 0.53(0.52)  Batch time: 0.53(0.55)
2025-07-12 15:59:12,096   INFO  Train:   99/100 ( 99%) [ 165/408 ( 40%)]  Loss: 1.927 (2.03)  LR: 5.262e-06  Time cost: 01:30/02:12 [4:20:15/05:56]  Acc_iter 40150       Data time: 0.00(0.02)  Forward time: 0.59(0.52)  Batch time: 0.60(0.55)
2025-07-12 15:59:37,797   INFO  Train:   99/100 ( 99%) [ 215/408 ( 53%)]  Loss: 2.126 (2.04)  LR: 4.489e-06  Time cost: 01:56/01:44 [4:20:41/05:24]  Acc_iter 40200       Data time: 0.00(0.02)  Forward time: 0.59(0.52)  Batch time: 0.60(0.54)
2025-07-12 16:00:03,382   INFO  Train:   99/100 ( 99%) [ 265/408 ( 65%)]  Loss: 2.018 (2.05)  LR: 3.778e-06  Time cost: 02:22/01:16 [4:21:07/04:54]  Acc_iter 40250       Data time: 0.00(0.02)  Forward time: 0.31(0.52)  Batch time: 0.31(0.53)
2025-07-12 16:00:28,577   INFO  Train:   99/100 ( 99%) [ 315/408 ( 77%)]  Loss: 3.943 (2.05)  LR: 3.129e-06  Time cost: 02:47/00:49 [4:21:32/04:25]  Acc_iter 40300       Data time: 0.00(0.01)  Forward time: 0.46(0.52)  Batch time: 0.46(0.53)
2025-07-12 16:00:54,159   INFO  Train:   99/100 ( 99%) [ 365/408 ( 89%)]  Loss: 2.012 (2.05)  LR: 2.542e-06  Time cost: 03:12/00:22 [4:21:57/03:57]  Acc_iter 40350       Data time: 0.00(0.01)  Forward time: 0.41(0.51)  Batch time: 0.42(0.53)
2025-07-12 16:01:13,743   INFO  Train:   99/100 ( 99%) [ 407/408 (100%)]  Loss: 1.153 (2.05)  LR: 2.096e-06  Time cost: 03:32/00:00 [4:22:17/03:32]  Acc_iter 40392       Data time: 0.00(0.01)  Forward time: 0.15(0.51)  Batch time: 0.15(0.52)
2025-07-12 16:01:18,577   INFO  Train:  100/100 (100%) [   0/408 (  0%)]  Loss: 2.454 (2.45)  LR: 2.086e-06  Time cost: 00:03/26:54 [4:22:22/26:54]  Acc_iter 40393       Data time: 2.96(2.96)  Forward time: 0.99(0.99)  Batch time: 3.96(3.96)
2025-07-12 16:01:22,344   INFO  Train:  100/100 (100%) [   7/408 (  2%)]  Loss: 1.524 (2.07)  LR: 2.016e-06  Time cost: 00:07/06:27 [4:22:25/06:27]  Acc_iter 40400       Data time: 0.00(0.37)  Forward time: 0.47(0.59)  Batch time: 0.47(0.97)
2025-07-12 16:01:47,376   INFO  Train:  100/100 (100%) [  57/408 ( 14%)]  Loss: 1.883 (2.01)  LR: 1.552e-06  Time cost: 00:32/03:18 [4:22:51/03:18]  Acc_iter 40450       Data time: 0.00(0.06)  Forward time: 0.27(0.51)  Batch time: 0.28(0.56)
2025-07-12 16:02:12,471   INFO  Train:  100/100 (100%) [ 107/408 ( 26%)]  Loss: 1.387 (2.10)  LR: 1.149e-06  Time cost: 00:57/02:41 [4:23:16/02:41]  Acc_iter 40500       Data time: 0.00(0.03)  Forward time: 0.30(0.50)  Batch time: 0.31(0.54)
2025-07-12 16:02:38,055   INFO  Train:  100/100 (100%) [ 157/408 ( 38%)]  Loss: 2.433 (2.06)  LR: 8.081e-07  Time cost: 01:23/02:12 [4:23:41/02:12]  Acc_iter 40550       Data time: 0.00(0.02)  Forward time: 0.57(0.50)  Batch time: 0.57(0.53)
2025-07-12 16:03:02,857   INFO  Train:  100/100 (100%) [ 207/408 ( 51%)]  Loss: 2.905 (2.03)  LR: 5.290e-07  Time cost: 01:48/01:44 [4:24:06/01:44]  Acc_iter 40600       Data time: 0.00(0.02)  Forward time: 0.35(0.50)  Batch time: 0.36(0.52)
2025-07-12 16:03:28,528   INFO  Train:  100/100 (100%) [ 257/408 ( 63%)]  Loss: 1.880 (2.05)  LR: 3.116e-07  Time cost: 02:13/01:18 [4:24:32/01:18]  Acc_iter 40650       Data time: 0.00(0.02)  Forward time: 0.42(0.50)  Batch time: 0.43(0.52)
2025-07-12 16:03:54,044   INFO  Train:  100/100 (100%) [ 307/408 ( 75%)]  Loss: 1.673 (2.05)  LR: 1.560e-07  Time cost: 02:39/00:52 [4:24:57/00:52]  Acc_iter 40700       Data time: 0.00(0.01)  Forward time: 0.49(0.50)  Batch time: 0.50(0.52)
2025-07-12 16:04:19,329   INFO  Train:  100/100 (100%) [ 357/408 ( 88%)]  Loss: 2.191 (2.04)  LR: 6.213e-08  Time cost: 03:04/00:26 [4:25:22/00:26]  Acc_iter 40750       Data time: 0.01(0.01)  Forward time: 0.39(0.50)  Batch time: 0.40(0.52)
2025-07-12 16:04:44,032   INFO  Train:  100/100 (100%) [ 407/408 (100%)]  Loss: 1.579 (2.05)  LR: 3.001e-08  Time cost: 03:29/00:00 [4:25:47/00:00]  Acc_iter 40800       Data time: 0.00(0.01)  Forward time: 0.18(0.50)  Batch time: 0.19(0.51)
2025-07-12 16:04:44,602   INFO  **********************End training cfgs/nuscenes_models/cbgs_voxel0075_voxelnext(default)**********************



2025-07-12 16:04:44,602   INFO  **********************Start evaluation cfgs/nuscenes_models/cbgs_voxel0075_voxelnext(default)**********************
2025-07-12 16:04:44,603   INFO  Loading NuScenes dataset
2025-07-12 16:04:44,611   INFO  Total samples for NuScenes dataset: 81
2025-07-12 16:04:44,614   INFO  ==> Loading parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_95.pth to GPU
2025-07-12 16:04:44,701   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+8caccce
2025-07-12 16:04:44,745   INFO  ==> Done (loaded 542/542)
2025-07-12 16:04:44,752   INFO  *************** EPOCH 95 EVALUATION *****************
2025-07-12 16:04:55,120   INFO  *************** Performance of EPOCH 95 *****************
2025-07-12 16:04:55,120   INFO  Generate label finished(sec_per_example: 0.1280 second).
2025-07-12 16:04:55,120   INFO  recall_roi_0.3: 0.000000
2025-07-12 16:04:55,120   INFO  recall_rcnn_0.3: 0.671329
2025-07-12 16:04:55,120   INFO  recall_roi_0.5: 0.000000
2025-07-12 16:04:55,120   INFO  recall_rcnn_0.5: 0.441904
2025-07-12 16:04:55,120   INFO  recall_roi_0.7: 0.000000
2025-07-12 16:04:55,120   INFO  recall_rcnn_0.7: 0.146046
2025-07-12 16:04:55,120   INFO  Average predicted number of objects(81 samples): 111.432
2025-07-12 16:04:58,027   INFO  The predictions of NuScenes have been saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_95/val/final_result/data/results_nusc.json
2025-07-12 16:05:00,941   INFO  ----------------Nuscene detection_cvpr_2019 results-----------------
***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.18, 0.50, 0.15, 0.10 | 51.33, 68.52, 77.24, 79.46 | mean AP: 0.6913708082841508
***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.17, 0.23, 0.11, 0.05 | 30.94, 32.80, 32.80, 33.06 | mean AP: 0.32400114401240726
***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.10, 0.28, 0.23, 2.56, 0.24 | 0.00, 2.66, 57.81, 62.40 | mean AP: 0.30718333088614247
***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.37, 1.23, 0.06, 0.00 | 12.05, 12.48, 12.54, 13.35 | mean AP: 0.12602864400629146
***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.18, 0.37, 1.41, 0.32, 0.30 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.30, 0.39, 0.26, 0.09 | 80.15, 82.01, 83.78, 87.52 | mean AP: 0.8336433938828334
***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.44, nan, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
--------------average performance-------------
trans_err:	 0.5167
scale_err:	 0.5102
orient_err:	 0.7766
vel_err:	 0.6821
attr_err:	 0.3470
mAP:	 0.2282
NDS:	 0.3309

2025-07-12 16:05:00,941   INFO  Result is saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_95/val
2025-07-12 16:05:00,941   INFO  ****************Evaluation done.*****************
2025-07-12 16:05:00,947   INFO  Epoch 95 has been evaluated
2025-07-12 16:05:00,948   INFO  ==> Loading parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_96.pth to GPU
2025-07-12 16:05:01,032   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+8caccce
2025-07-12 16:05:01,070   INFO  ==> Done (loaded 542/542)
2025-07-12 16:05:01,076   INFO  *************** EPOCH 96 EVALUATION *****************
2025-07-12 16:05:11,301   INFO  *************** Performance of EPOCH 96 *****************
2025-07-12 16:05:11,301   INFO  Generate label finished(sec_per_example: 0.1262 second).
2025-07-12 16:05:11,301   INFO  recall_roi_0.3: 0.000000
2025-07-12 16:05:11,301   INFO  recall_rcnn_0.3: 0.670791
2025-07-12 16:05:11,301   INFO  recall_roi_0.5: 0.000000
2025-07-12 16:05:11,301   INFO  recall_rcnn_0.5: 0.439753
2025-07-12 16:05:11,301   INFO  recall_roi_0.7: 0.000000
2025-07-12 16:05:11,301   INFO  recall_rcnn_0.7: 0.143895
2025-07-12 16:05:11,302   INFO  Average predicted number of objects(81 samples): 111.099
2025-07-12 16:05:13,337   INFO  The predictions of NuScenes have been saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_96/val/final_result/data/results_nusc.json
2025-07-12 16:05:16,211   INFO  ----------------Nuscene detection_cvpr_2019 results-----------------
***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.18, 0.51, 0.15, 0.10 | 51.27, 68.55, 78.07, 79.56 | mean AP: 0.6936274401878284
***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.16, 0.24, 0.11, 0.04 | 32.16, 34.62, 34.72, 34.85 | mean AP: 0.34087377755051806
***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.05, 0.28, 0.24, 2.59, 0.24 | 0.00, 4.63, 56.82, 61.43 | mean AP: 0.30720645038705297
***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.37, 1.24, 0.06, 0.00 | 11.83, 12.20, 12.31, 12.96 | mean AP: 0.12326255680351812
***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.13, 0.36, 1.62, 0.23, 0.17 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.30, 0.38, 0.27, 0.09 | 80.03, 81.89, 83.57, 86.91 | mean AP: 0.8310177497611709
***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.44, nan, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
--------------average performance-------------
trans_err:	 0.5082
scale_err:	 0.5082
orient_err:	 0.8023
vel_err:	 0.6757
attr_err:	 0.3312
mAP:	 0.2296
NDS:	 0.3322

2025-07-12 16:05:16,212   INFO  Result is saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_96/val
2025-07-12 16:05:16,212   INFO  ****************Evaluation done.*****************
2025-07-12 16:05:16,216   INFO  Epoch 96 has been evaluated
2025-07-12 16:05:16,217   INFO  ==> Loading parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_97.pth to GPU
2025-07-12 16:05:16,296   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+8caccce
2025-07-12 16:05:16,333   INFO  ==> Done (loaded 542/542)
2025-07-12 16:05:16,340   INFO  *************** EPOCH 97 EVALUATION *****************
2025-07-12 16:05:26,941   INFO  *************** Performance of EPOCH 97 *****************
2025-07-12 16:05:26,941   INFO  Generate label finished(sec_per_example: 0.1309 second).
2025-07-12 16:05:26,941   INFO  recall_roi_0.3: 0.000000
2025-07-12 16:05:26,941   INFO  recall_rcnn_0.3: 0.672673
2025-07-12 16:05:26,941   INFO  recall_roi_0.5: 0.000000
2025-07-12 16:05:26,941   INFO  recall_rcnn_0.5: 0.441635
2025-07-12 16:05:26,942   INFO  recall_roi_0.7: 0.000000
2025-07-12 16:05:26,942   INFO  recall_rcnn_0.7: 0.144432
2025-07-12 16:05:26,942   INFO  Average predicted number of objects(81 samples): 110.988
2025-07-12 16:05:29,194   INFO  The predictions of NuScenes have been saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_97/val/final_result/data/results_nusc.json
2025-07-12 16:05:31,928   INFO  ----------------Nuscene detection_cvpr_2019 results-----------------
***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.18, 0.51, 0.15, 0.10 | 51.43, 68.56, 78.08, 79.55 | mean AP: 0.6940665951704673
***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.16, 0.22, 0.11, 0.05 | 32.09, 34.40, 34.40, 34.48 | mean AP: 0.3384269330579867
***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.11, 0.29, 0.23, 2.55, 0.24 | 0.00, 3.32, 59.36, 64.19 | mean AP: 0.3171843080004577
***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.37, 1.25, 0.06, 0.00 | 11.96, 12.07, 12.39, 13.05 | mean AP: 0.12367617136197115
***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.36, 1.57, 0.33, 0.28 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.30, 0.38, 0.26, 0.09 | 80.00, 81.88, 83.54, 86.88 | mean AP: 0.8307647143088838
***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.15, 0.44, nan, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
--------------average performance-------------
trans_err:	 0.5169
scale_err:	 0.5084
orient_err:	 0.7946
vel_err:	 0.6824
attr_err:	 0.3449
mAP:	 0.2304
NDS:	 0.3305

2025-07-12 16:05:31,928   INFO  Result is saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_97/val
2025-07-12 16:05:31,929   INFO  ****************Evaluation done.*****************
2025-07-12 16:05:31,933   INFO  Epoch 97 has been evaluated
2025-07-12 16:05:31,933   INFO  ==> Loading parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_98.pth to GPU
2025-07-12 16:05:32,005   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+8caccce
2025-07-12 16:05:32,041   INFO  ==> Done (loaded 542/542)
2025-07-12 16:05:32,047   INFO  *************** EPOCH 98 EVALUATION *****************
2025-07-12 16:05:42,865   INFO  *************** Performance of EPOCH 98 *****************
2025-07-12 16:05:42,865   INFO  Generate label finished(sec_per_example: 0.1335 second).
2025-07-12 16:05:42,865   INFO  recall_roi_0.3: 0.000000
2025-07-12 16:05:42,865   INFO  recall_rcnn_0.3: 0.671329
2025-07-12 16:05:42,865   INFO  recall_roi_0.5: 0.000000
2025-07-12 16:05:42,865   INFO  recall_rcnn_0.5: 0.441904
2025-07-12 16:05:42,865   INFO  recall_roi_0.7: 0.000000
2025-07-12 16:05:42,865   INFO  recall_rcnn_0.7: 0.143626
2025-07-12 16:05:42,865   INFO  Average predicted number of objects(81 samples): 111.654
2025-07-12 16:05:45,279   INFO  The predictions of NuScenes have been saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_98/val/final_result/data/results_nusc.json
2025-07-12 16:05:48,033   INFO  ----------------Nuscene detection_cvpr_2019 results-----------------
***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.18, 0.50, 0.15, 0.10 | 51.44, 68.54, 78.09, 80.35 | mean AP: 0.6960401084798259
***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.16, 0.23, 0.11, 0.05 | 32.23, 34.41, 34.41, 34.58 | mean AP: 0.33907858738757
***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.10, 0.29, 0.24, 2.62, 0.24 | 0.00, 3.27, 58.04, 62.64 | mean AP: 0.3098579205568266
***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.36, 1.24, 0.06, 0.00 | 12.14, 12.31, 12.60, 13.29 | mean AP: 0.12585984981188808
***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.36, 1.49, 0.33, 0.28 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.30, 0.38, 0.26, 0.09 | 80.03, 81.91, 83.63, 86.92 | mean AP: 0.8311972182752582
***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.15, 0.44, nan, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
--------------average performance-------------
trans_err:	 0.5156
scale_err:	 0.5084
orient_err:	 0.7859
vel_err:	 0.6920
attr_err:	 0.3444
mAP:	 0.2302
NDS:	 0.3305

2025-07-12 16:05:48,034   INFO  Result is saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_98/val
2025-07-12 16:05:48,034   INFO  ****************Evaluation done.*****************
2025-07-12 16:05:48,038   INFO  Epoch 98 has been evaluated
2025-07-12 16:05:48,039   INFO  ==> Loading parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_99.pth to GPU
2025-07-12 16:05:48,112   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+8caccce
2025-07-12 16:05:48,152   INFO  ==> Done (loaded 542/542)
2025-07-12 16:05:48,159   INFO  *************** EPOCH 99 EVALUATION *****************
2025-07-12 16:05:59,258   INFO  *************** Performance of EPOCH 99 *****************
2025-07-12 16:05:59,259   INFO  Generate label finished(sec_per_example: 0.1370 second).
2025-07-12 16:05:59,259   INFO  recall_roi_0.3: 0.000000
2025-07-12 16:05:59,259   INFO  recall_rcnn_0.3: 0.671060
2025-07-12 16:05:59,259   INFO  recall_roi_0.5: 0.000000
2025-07-12 16:05:59,259   INFO  recall_rcnn_0.5: 0.443787
2025-07-12 16:05:59,259   INFO  recall_roi_0.7: 0.000000
2025-07-12 16:05:59,259   INFO  recall_rcnn_0.7: 0.146853
2025-07-12 16:05:59,260   INFO  Average predicted number of objects(81 samples): 109.321
2025-07-12 16:06:01,798   INFO  The predictions of NuScenes have been saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_99/val/final_result/data/results_nusc.json
2025-07-12 16:06:04,510   INFO  ----------------Nuscene detection_cvpr_2019 results-----------------
***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.18, 0.50, 0.15, 0.10 | 51.43, 68.50, 77.32, 79.56 | mean AP: 0.6920270413258539
***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.16, 0.23, 0.11, 0.05 | 31.62, 33.89, 33.89, 33.98 | mean AP: 0.3334556318903165
***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.10, 0.29, 0.24, 2.62, 0.24 | 0.00, 3.19, 57.48, 62.01 | mean AP: 0.30669249263183684
***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.36, 1.24, 0.06, 0.00 | 12.08, 12.22, 12.50, 13.13 | mean AP: 0.12481366632499287
***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.36, 1.48, 0.32, 0.27 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.30, 0.38, 0.26, 0.09 | 80.04, 81.92, 83.59, 86.92 | mean AP: 0.8311879155692045
***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.15, 0.44, nan, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
--------------average performance-------------
trans_err:	 0.5151
scale_err:	 0.5085
orient_err:	 0.7844
vel_err:	 0.6894
attr_err:	 0.3434
mAP:	 0.2288
NDS:	 0.3303

2025-07-12 16:06:04,511   INFO  Result is saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_99/val
2025-07-12 16:06:04,511   INFO  ****************Evaluation done.*****************
2025-07-12 16:06:04,514   INFO  Epoch 99 has been evaluated
2025-07-12 16:06:04,515   INFO  ==> Loading parameters from checkpoint /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/ckpt/checkpoint_epoch_100.pth to GPU
2025-07-12 16:06:04,597   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+8caccce
2025-07-12 16:06:04,634   INFO  ==> Done (loaded 542/542)
2025-07-12 16:06:04,641   INFO  *************** EPOCH 100 EVALUATION *****************
2025-07-12 16:06:15,075   INFO  *************** Performance of EPOCH 100 *****************
2025-07-12 16:06:15,075   INFO  Generate label finished(sec_per_example: 0.1288 second).
2025-07-12 16:06:15,075   INFO  recall_roi_0.3: 0.000000
2025-07-12 16:06:15,075   INFO  recall_rcnn_0.3: 0.670791
2025-07-12 16:06:15,075   INFO  recall_roi_0.5: 0.000000
2025-07-12 16:06:15,075   INFO  recall_rcnn_0.5: 0.438677
2025-07-12 16:06:15,075   INFO  recall_roi_0.7: 0.000000
2025-07-12 16:06:15,075   INFO  recall_rcnn_0.7: 0.143626
2025-07-12 16:06:15,075   INFO  Average predicted number of objects(81 samples): 110.481
2025-07-12 16:06:17,358   INFO  The predictions of NuScenes have been saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_100/val/final_result/data/results_nusc.json
2025-07-12 16:06:19,999   INFO  ----------------Nuscene detection_cvpr_2019 results-----------------
***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.25, 0.18, 0.50, 0.15, 0.10 | 51.41, 68.52, 77.30, 79.55 | mean AP: 0.6919468479838672
***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.16, 0.23, 0.11, 0.05 | 31.54, 33.72, 33.72, 33.80 | mean AP: 0.33194148917622623
***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.10, 0.29, 0.23, 2.54, 0.24 | 0.00, 3.16, 57.37, 61.83 | mean AP: 0.30590730041992054
***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, 1.00, 1.00 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
1.00, 1.00, 1.00, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.19, 0.36, 1.24, 0.06, 0.00 | 11.75, 11.91, 12.19, 12.85 | mean AP: 0.12175661370443125
***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.16, 0.36, 1.55, 0.35, 0.28 | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.14, 0.30, 0.37, 0.26, 0.09 | 80.03, 81.88, 83.56, 86.93 | mean AP: 0.8309802468488381
***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0
0.15, 0.44, nan, nan, nan | 0.00, 0.00, 0.00, 0.00 | mean AP: 0.0
--------------average performance-------------
trans_err:	 0.5154
scale_err:	 0.5084
orient_err:	 0.7916
vel_err:	 0.6829
attr_err:	 0.3445
mAP:	 0.2283
NDS:	 0.3299

2025-07-12 16:06:20,000   INFO  Result is saved to /root/autodl-tmp/OpenPCDet/output/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext/default/eval/eval_with_train/epoch_100/val
2025-07-12 16:06:20,000   INFO  ****************Evaluation done.*****************
2025-07-12 16:06:20,004   INFO  Epoch 100 has been evaluated
